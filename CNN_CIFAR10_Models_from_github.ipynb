{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN CIFAR10 Models_from_github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Download progress: 100.0%\n",
      "Download finished. Extracting files.\n",
      "Done.\n",
      "\n",
      "Trying to restore last checkpoint ...\n",
      "\n",
      "Failed to restore checkpoint. Initializing variables instead.\n",
      "\n",
      "Epoch: 1/60\n",
      "\n",
      "Global step:     1 - [>-----------------------------]   0% - acc: 0.0938 - loss: 2.3014 - 297.1 sample/sec\n",
      "Global step:    11 - [>-----------------------------]   3% - acc: 0.0859 - loss: 2.3058 - 340.3 sample/sec\n",
      "Global step:    21 - [=>----------------------------]   5% - acc: 0.2344 - loss: 2.2179 - 363.0 sample/sec\n",
      "Global step:    31 - [==>---------------------------]   8% - acc: 0.2812 - loss: 2.1843 - 355.9 sample/sec\n",
      "Global step:    41 - [==>---------------------------]  10% - acc: 0.2344 - loss: 2.2072 - 352.9 sample/sec\n",
      "Global step:    51 - [===>--------------------------]  13% - acc: 0.3281 - loss: 2.1298 - 369.2 sample/sec\n",
      "Global step:    61 - [====>-------------------------]  15% - acc: 0.2422 - loss: 2.1920 - 362.0 sample/sec\n",
      "Global step:    71 - [=====>------------------------]  18% - acc: 0.2109 - loss: 2.2251 - 355.2 sample/sec\n",
      "Global step:    81 - [=====>------------------------]  20% - acc: 0.2578 - loss: 2.1820 - 375.0 sample/sec\n",
      "Global step:    91 - [======>-----------------------]  23% - acc: 0.2734 - loss: 2.1858 - 364.3 sample/sec\n",
      "Global step:   101 - [=======>----------------------]  26% - acc: 0.2891 - loss: 2.1681 - 365.5 sample/sec\n",
      "Global step:   111 - [========>---------------------]  28% - acc: 0.2891 - loss: 2.1636 - 362.0 sample/sec\n",
      "Global step:   121 - [========>---------------------]  31% - acc: 0.3047 - loss: 2.1740 - 359.9 sample/sec\n",
      "Global step:   131 - [=========>--------------------]  33% - acc: 0.3125 - loss: 2.1323 - 354.6 sample/sec\n",
      "Global step:   141 - [==========>-------------------]  36% - acc: 0.3594 - loss: 2.0960 - 362.7 sample/sec\n",
      "Global step:   151 - [===========>------------------]  38% - acc: 0.2500 - loss: 2.1977 - 348.7 sample/sec\n",
      "Global step:   161 - [===========>------------------]  41% - acc: 0.3438 - loss: 2.0951 - 325.1 sample/sec\n",
      "Global step:   171 - [============>-----------------]  43% - acc: 0.3516 - loss: 2.1115 - 372.7 sample/sec\n",
      "Global step:   181 - [=============>----------------]  46% - acc: 0.3750 - loss: 2.0863 - 379.0 sample/sec\n",
      "Global step:   191 - [==============>---------------]  49% - acc: 0.3906 - loss: 2.0516 - 361.3 sample/sec\n",
      "Global step:   201 - [==============>---------------]  51% - acc: 0.3281 - loss: 2.1283 - 366.3 sample/sec\n",
      "Global step:   211 - [===============>--------------]  54% - acc: 0.3906 - loss: 2.0823 - 375.4 sample/sec\n",
      "Global step:   221 - [================>-------------]  56% - acc: 0.3438 - loss: 2.1129 - 367.9 sample/sec\n",
      "Global step:   231 - [=================>------------]  59% - acc: 0.3594 - loss: 2.0839 - 374.0 sample/sec\n",
      "Global step:   241 - [=================>------------]  61% - acc: 0.3672 - loss: 2.0820 - 356.5 sample/sec\n",
      "Global step:   251 - [==================>-----------]  64% - acc: 0.4297 - loss: 2.0401 - 351.2 sample/sec\n",
      "Global step:   261 - [===================>----------]  66% - acc: 0.3828 - loss: 2.0918 - 365.2 sample/sec\n",
      "Global step:   271 - [====================>---------]  69% - acc: 0.3828 - loss: 2.0681 - 378.8 sample/sec\n",
      "Global step:   281 - [====================>---------]  72% - acc: 0.4375 - loss: 2.0257 - 381.8 sample/sec\n",
      "Global step:   291 - [=====================>--------]  74% - acc: 0.3359 - loss: 2.1212 - 354.0 sample/sec\n",
      "Global step:   301 - [======================>-------]  77% - acc: 0.3828 - loss: 2.0578 - 350.5 sample/sec\n",
      "Global step:   311 - [======================>-------]  79% - acc: 0.3750 - loss: 2.0887 - 363.7 sample/sec\n",
      "Global step:   321 - [=======================>------]  82% - acc: 0.3359 - loss: 2.1037 - 360.7 sample/sec\n",
      "Global step:   331 - [========================>-----]  84% - acc: 0.4766 - loss: 1.9933 - 363.9 sample/sec\n",
      "Global step:   341 - [=========================>----]  87% - acc: 0.3984 - loss: 2.0492 - 355.6 sample/sec\n",
      "Global step:   351 - [==========================>---]  90% - acc: 0.3906 - loss: 2.0684 - 371.0 sample/sec\n",
      "Global step:   361 - [==========================>---]  92% - acc: 0.4375 - loss: 2.0147 - 353.5 sample/sec\n",
      "Global step:   371 - [===========================>--]  95% - acc: 0.4219 - loss: 2.0356 - 360.7 sample/sec\n",
      "Global step:   381 - [============================>-]  97% - acc: 0.4297 - loss: 2.0315 - 358.0 sample/sec\n",
      "Global step:   391 - [=============================>] 100% - acc: 0.3750 - loss: 2.0903 - 557.6 sample/sec\n",
      "\n",
      "Epoch 1 - accuracy: 41.30% (4130/10000) - time: 00:02:28.21\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 2/60\n",
      "\n",
      "Global step:   392 - [>-----------------------------]   0% - acc: 0.3828 - loss: 2.0658 - 370.1 sample/sec\n",
      "Global step:   402 - [>-----------------------------]   3% - acc: 0.4219 - loss: 2.0195 - 362.6 sample/sec\n",
      "Global step:   412 - [=>----------------------------]   5% - acc: 0.4531 - loss: 1.9893 - 365.8 sample/sec\n",
      "Global step:   422 - [==>---------------------------]   8% - acc: 0.4219 - loss: 2.0333 - 343.6 sample/sec\n",
      "Global step:   432 - [==>---------------------------]  10% - acc: 0.4219 - loss: 2.0390 - 311.1 sample/sec\n",
      "Global step:   442 - [===>--------------------------]  13% - acc: 0.5078 - loss: 1.9495 - 298.2 sample/sec\n",
      "Global step:   452 - [====>-------------------------]  15% - acc: 0.4141 - loss: 2.0442 - 273.2 sample/sec\n",
      "Global step:   462 - [=====>------------------------]  18% - acc: 0.4297 - loss: 2.0220 - 285.9 sample/sec\n",
      "Global step:   472 - [=====>------------------------]  20% - acc: 0.5391 - loss: 1.9235 - 273.5 sample/sec\n",
      "Global step:   482 - [======>-----------------------]  23% - acc: 0.4297 - loss: 2.0207 - 269.5 sample/sec\n",
      "Global step:   492 - [=======>----------------------]  26% - acc: 0.4297 - loss: 2.0099 - 279.8 sample/sec\n",
      "Global step:   502 - [========>---------------------]  28% - acc: 0.3516 - loss: 2.0755 - 332.3 sample/sec\n",
      "Global step:   512 - [========>---------------------]  31% - acc: 0.5000 - loss: 1.9683 - 352.0 sample/sec\n",
      "Global step:   522 - [=========>--------------------]  33% - acc: 0.4531 - loss: 2.0064 - 361.6 sample/sec\n",
      "Global step:   532 - [==========>-------------------]  36% - acc: 0.4453 - loss: 1.9915 - 358.4 sample/sec\n",
      "Global step:   542 - [===========>------------------]  38% - acc: 0.4922 - loss: 1.9762 - 367.3 sample/sec\n",
      "Global step:   552 - [===========>------------------]  41% - acc: 0.4531 - loss: 1.9964 - 362.6 sample/sec\n",
      "Global step:   562 - [============>-----------------]  43% - acc: 0.4531 - loss: 2.0262 - 370.5 sample/sec\n",
      "Global step:   572 - [=============>----------------]  46% - acc: 0.5625 - loss: 1.8977 - 349.3 sample/sec\n",
      "Global step:   582 - [==============>---------------]  49% - acc: 0.4844 - loss: 1.9565 - 359.7 sample/sec\n",
      "Global step:   592 - [==============>---------------]  51% - acc: 0.5156 - loss: 1.9529 - 364.4 sample/sec\n",
      "Global step:   602 - [===============>--------------]  54% - acc: 0.5547 - loss: 1.9150 - 354.9 sample/sec\n",
      "Global step:   612 - [================>-------------]  56% - acc: 0.4766 - loss: 1.9730 - 359.8 sample/sec\n",
      "Global step:   622 - [=================>------------]  59% - acc: 0.4609 - loss: 1.9870 - 370.0 sample/sec\n",
      "Global step:   632 - [=================>------------]  61% - acc: 0.4766 - loss: 1.9848 - 375.7 sample/sec\n",
      "Global step:   642 - [==================>-----------]  64% - acc: 0.5156 - loss: 1.9341 - 355.9 sample/sec\n",
      "Global step:   652 - [===================>----------]  66% - acc: 0.4531 - loss: 1.9936 - 353.3 sample/sec\n",
      "Global step:   662 - [====================>---------]  69% - acc: 0.5625 - loss: 1.9091 - 357.4 sample/sec\n",
      "Global step:   672 - [====================>---------]  72% - acc: 0.5156 - loss: 1.9385 - 357.2 sample/sec\n",
      "Global step:   682 - [=====================>--------]  74% - acc: 0.4297 - loss: 2.0108 - 361.3 sample/sec\n",
      "Global step:   692 - [======================>-------]  77% - acc: 0.5312 - loss: 1.9161 - 362.9 sample/sec\n",
      "Global step:   702 - [======================>-------]  79% - acc: 0.5000 - loss: 1.9565 - 293.1 sample/sec\n",
      "Global step:   712 - [=======================>------]  82% - acc: 0.4531 - loss: 2.0064 - 359.7 sample/sec\n",
      "Global step:   722 - [========================>-----]  84% - acc: 0.6562 - loss: 1.8114 - 294.8 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:   732 - [=========================>----]  87% - acc: 0.5703 - loss: 1.8789 - 353.4 sample/sec\n",
      "Global step:   742 - [==========================>---]  90% - acc: 0.4609 - loss: 1.9625 - 358.0 sample/sec\n",
      "Global step:   752 - [==========================>---]  92% - acc: 0.6328 - loss: 1.8303 - 351.9 sample/sec\n",
      "Global step:   762 - [===========================>--]  95% - acc: 0.5469 - loss: 1.9229 - 344.8 sample/sec\n",
      "Global step:   772 - [============================>-]  97% - acc: 0.5156 - loss: 1.9277 - 354.2 sample/sec\n",
      "Global step:   782 - [=============================>] 100% - acc: 0.5875 - loss: 1.8939 - 544.4 sample/sec\n",
      "\n",
      "Epoch 2 - accuracy: 55.40% (5540/10000) - time: 00:02:36.06\n",
      "This epoch receive better accuracy: 55.40 > 41.30. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 3/60\n",
      "\n",
      "Global step:   783 - [>-----------------------------]   0% - acc: 0.5938 - loss: 1.8669 - 345.5 sample/sec\n",
      "Global step:   793 - [>-----------------------------]   3% - acc: 0.5859 - loss: 1.8758 - 356.4 sample/sec\n",
      "Global step:   803 - [=>----------------------------]   5% - acc: 0.6016 - loss: 1.8646 - 360.7 sample/sec\n",
      "Global step:   813 - [==>---------------------------]   8% - acc: 0.5234 - loss: 1.9292 - 359.3 sample/sec\n",
      "Global step:   823 - [==>---------------------------]  10% - acc: 0.5703 - loss: 1.8923 - 355.4 sample/sec\n",
      "Global step:   833 - [===>--------------------------]  13% - acc: 0.5781 - loss: 1.8679 - 366.6 sample/sec\n",
      "Global step:   843 - [====>-------------------------]  15% - acc: 0.5078 - loss: 1.9620 - 379.5 sample/sec\n",
      "Global step:   853 - [=====>------------------------]  18% - acc: 0.5000 - loss: 1.9405 - 375.0 sample/sec\n",
      "Global step:   863 - [=====>------------------------]  20% - acc: 0.6094 - loss: 1.8563 - 360.7 sample/sec\n",
      "Global step:   873 - [======>-----------------------]  23% - acc: 0.5703 - loss: 1.8747 - 373.6 sample/sec\n",
      "Global step:   883 - [=======>----------------------]  26% - acc: 0.5547 - loss: 1.8910 - 374.1 sample/sec\n",
      "Global step:   893 - [========>---------------------]  28% - acc: 0.5312 - loss: 1.9191 - 368.3 sample/sec\n",
      "Global step:   903 - [========>---------------------]  31% - acc: 0.6172 - loss: 1.8404 - 363.1 sample/sec\n",
      "Global step:   913 - [=========>--------------------]  33% - acc: 0.5156 - loss: 1.9244 - 370.4 sample/sec\n",
      "Global step:   923 - [==========>-------------------]  36% - acc: 0.5156 - loss: 1.9416 - 370.1 sample/sec\n",
      "Global step:   933 - [===========>------------------]  38% - acc: 0.6094 - loss: 1.8398 - 367.8 sample/sec\n",
      "Global step:   943 - [===========>------------------]  41% - acc: 0.6016 - loss: 1.8584 - 356.0 sample/sec\n",
      "Global step:   953 - [============>-----------------]  43% - acc: 0.5938 - loss: 1.8860 - 356.8 sample/sec\n",
      "Global step:   963 - [=============>----------------]  46% - acc: 0.6797 - loss: 1.7926 - 374.3 sample/sec\n",
      "Global step:   973 - [==============>---------------]  49% - acc: 0.5781 - loss: 1.8712 - 383.0 sample/sec\n",
      "Global step:   983 - [==============>---------------]  51% - acc: 0.5312 - loss: 1.9070 - 367.0 sample/sec\n",
      "Global step:   993 - [===============>--------------]  54% - acc: 0.5859 - loss: 1.8735 - 375.5 sample/sec\n",
      "Global step:  1003 - [================>-------------]  56% - acc: 0.6016 - loss: 1.8433 - 353.8 sample/sec\n",
      "Global step:  1013 - [=================>------------]  59% - acc: 0.6172 - loss: 1.8509 - 360.6 sample/sec\n",
      "Global step:  1023 - [=================>------------]  61% - acc: 0.5469 - loss: 1.9046 - 361.0 sample/sec\n",
      "Global step:  1033 - [==================>-----------]  64% - acc: 0.6094 - loss: 1.8544 - 372.3 sample/sec\n",
      "Global step:  1043 - [===================>----------]  66% - acc: 0.5391 - loss: 1.9101 - 378.3 sample/sec\n",
      "Global step:  1053 - [====================>---------]  69% - acc: 0.5781 - loss: 1.8701 - 373.2 sample/sec\n",
      "Global step:  1063 - [====================>---------]  72% - acc: 0.6484 - loss: 1.8329 - 381.8 sample/sec\n",
      "Global step:  1073 - [=====================>--------]  74% - acc: 0.6094 - loss: 1.8555 - 360.6 sample/sec\n",
      "Global step:  1083 - [======================>-------]  77% - acc: 0.6797 - loss: 1.7716 - 378.6 sample/sec\n",
      "Global step:  1093 - [======================>-------]  79% - acc: 0.5859 - loss: 1.8753 - 373.8 sample/sec\n",
      "Global step:  1103 - [=======================>------]  82% - acc: 0.5469 - loss: 1.9142 - 280.9 sample/sec\n",
      "Global step:  1113 - [========================>-----]  84% - acc: 0.6953 - loss: 1.7695 - 371.5 sample/sec\n",
      "Global step:  1123 - [=========================>----]  87% - acc: 0.5938 - loss: 1.8683 - 339.3 sample/sec\n",
      "Global step:  1133 - [==========================>---]  90% - acc: 0.5469 - loss: 1.9192 - 306.3 sample/sec\n",
      "Global step:  1143 - [==========================>---]  92% - acc: 0.7422 - loss: 1.7223 - 368.6 sample/sec\n",
      "Global step:  1153 - [===========================>--]  95% - acc: 0.6562 - loss: 1.8227 - 374.2 sample/sec\n",
      "Global step:  1163 - [============================>-]  97% - acc: 0.6328 - loss: 1.8202 - 355.3 sample/sec\n",
      "Global step:  1173 - [=============================>] 100% - acc: 0.6250 - loss: 1.8243 - 591.1 sample/sec\n",
      "\n",
      "Epoch 3 - accuracy: 62.08% (6208/10000) - time: 00:02:26.45\n",
      "This epoch receive better accuracy: 62.08 > 55.40. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 4/60\n",
      "\n",
      "Global step:  1174 - [>-----------------------------]   0% - acc: 0.7109 - loss: 1.7646 - 370.1 sample/sec\n",
      "Global step:  1184 - [>-----------------------------]   3% - acc: 0.6250 - loss: 1.8289 - 303.4 sample/sec\n",
      "Global step:  1194 - [=>----------------------------]   5% - acc: 0.6953 - loss: 1.7736 - 357.8 sample/sec\n",
      "Global step:  1204 - [==>---------------------------]   8% - acc: 0.5781 - loss: 1.8721 - 367.8 sample/sec\n",
      "Global step:  1214 - [==>---------------------------]  10% - acc: 0.7031 - loss: 1.7766 - 375.1 sample/sec\n",
      "Global step:  1224 - [===>--------------------------]  13% - acc: 0.6406 - loss: 1.8317 - 325.5 sample/sec\n",
      "Global step:  1234 - [====>-------------------------]  15% - acc: 0.6328 - loss: 1.8347 - 366.0 sample/sec\n",
      "Global step:  1244 - [=====>------------------------]  18% - acc: 0.6016 - loss: 1.8707 - 363.6 sample/sec\n",
      "Global step:  1254 - [=====>------------------------]  20% - acc: 0.6562 - loss: 1.8206 - 348.9 sample/sec\n",
      "Global step:  1264 - [======>-----------------------]  23% - acc: 0.6562 - loss: 1.7995 - 361.3 sample/sec\n",
      "Global step:  1274 - [=======>----------------------]  26% - acc: 0.6250 - loss: 1.8262 - 336.9 sample/sec\n",
      "Global step:  1284 - [========>---------------------]  28% - acc: 0.6016 - loss: 1.8624 - 344.7 sample/sec\n",
      "Global step:  1294 - [========>---------------------]  31% - acc: 0.6641 - loss: 1.7929 - 306.4 sample/sec\n",
      "Global step:  1304 - [=========>--------------------]  33% - acc: 0.6562 - loss: 1.8139 - 319.0 sample/sec\n",
      "Global step:  1314 - [==========>-------------------]  36% - acc: 0.6094 - loss: 1.8619 - 310.5 sample/sec\n",
      "Global step:  1324 - [===========>------------------]  38% - acc: 0.6797 - loss: 1.7755 - 359.6 sample/sec\n",
      "Global step:  1334 - [===========>------------------]  41% - acc: 0.6484 - loss: 1.7856 - 377.2 sample/sec\n",
      "Global step:  1344 - [============>-----------------]  43% - acc: 0.6328 - loss: 1.8276 - 368.0 sample/sec\n",
      "Global step:  1354 - [=============>----------------]  46% - acc: 0.7266 - loss: 1.7375 - 340.5 sample/sec\n",
      "Global step:  1364 - [==============>---------------]  49% - acc: 0.6797 - loss: 1.7956 - 368.8 sample/sec\n",
      "Global step:  1374 - [==============>---------------]  51% - acc: 0.6094 - loss: 1.8611 - 364.1 sample/sec\n",
      "Global step:  1384 - [===============>--------------]  54% - acc: 0.6562 - loss: 1.7978 - 360.3 sample/sec\n",
      "Global step:  1394 - [================>-------------]  56% - acc: 0.6797 - loss: 1.7932 - 332.8 sample/sec\n",
      "Global step:  1404 - [=================>------------]  59% - acc: 0.6406 - loss: 1.8185 - 339.5 sample/sec\n",
      "Global step:  1414 - [=================>------------]  61% - acc: 0.6016 - loss: 1.8428 - 338.3 sample/sec\n",
      "Global step:  1424 - [==================>-----------]  64% - acc: 0.6406 - loss: 1.8185 - 341.6 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  1434 - [===================>----------]  66% - acc: 0.6250 - loss: 1.8492 - 334.9 sample/sec\n",
      "Global step:  1444 - [====================>---------]  69% - acc: 0.5781 - loss: 1.8844 - 339.3 sample/sec\n",
      "Global step:  1454 - [====================>---------]  72% - acc: 0.5547 - loss: 1.8747 - 349.5 sample/sec\n",
      "Global step:  1464 - [=====================>--------]  74% - acc: 0.5781 - loss: 1.8582 - 355.1 sample/sec\n",
      "Global step:  1474 - [======================>-------]  77% - acc: 0.7109 - loss: 1.7433 - 342.3 sample/sec\n",
      "Global step:  1484 - [======================>-------]  79% - acc: 0.6172 - loss: 1.8399 - 336.7 sample/sec\n",
      "Global step:  1494 - [=======================>------]  82% - acc: 0.5859 - loss: 1.8637 - 345.4 sample/sec\n",
      "Global step:  1504 - [========================>-----]  84% - acc: 0.7266 - loss: 1.7407 - 327.2 sample/sec\n",
      "Global step:  1514 - [=========================>----]  87% - acc: 0.6641 - loss: 1.7994 - 364.2 sample/sec\n",
      "Global step:  1524 - [==========================>---]  90% - acc: 0.5859 - loss: 1.8711 - 364.8 sample/sec\n",
      "Global step:  1534 - [==========================>---]  92% - acc: 0.7734 - loss: 1.6834 - 361.0 sample/sec\n",
      "Global step:  1544 - [===========================>--]  95% - acc: 0.7109 - loss: 1.7627 - 381.3 sample/sec\n",
      "Global step:  1554 - [============================>-]  97% - acc: 0.6484 - loss: 1.8136 - 355.6 sample/sec\n",
      "Global step:  1564 - [=============================>] 100% - acc: 0.6625 - loss: 1.7860 - 561.1 sample/sec\n",
      "\n",
      "Epoch 4 - accuracy: 64.97% (6497/10000) - time: 00:02:33.40\n",
      "This epoch receive better accuracy: 64.97 > 62.08. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 5/60\n",
      "\n",
      "Global step:  1565 - [>-----------------------------]   0% - acc: 0.7266 - loss: 1.7453 - 359.2 sample/sec\n",
      "Global step:  1575 - [>-----------------------------]   3% - acc: 0.7031 - loss: 1.7658 - 357.1 sample/sec\n",
      "Global step:  1585 - [=>----------------------------]   5% - acc: 0.7422 - loss: 1.7161 - 356.5 sample/sec\n",
      "Global step:  1595 - [==>---------------------------]   8% - acc: 0.6484 - loss: 1.8161 - 358.5 sample/sec\n",
      "Global step:  1605 - [==>---------------------------]  10% - acc: 0.6016 - loss: 1.8760 - 358.1 sample/sec\n",
      "Global step:  1615 - [===>--------------------------]  13% - acc: 0.6953 - loss: 1.7668 - 290.5 sample/sec\n",
      "Global step:  1625 - [====>-------------------------]  15% - acc: 0.6250 - loss: 1.8459 - 366.0 sample/sec\n",
      "Global step:  1635 - [=====>------------------------]  18% - acc: 0.6562 - loss: 1.8043 - 374.9 sample/sec\n",
      "Global step:  1645 - [=====>------------------------]  20% - acc: 0.6328 - loss: 1.7989 - 370.9 sample/sec\n",
      "Global step:  1655 - [======>-----------------------]  23% - acc: 0.7031 - loss: 1.7575 - 372.2 sample/sec\n",
      "Global step:  1665 - [=======>----------------------]  26% - acc: 0.7188 - loss: 1.7469 - 310.6 sample/sec\n",
      "Global step:  1675 - [========>---------------------]  28% - acc: 0.6328 - loss: 1.8257 - 381.6 sample/sec\n",
      "Global step:  1685 - [========>---------------------]  31% - acc: 0.7188 - loss: 1.7328 - 363.2 sample/sec\n",
      "Global step:  1695 - [=========>--------------------]  33% - acc: 0.6094 - loss: 1.8363 - 355.4 sample/sec\n",
      "Global step:  1705 - [==========>-------------------]  36% - acc: 0.7109 - loss: 1.7646 - 342.9 sample/sec\n",
      "Global step:  1715 - [===========>------------------]  38% - acc: 0.6484 - loss: 1.8110 - 361.8 sample/sec\n",
      "Global step:  1725 - [===========>------------------]  41% - acc: 0.6406 - loss: 1.8251 - 349.1 sample/sec\n",
      "Global step:  1735 - [============>-----------------]  43% - acc: 0.6094 - loss: 1.8341 - 363.0 sample/sec\n",
      "Global step:  1745 - [=============>----------------]  46% - acc: 0.6953 - loss: 1.7596 - 362.3 sample/sec\n",
      "Global step:  1755 - [==============>---------------]  49% - acc: 0.6953 - loss: 1.7729 - 365.0 sample/sec\n",
      "Global step:  1765 - [==============>---------------]  51% - acc: 0.6406 - loss: 1.8121 - 363.6 sample/sec\n",
      "Global step:  1775 - [===============>--------------]  54% - acc: 0.6797 - loss: 1.7764 - 372.5 sample/sec\n",
      "Global step:  1785 - [================>-------------]  56% - acc: 0.6875 - loss: 1.7663 - 373.0 sample/sec\n",
      "Global step:  1795 - [=================>------------]  59% - acc: 0.6719 - loss: 1.7875 - 373.8 sample/sec\n",
      "Global step:  1805 - [=================>------------]  61% - acc: 0.6406 - loss: 1.8138 - 369.9 sample/sec\n",
      "Global step:  1815 - [==================>-----------]  64% - acc: 0.6797 - loss: 1.7875 - 378.0 sample/sec\n",
      "Global step:  1825 - [===================>----------]  66% - acc: 0.6250 - loss: 1.8296 - 372.9 sample/sec\n",
      "Global step:  1835 - [====================>---------]  69% - acc: 0.6094 - loss: 1.8479 - 355.2 sample/sec\n",
      "Global step:  1845 - [====================>---------]  72% - acc: 0.6562 - loss: 1.8028 - 377.3 sample/sec\n",
      "Global step:  1855 - [=====================>--------]  74% - acc: 0.6328 - loss: 1.8281 - 372.2 sample/sec\n",
      "Global step:  1865 - [======================>-------]  77% - acc: 0.7188 - loss: 1.7403 - 367.0 sample/sec\n",
      "Global step:  1875 - [======================>-------]  79% - acc: 0.6875 - loss: 1.7822 - 369.8 sample/sec\n",
      "Global step:  1885 - [=======================>------]  82% - acc: 0.6406 - loss: 1.8180 - 367.1 sample/sec\n",
      "Global step:  1895 - [========================>-----]  84% - acc: 0.7500 - loss: 1.6958 - 357.9 sample/sec\n",
      "Global step:  1905 - [=========================>----]  87% - acc: 0.6797 - loss: 1.7744 - 360.9 sample/sec\n",
      "Global step:  1915 - [==========================>---]  90% - acc: 0.6562 - loss: 1.7974 - 374.1 sample/sec\n",
      "Global step:  1925 - [==========================>---]  92% - acc: 0.8047 - loss: 1.6669 - 351.8 sample/sec\n",
      "Global step:  1935 - [===========================>--]  95% - acc: 0.7188 - loss: 1.7484 - 354.3 sample/sec\n",
      "Global step:  1945 - [============================>-]  97% - acc: 0.7109 - loss: 1.7382 - 326.7 sample/sec\n",
      "Global step:  1955 - [=============================>] 100% - acc: 0.6875 - loss: 1.7937 - 483.1 sample/sec\n",
      "\n",
      "Epoch 5 - accuracy: 65.18% (6518/10000) - time: 00:02:28.68\n",
      "This epoch receive better accuracy: 65.18 > 64.97. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 6/60\n",
      "\n",
      "Global step:  1956 - [>-----------------------------]   0% - acc: 0.7031 - loss: 1.7550 - 357.5 sample/sec\n",
      "Global step:  1966 - [>-----------------------------]   3% - acc: 0.6562 - loss: 1.7880 - 342.3 sample/sec\n",
      "Global step:  1976 - [=>----------------------------]   5% - acc: 0.7812 - loss: 1.6830 - 332.7 sample/sec\n",
      "Global step:  1986 - [==>---------------------------]   8% - acc: 0.6328 - loss: 1.8307 - 337.4 sample/sec\n",
      "Global step:  1996 - [==>---------------------------]  10% - acc: 0.6875 - loss: 1.7732 - 343.2 sample/sec\n",
      "Global step:  2006 - [===>--------------------------]  13% - acc: 0.6953 - loss: 1.7642 - 340.3 sample/sec\n",
      "Global step:  2016 - [====>-------------------------]  15% - acc: 0.6641 - loss: 1.7815 - 338.3 sample/sec\n",
      "Global step:  2026 - [=====>------------------------]  18% - acc: 0.6719 - loss: 1.7959 - 347.5 sample/sec\n",
      "Global step:  2036 - [=====>------------------------]  20% - acc: 0.7188 - loss: 1.7342 - 358.0 sample/sec\n",
      "Global step:  2046 - [======>-----------------------]  23% - acc: 0.7344 - loss: 1.7199 - 362.3 sample/sec\n",
      "Global step:  2056 - [=======>----------------------]  26% - acc: 0.7734 - loss: 1.6869 - 370.6 sample/sec\n",
      "Global step:  2066 - [========>---------------------]  28% - acc: 0.6641 - loss: 1.7939 - 356.6 sample/sec\n",
      "Global step:  2076 - [========>---------------------]  31% - acc: 0.7422 - loss: 1.7215 - 353.0 sample/sec\n",
      "Global step:  2086 - [=========>--------------------]  33% - acc: 0.6797 - loss: 1.7834 - 324.1 sample/sec\n",
      "Global step:  2096 - [==========>-------------------]  36% - acc: 0.7031 - loss: 1.7688 - 362.9 sample/sec\n",
      "Global step:  2106 - [===========>------------------]  38% - acc: 0.7578 - loss: 1.7065 - 351.1 sample/sec\n",
      "Global step:  2116 - [===========>------------------]  41% - acc: 0.6953 - loss: 1.7590 - 349.3 sample/sec\n",
      "Global step:  2126 - [============>-----------------]  43% - acc: 0.7266 - loss: 1.7367 - 332.9 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  2136 - [=============>----------------]  46% - acc: 0.7656 - loss: 1.6941 - 354.2 sample/sec\n",
      "Global step:  2146 - [==============>---------------]  49% - acc: 0.6953 - loss: 1.7434 - 375.0 sample/sec\n",
      "Global step:  2156 - [==============>---------------]  51% - acc: 0.6953 - loss: 1.7702 - 363.8 sample/sec\n",
      "Global step:  2166 - [===============>--------------]  54% - acc: 0.7031 - loss: 1.7655 - 365.2 sample/sec\n",
      "Global step:  2176 - [================>-------------]  56% - acc: 0.7578 - loss: 1.7080 - 358.4 sample/sec\n",
      "Global step:  2186 - [=================>------------]  59% - acc: 0.6953 - loss: 1.7586 - 367.1 sample/sec\n",
      "Global step:  2196 - [=================>------------]  61% - acc: 0.6875 - loss: 1.7704 - 343.6 sample/sec\n",
      "Global step:  2206 - [==================>-----------]  64% - acc: 0.6719 - loss: 1.7806 - 359.2 sample/sec\n",
      "Global step:  2216 - [===================>----------]  66% - acc: 0.6328 - loss: 1.8116 - 351.0 sample/sec\n",
      "Global step:  2226 - [====================>---------]  69% - acc: 0.6484 - loss: 1.8099 - 352.6 sample/sec\n",
      "Global step:  2236 - [====================>---------]  72% - acc: 0.7500 - loss: 1.7149 - 330.5 sample/sec\n",
      "Global step:  2246 - [=====================>--------]  74% - acc: 0.6719 - loss: 1.7852 - 362.3 sample/sec\n",
      "Global step:  2256 - [======================>-------]  77% - acc: 0.7734 - loss: 1.6855 - 357.8 sample/sec\n",
      "Global step:  2266 - [======================>-------]  79% - acc: 0.6875 - loss: 1.7699 - 324.3 sample/sec\n",
      "Global step:  2276 - [=======================>------]  82% - acc: 0.6719 - loss: 1.7849 - 355.6 sample/sec\n",
      "Global step:  2286 - [========================>-----]  84% - acc: 0.8125 - loss: 1.6734 - 354.1 sample/sec\n",
      "Global step:  2296 - [=========================>----]  87% - acc: 0.6875 - loss: 1.7640 - 361.5 sample/sec\n",
      "Global step:  2306 - [==========================>---]  90% - acc: 0.6875 - loss: 1.7647 - 357.5 sample/sec\n",
      "Global step:  2316 - [==========================>---]  92% - acc: 0.8125 - loss: 1.6526 - 364.2 sample/sec\n",
      "Global step:  2326 - [===========================>--]  95% - acc: 0.7109 - loss: 1.7456 - 355.3 sample/sec\n",
      "Global step:  2336 - [============================>-]  97% - acc: 0.7344 - loss: 1.7162 - 303.9 sample/sec\n",
      "Global step:  2346 - [=============================>] 100% - acc: 0.7250 - loss: 1.7355 - 583.8 sample/sec\n",
      "\n",
      "Epoch 6 - accuracy: 67.28% (6728/10000) - time: 00:02:31.56\n",
      "This epoch receive better accuracy: 67.28 > 65.18. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 7/60\n",
      "\n",
      "Global step:  2347 - [>-----------------------------]   0% - acc: 0.7578 - loss: 1.7138 - 364.0 sample/sec\n",
      "Global step:  2357 - [>-----------------------------]   3% - acc: 0.7422 - loss: 1.7121 - 347.1 sample/sec\n",
      "Global step:  2367 - [=>----------------------------]   5% - acc: 0.7969 - loss: 1.6556 - 353.2 sample/sec\n",
      "Global step:  2377 - [==>---------------------------]   8% - acc: 0.7344 - loss: 1.7263 - 374.9 sample/sec\n",
      "Global step:  2387 - [==>---------------------------]  10% - acc: 0.6875 - loss: 1.7729 - 382.4 sample/sec\n",
      "Global step:  2397 - [===>--------------------------]  13% - acc: 0.7500 - loss: 1.6992 - 365.6 sample/sec\n",
      "Global step:  2407 - [====>-------------------------]  15% - acc: 0.6641 - loss: 1.7800 - 379.3 sample/sec\n",
      "Global step:  2417 - [=====>------------------------]  18% - acc: 0.7266 - loss: 1.7280 - 370.7 sample/sec\n",
      "Global step:  2427 - [=====>------------------------]  20% - acc: 0.7656 - loss: 1.6952 - 372.9 sample/sec\n",
      "Global step:  2437 - [======>-----------------------]  23% - acc: 0.8047 - loss: 1.6613 - 372.9 sample/sec\n",
      "Global step:  2447 - [=======>----------------------]  26% - acc: 0.7734 - loss: 1.6990 - 357.9 sample/sec\n",
      "Global step:  2457 - [========>---------------------]  28% - acc: 0.6953 - loss: 1.7726 - 373.5 sample/sec\n",
      "Global step:  2467 - [========>---------------------]  31% - acc: 0.7500 - loss: 1.7076 - 366.4 sample/sec\n",
      "Global step:  2477 - [=========>--------------------]  33% - acc: 0.7109 - loss: 1.7552 - 360.2 sample/sec\n",
      "Global step:  2487 - [==========>-------------------]  36% - acc: 0.7109 - loss: 1.7462 - 329.8 sample/sec\n",
      "Global step:  2497 - [===========>------------------]  38% - acc: 0.7422 - loss: 1.7194 - 381.6 sample/sec\n",
      "Global step:  2507 - [===========>------------------]  41% - acc: 0.7266 - loss: 1.7305 - 373.1 sample/sec\n",
      "Global step:  2517 - [============>-----------------]  43% - acc: 0.7500 - loss: 1.7074 - 367.6 sample/sec\n",
      "Global step:  2527 - [=============>----------------]  46% - acc: 0.7578 - loss: 1.7051 - 369.7 sample/sec\n",
      "Global step:  2537 - [==============>---------------]  49% - acc: 0.7422 - loss: 1.7221 - 328.0 sample/sec\n",
      "Global step:  2547 - [==============>---------------]  51% - acc: 0.6562 - loss: 1.8051 - 376.9 sample/sec\n",
      "Global step:  2557 - [===============>--------------]  54% - acc: 0.7266 - loss: 1.7474 - 372.6 sample/sec\n",
      "Global step:  2567 - [================>-------------]  56% - acc: 0.7500 - loss: 1.6995 - 364.6 sample/sec\n",
      "Global step:  2577 - [=================>------------]  59% - acc: 0.7422 - loss: 1.7274 - 369.8 sample/sec\n",
      "Global step:  2587 - [=================>------------]  61% - acc: 0.7344 - loss: 1.7266 - 376.4 sample/sec\n",
      "Global step:  2597 - [==================>-----------]  64% - acc: 0.7422 - loss: 1.7218 - 375.0 sample/sec\n",
      "Global step:  2607 - [===================>----------]  66% - acc: 0.6562 - loss: 1.8049 - 372.5 sample/sec\n",
      "Global step:  2617 - [====================>---------]  69% - acc: 0.7031 - loss: 1.7648 - 373.2 sample/sec\n",
      "Global step:  2627 - [====================>---------]  72% - acc: 0.7891 - loss: 1.6842 - 376.0 sample/sec\n",
      "Global step:  2637 - [=====================>--------]  74% - acc: 0.7422 - loss: 1.7203 - 368.8 sample/sec\n",
      "Global step:  2647 - [======================>-------]  77% - acc: 0.7344 - loss: 1.7170 - 368.6 sample/sec\n",
      "Global step:  2657 - [======================>-------]  79% - acc: 0.7266 - loss: 1.7257 - 363.1 sample/sec\n",
      "Global step:  2667 - [=======================>------]  82% - acc: 0.7344 - loss: 1.7401 - 370.3 sample/sec\n",
      "Global step:  2677 - [========================>-----]  84% - acc: 0.7578 - loss: 1.7123 - 367.3 sample/sec\n",
      "Global step:  2687 - [=========================>----]  87% - acc: 0.6875 - loss: 1.7705 - 374.3 sample/sec\n",
      "Global step:  2697 - [==========================>---]  90% - acc: 0.7344 - loss: 1.7246 - 376.7 sample/sec\n",
      "Global step:  2707 - [==========================>---]  92% - acc: 0.8047 - loss: 1.6505 - 378.2 sample/sec\n",
      "Global step:  2717 - [===========================>--]  95% - acc: 0.6953 - loss: 1.7611 - 373.9 sample/sec\n",
      "Global step:  2727 - [============================>-]  97% - acc: 0.7656 - loss: 1.7128 - 376.9 sample/sec\n",
      "Global step:  2737 - [=============================>] 100% - acc: 0.6875 - loss: 1.7620 - 590.2 sample/sec\n",
      "\n",
      "Epoch 7 - accuracy: 68.83% (6883/10000) - time: 00:02:25.26\n",
      "This epoch receive better accuracy: 68.83 > 67.28. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 8/60\n",
      "\n",
      "Global step:  2738 - [>-----------------------------]   0% - acc: 0.7812 - loss: 1.6749 - 377.7 sample/sec\n",
      "Global step:  2748 - [>-----------------------------]   3% - acc: 0.7578 - loss: 1.7084 - 355.5 sample/sec\n",
      "Global step:  2758 - [=>----------------------------]   5% - acc: 0.7891 - loss: 1.6537 - 371.3 sample/sec\n",
      "Global step:  2768 - [==>---------------------------]   8% - acc: 0.7266 - loss: 1.7254 - 363.4 sample/sec\n",
      "Global step:  2778 - [==>---------------------------]  10% - acc: 0.6953 - loss: 1.7501 - 366.5 sample/sec\n",
      "Global step:  2788 - [===>--------------------------]  13% - acc: 0.7578 - loss: 1.6918 - 350.2 sample/sec\n",
      "Global step:  2798 - [====>-------------------------]  15% - acc: 0.7266 - loss: 1.7358 - 381.6 sample/sec\n",
      "Global step:  2808 - [=====>------------------------]  18% - acc: 0.7422 - loss: 1.7429 - 363.6 sample/sec\n",
      "Global step:  2818 - [=====>------------------------]  20% - acc: 0.7656 - loss: 1.6994 - 362.2 sample/sec\n",
      "Global step:  2828 - [======>-----------------------]  23% - acc: 0.8516 - loss: 1.6173 - 333.1 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  2838 - [=======>----------------------]  26% - acc: 0.8047 - loss: 1.6677 - 279.6 sample/sec\n",
      "Global step:  2848 - [========>---------------------]  28% - acc: 0.7344 - loss: 1.7230 - 363.3 sample/sec\n",
      "Global step:  2858 - [========>---------------------]  31% - acc: 0.7812 - loss: 1.6794 - 367.1 sample/sec\n",
      "Global step:  2868 - [=========>--------------------]  33% - acc: 0.6953 - loss: 1.7710 - 373.0 sample/sec\n",
      "Global step:  2878 - [==========>-------------------]  36% - acc: 0.7578 - loss: 1.7083 - 359.6 sample/sec\n",
      "Global step:  2888 - [===========>------------------]  38% - acc: 0.7578 - loss: 1.7062 - 351.4 sample/sec\n",
      "Global step:  2898 - [===========>------------------]  41% - acc: 0.7734 - loss: 1.6754 - 377.0 sample/sec\n",
      "Global step:  2908 - [============>-----------------]  43% - acc: 0.7344 - loss: 1.7252 - 378.1 sample/sec\n",
      "Global step:  2918 - [=============>----------------]  46% - acc: 0.7734 - loss: 1.6890 - 366.2 sample/sec\n",
      "Global step:  2928 - [==============>---------------]  49% - acc: 0.7266 - loss: 1.7354 - 370.0 sample/sec\n",
      "Global step:  2938 - [==============>---------------]  51% - acc: 0.6797 - loss: 1.7796 - 367.4 sample/sec\n",
      "Global step:  2948 - [===============>--------------]  54% - acc: 0.7266 - loss: 1.7449 - 342.5 sample/sec\n",
      "Global step:  2958 - [================>-------------]  56% - acc: 0.7891 - loss: 1.6659 - 354.4 sample/sec\n",
      "Global step:  2968 - [=================>------------]  59% - acc: 0.7578 - loss: 1.7066 - 357.9 sample/sec\n",
      "Global step:  2978 - [=================>------------]  61% - acc: 0.7422 - loss: 1.7197 - 370.2 sample/sec\n",
      "Global step:  2988 - [==================>-----------]  64% - acc: 0.7422 - loss: 1.7265 - 372.7 sample/sec\n",
      "Global step:  2998 - [===================>----------]  66% - acc: 0.7109 - loss: 1.7449 - 377.7 sample/sec\n",
      "Global step:  3008 - [====================>---------]  69% - acc: 0.7188 - loss: 1.7486 - 366.1 sample/sec\n",
      "Global step:  3018 - [====================>---------]  72% - acc: 0.7812 - loss: 1.6749 - 359.0 sample/sec\n",
      "Global step:  3028 - [=====================>--------]  74% - acc: 0.7891 - loss: 1.6802 - 351.9 sample/sec\n",
      "Global step:  3038 - [======================>-------]  77% - acc: 0.7734 - loss: 1.6849 - 360.6 sample/sec\n",
      "Global step:  3048 - [======================>-------]  79% - acc: 0.7344 - loss: 1.7391 - 341.5 sample/sec\n",
      "Global step:  3058 - [=======================>------]  82% - acc: 0.7109 - loss: 1.7508 - 355.8 sample/sec\n",
      "Global step:  3068 - [========================>-----]  84% - acc: 0.8359 - loss: 1.6326 - 361.8 sample/sec\n",
      "Global step:  3078 - [=========================>----]  87% - acc: 0.7578 - loss: 1.6991 - 321.9 sample/sec\n",
      "Global step:  3088 - [==========================>---]  90% - acc: 0.7344 - loss: 1.7093 - 346.5 sample/sec\n",
      "Global step:  3098 - [==========================>---]  92% - acc: 0.8047 - loss: 1.6533 - 361.3 sample/sec\n",
      "Global step:  3108 - [===========================>--]  95% - acc: 0.7422 - loss: 1.7174 - 346.4 sample/sec\n",
      "Global step:  3118 - [============================>-]  97% - acc: 0.7812 - loss: 1.6853 - 363.0 sample/sec\n",
      "Global step:  3128 - [=============================>] 100% - acc: 0.7875 - loss: 1.6788 - 511.9 sample/sec\n",
      "\n",
      "Epoch 8 - accuracy: 71.85% (7185/10000) - time: 00:02:29.85\n",
      "This epoch receive better accuracy: 71.85 > 68.83. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 9/60\n",
      "\n",
      "Global step:  3129 - [>-----------------------------]   0% - acc: 0.8047 - loss: 1.6557 - 358.6 sample/sec\n",
      "Global step:  3139 - [>-----------------------------]   3% - acc: 0.7500 - loss: 1.7062 - 340.1 sample/sec\n",
      "Global step:  3149 - [=>----------------------------]   5% - acc: 0.8438 - loss: 1.6136 - 340.7 sample/sec\n",
      "Global step:  3159 - [==>---------------------------]   8% - acc: 0.6797 - loss: 1.7656 - 343.6 sample/sec\n",
      "Global step:  3169 - [==>---------------------------]  10% - acc: 0.6797 - loss: 1.7744 - 341.2 sample/sec\n",
      "Global step:  3179 - [===>--------------------------]  13% - acc: 0.7656 - loss: 1.7055 - 343.0 sample/sec\n",
      "Global step:  3189 - [====>-------------------------]  15% - acc: 0.7500 - loss: 1.7026 - 339.0 sample/sec\n",
      "Global step:  3199 - [=====>------------------------]  18% - acc: 0.7344 - loss: 1.7251 - 328.8 sample/sec\n",
      "Global step:  3209 - [=====>------------------------]  20% - acc: 0.7500 - loss: 1.7007 - 344.2 sample/sec\n",
      "Global step:  3219 - [======>-----------------------]  23% - acc: 0.7969 - loss: 1.6624 - 350.5 sample/sec\n",
      "Global step:  3229 - [=======>----------------------]  26% - acc: 0.7969 - loss: 1.6574 - 345.8 sample/sec\n",
      "Global step:  3239 - [========>---------------------]  28% - acc: 0.7500 - loss: 1.7114 - 352.2 sample/sec\n",
      "Global step:  3249 - [========>---------------------]  31% - acc: 0.7812 - loss: 1.6690 - 343.5 sample/sec\n",
      "Global step:  3259 - [=========>--------------------]  33% - acc: 0.7578 - loss: 1.7023 - 361.0 sample/sec\n",
      "Global step:  3269 - [==========>-------------------]  36% - acc: 0.7109 - loss: 1.7590 - 341.5 sample/sec\n",
      "Global step:  3279 - [===========>------------------]  38% - acc: 0.7891 - loss: 1.6833 - 343.2 sample/sec\n",
      "Global step:  3289 - [===========>------------------]  41% - acc: 0.7656 - loss: 1.6871 - 341.7 sample/sec\n",
      "Global step:  3299 - [============>-----------------]  43% - acc: 0.7656 - loss: 1.6826 - 328.5 sample/sec\n",
      "Global step:  3309 - [=============>----------------]  46% - acc: 0.7500 - loss: 1.7085 - 370.5 sample/sec\n",
      "Global step:  3319 - [==============>---------------]  49% - acc: 0.7734 - loss: 1.6827 - 369.3 sample/sec\n",
      "Global step:  3329 - [==============>---------------]  51% - acc: 0.7031 - loss: 1.7566 - 361.8 sample/sec\n",
      "Global step:  3339 - [===============>--------------]  54% - acc: 0.7578 - loss: 1.7017 - 357.4 sample/sec\n",
      "Global step:  3349 - [================>-------------]  56% - acc: 0.8281 - loss: 1.6408 - 364.2 sample/sec\n",
      "Global step:  3359 - [=================>------------]  59% - acc: 0.7734 - loss: 1.6868 - 365.9 sample/sec\n",
      "Global step:  3369 - [=================>------------]  61% - acc: 0.7109 - loss: 1.7544 - 361.8 sample/sec\n",
      "Global step:  3379 - [==================>-----------]  64% - acc: 0.7344 - loss: 1.7283 - 370.4 sample/sec\n",
      "Global step:  3389 - [===================>----------]  66% - acc: 0.7500 - loss: 1.7216 - 365.5 sample/sec\n",
      "Global step:  3399 - [====================>---------]  69% - acc: 0.7344 - loss: 1.7281 - 373.7 sample/sec\n",
      "Global step:  3409 - [====================>---------]  72% - acc: 0.7969 - loss: 1.6742 - 310.9 sample/sec\n",
      "Global step:  3419 - [=====================>--------]  74% - acc: 0.7734 - loss: 1.6789 - 335.3 sample/sec\n",
      "Global step:  3429 - [======================>-------]  77% - acc: 0.8047 - loss: 1.6580 - 379.0 sample/sec\n",
      "Global step:  3439 - [======================>-------]  79% - acc: 0.7422 - loss: 1.7190 - 368.4 sample/sec\n",
      "Global step:  3449 - [=======================>------]  82% - acc: 0.7500 - loss: 1.7131 - 376.5 sample/sec\n",
      "Global step:  3459 - [========================>-----]  84% - acc: 0.8438 - loss: 1.6147 - 358.5 sample/sec\n",
      "Global step:  3469 - [=========================>----]  87% - acc: 0.7734 - loss: 1.6881 - 372.2 sample/sec\n",
      "Global step:  3479 - [==========================>---]  90% - acc: 0.7578 - loss: 1.6965 - 302.5 sample/sec\n",
      "Global step:  3489 - [==========================>---]  92% - acc: 0.8359 - loss: 1.6311 - 363.8 sample/sec\n",
      "Global step:  3499 - [===========================>--]  95% - acc: 0.7734 - loss: 1.6969 - 361.0 sample/sec\n",
      "Global step:  3509 - [============================>-]  97% - acc: 0.7812 - loss: 1.6726 - 370.5 sample/sec\n",
      "Global step:  3519 - [=============================>] 100% - acc: 0.7375 - loss: 1.7146 - 581.2 sample/sec\n",
      "\n",
      "Epoch 9 - accuracy: 70.88% (7088/10000) - time: 00:02:31.81\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 10/60\n",
      "\n",
      "Global step:  3520 - [>-----------------------------]   0% - acc: 0.7656 - loss: 1.6862 - 360.8 sample/sec\n",
      "Global step:  3530 - [>-----------------------------]   3% - acc: 0.7656 - loss: 1.6874 - 338.6 sample/sec\n",
      "Global step:  3540 - [=>----------------------------]   5% - acc: 0.8203 - loss: 1.6369 - 338.9 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  3550 - [==>---------------------------]   8% - acc: 0.7734 - loss: 1.6906 - 342.6 sample/sec\n",
      "Global step:  3560 - [==>---------------------------]  10% - acc: 0.7656 - loss: 1.7037 - 329.2 sample/sec\n",
      "Global step:  3570 - [===>--------------------------]  13% - acc: 0.7891 - loss: 1.6702 - 332.9 sample/sec\n",
      "Global step:  3580 - [====>-------------------------]  15% - acc: 0.7578 - loss: 1.7036 - 295.2 sample/sec\n",
      "Global step:  3590 - [=====>------------------------]  18% - acc: 0.7734 - loss: 1.6847 - 354.1 sample/sec\n",
      "Global step:  3600 - [=====>------------------------]  20% - acc: 0.8125 - loss: 1.6532 - 353.2 sample/sec\n",
      "Global step:  3610 - [======>-----------------------]  23% - acc: 0.8203 - loss: 1.6495 - 371.4 sample/sec\n",
      "Global step:  3620 - [=======>----------------------]  26% - acc: 0.7969 - loss: 1.6669 - 369.6 sample/sec\n",
      "Global step:  3630 - [========>---------------------]  28% - acc: 0.7344 - loss: 1.7171 - 359.8 sample/sec\n",
      "Global step:  3640 - [========>---------------------]  31% - acc: 0.8750 - loss: 1.6036 - 348.3 sample/sec\n",
      "Global step:  3650 - [=========>--------------------]  33% - acc: 0.7734 - loss: 1.6849 - 378.5 sample/sec\n",
      "Global step:  3660 - [==========>-------------------]  36% - acc: 0.7969 - loss: 1.6637 - 370.7 sample/sec\n",
      "Global step:  3670 - [===========>------------------]  38% - acc: 0.8047 - loss: 1.6617 - 363.8 sample/sec\n",
      "Global step:  3680 - [===========>------------------]  41% - acc: 0.8047 - loss: 1.6643 - 366.2 sample/sec\n",
      "Global step:  3690 - [============>-----------------]  43% - acc: 0.8125 - loss: 1.6596 - 364.0 sample/sec\n",
      "Global step:  3700 - [=============>----------------]  46% - acc: 0.8125 - loss: 1.6562 - 365.2 sample/sec\n",
      "Global step:  3710 - [==============>---------------]  49% - acc: 0.8125 - loss: 1.6624 - 369.9 sample/sec\n",
      "Global step:  3720 - [==============>---------------]  51% - acc: 0.6953 - loss: 1.7654 - 361.3 sample/sec\n",
      "Global step:  3730 - [===============>--------------]  54% - acc: 0.7500 - loss: 1.7015 - 367.1 sample/sec\n",
      "Global step:  3740 - [================>-------------]  56% - acc: 0.8438 - loss: 1.6300 - 378.4 sample/sec\n",
      "Global step:  3750 - [=================>------------]  59% - acc: 0.8047 - loss: 1.6652 - 357.5 sample/sec\n",
      "Global step:  3760 - [=================>------------]  61% - acc: 0.7656 - loss: 1.6938 - 330.2 sample/sec\n",
      "Global step:  3770 - [==================>-----------]  64% - acc: 0.7266 - loss: 1.7260 - 359.4 sample/sec\n",
      "Global step:  3780 - [===================>----------]  66% - acc: 0.7656 - loss: 1.6861 - 333.4 sample/sec\n",
      "Global step:  3790 - [====================>---------]  69% - acc: 0.7500 - loss: 1.7090 - 317.0 sample/sec\n",
      "Global step:  3800 - [====================>---------]  72% - acc: 0.7969 - loss: 1.6527 - 342.6 sample/sec\n",
      "Global step:  3810 - [=====================>--------]  74% - acc: 0.7422 - loss: 1.7203 - 305.5 sample/sec\n",
      "Global step:  3820 - [======================>-------]  77% - acc: 0.7734 - loss: 1.6820 - 373.8 sample/sec\n",
      "Global step:  3830 - [======================>-------]  79% - acc: 0.7109 - loss: 1.7446 - 369.9 sample/sec\n",
      "Global step:  3840 - [=======================>------]  82% - acc: 0.7422 - loss: 1.7131 - 369.0 sample/sec\n",
      "Global step:  3850 - [========================>-----]  84% - acc: 0.8203 - loss: 1.6391 - 373.2 sample/sec\n",
      "Global step:  3860 - [=========================>----]  87% - acc: 0.7734 - loss: 1.6905 - 376.2 sample/sec\n",
      "Global step:  3870 - [==========================>---]  90% - acc: 0.7578 - loss: 1.7066 - 367.8 sample/sec\n",
      "Global step:  3880 - [==========================>---]  92% - acc: 0.8203 - loss: 1.6449 - 309.9 sample/sec\n",
      "Global step:  3890 - [===========================>--]  95% - acc: 0.7656 - loss: 1.6957 - 286.3 sample/sec\n",
      "Global step:  3900 - [============================>-]  97% - acc: 0.7734 - loss: 1.6879 - 360.7 sample/sec\n",
      "Global step:  3910 - [=============================>] 100% - acc: 0.8000 - loss: 1.6524 - 575.2 sample/sec\n",
      "\n",
      "Epoch 10 - accuracy: 73.44% (7344/10000) - time: 00:02:32.82\n",
      "This epoch receive better accuracy: 73.44 > 71.85. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 11/60\n",
      "\n",
      "Global step:  3911 - [>-----------------------------]   0% - acc: 0.8438 - loss: 1.6278 - 346.0 sample/sec\n",
      "Global step:  3921 - [>-----------------------------]   3% - acc: 0.7969 - loss: 1.6663 - 339.3 sample/sec\n",
      "Global step:  3931 - [=>----------------------------]   5% - acc: 0.8594 - loss: 1.5984 - 346.5 sample/sec\n",
      "Global step:  3941 - [==>---------------------------]   8% - acc: 0.8047 - loss: 1.6523 - 349.9 sample/sec\n",
      "Global step:  3951 - [==>---------------------------]  10% - acc: 0.8125 - loss: 1.6532 - 353.9 sample/sec\n",
      "Global step:  3961 - [===>--------------------------]  13% - acc: 0.8125 - loss: 1.6527 - 363.8 sample/sec\n",
      "Global step:  3971 - [====>-------------------------]  15% - acc: 0.7812 - loss: 1.6788 - 377.2 sample/sec\n",
      "Global step:  3981 - [=====>------------------------]  18% - acc: 0.7578 - loss: 1.6958 - 372.1 sample/sec\n",
      "Global step:  3991 - [=====>------------------------]  20% - acc: 0.8594 - loss: 1.6049 - 370.2 sample/sec\n",
      "Global step:  4001 - [======>-----------------------]  23% - acc: 0.8516 - loss: 1.6113 - 385.2 sample/sec\n",
      "Global step:  4011 - [=======>----------------------]  26% - acc: 0.8203 - loss: 1.6446 - 373.0 sample/sec\n",
      "Global step:  4021 - [========>---------------------]  28% - acc: 0.7500 - loss: 1.7150 - 372.6 sample/sec\n",
      "Global step:  4031 - [========>---------------------]  31% - acc: 0.8438 - loss: 1.6152 - 373.3 sample/sec\n",
      "Global step:  4041 - [=========>--------------------]  33% - acc: 0.8125 - loss: 1.6541 - 363.4 sample/sec\n",
      "Global step:  4051 - [==========>-------------------]  36% - acc: 0.8125 - loss: 1.6560 - 375.3 sample/sec\n",
      "Global step:  4061 - [===========>------------------]  38% - acc: 0.7812 - loss: 1.6778 - 367.9 sample/sec\n",
      "Global step:  4071 - [===========>------------------]  41% - acc: 0.8203 - loss: 1.6418 - 376.8 sample/sec\n",
      "Global step:  4081 - [============>-----------------]  43% - acc: 0.8281 - loss: 1.6306 - 350.7 sample/sec\n",
      "Global step:  4091 - [=============>----------------]  46% - acc: 0.8047 - loss: 1.6540 - 319.4 sample/sec\n",
      "Global step:  4101 - [==============>---------------]  49% - acc: 0.7812 - loss: 1.6879 - 347.6 sample/sec\n",
      "Global step:  4111 - [==============>---------------]  51% - acc: 0.7422 - loss: 1.7200 - 369.9 sample/sec\n",
      "Global step:  4121 - [===============>--------------]  54% - acc: 0.7500 - loss: 1.7149 - 356.7 sample/sec\n",
      "Global step:  4131 - [================>-------------]  56% - acc: 0.8594 - loss: 1.5872 - 355.8 sample/sec\n",
      "Global step:  4141 - [=================>------------]  59% - acc: 0.7812 - loss: 1.6695 - 314.9 sample/sec\n",
      "Global step:  4151 - [=================>------------]  61% - acc: 0.7734 - loss: 1.6804 - 324.6 sample/sec\n",
      "Global step:  4161 - [==================>-----------]  64% - acc: 0.7656 - loss: 1.6872 - 352.3 sample/sec\n",
      "Global step:  4171 - [===================>----------]  66% - acc: 0.7891 - loss: 1.6745 - 371.0 sample/sec\n",
      "Global step:  4181 - [====================>---------]  69% - acc: 0.7969 - loss: 1.6596 - 353.3 sample/sec\n",
      "Global step:  4191 - [====================>---------]  72% - acc: 0.8203 - loss: 1.6441 - 306.8 sample/sec\n",
      "Global step:  4201 - [=====================>--------]  74% - acc: 0.8281 - loss: 1.6380 - 264.0 sample/sec\n",
      "Global step:  4211 - [======================>-------]  77% - acc: 0.8047 - loss: 1.6501 - 310.0 sample/sec\n",
      "Global step:  4221 - [======================>-------]  79% - acc: 0.7422 - loss: 1.7288 - 257.0 sample/sec\n",
      "Global step:  4231 - [=======================>------]  82% - acc: 0.7188 - loss: 1.7243 - 264.7 sample/sec\n",
      "Global step:  4241 - [========================>-----]  84% - acc: 0.8828 - loss: 1.5789 - 218.7 sample/sec\n",
      "Global step:  4251 - [=========================>----]  87% - acc: 0.7891 - loss: 1.6733 - 242.6 sample/sec\n",
      "Global step:  4261 - [==========================>---]  90% - acc: 0.7344 - loss: 1.7196 - 222.0 sample/sec\n",
      "Global step:  4271 - [==========================>---]  92% - acc: 0.8672 - loss: 1.6040 - 288.1 sample/sec\n",
      "Global step:  4281 - [===========================>--]  95% - acc: 0.8203 - loss: 1.6395 - 212.6 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  4291 - [============================>-]  97% - acc: 0.8047 - loss: 1.6621 - 197.1 sample/sec\n",
      "Global step:  4301 - [=============================>] 100% - acc: 0.7875 - loss: 1.6758 - 381.7 sample/sec\n",
      "\n",
      "Epoch 11 - accuracy: 72.84% (7284/10000) - time: 00:02:55.99\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 12/60\n",
      "\n",
      "Global step:  4302 - [>-----------------------------]   0% - acc: 0.8203 - loss: 1.6384 - 236.5 sample/sec\n",
      "Global step:  4312 - [>-----------------------------]   3% - acc: 0.8359 - loss: 1.6300 - 220.8 sample/sec\n",
      "Global step:  4322 - [=>----------------------------]   5% - acc: 0.9062 - loss: 1.5682 - 205.2 sample/sec\n",
      "Global step:  4332 - [==>---------------------------]   8% - acc: 0.8125 - loss: 1.6493 - 217.4 sample/sec\n",
      "Global step:  4342 - [==>---------------------------]  10% - acc: 0.8047 - loss: 1.6540 - 199.0 sample/sec\n",
      "Global step:  4352 - [===>--------------------------]  13% - acc: 0.8438 - loss: 1.6112 - 211.8 sample/sec\n",
      "Global step:  4362 - [====>-------------------------]  15% - acc: 0.8281 - loss: 1.6363 - 209.9 sample/sec\n",
      "Global step:  4372 - [=====>------------------------]  18% - acc: 0.7891 - loss: 1.6737 - 258.2 sample/sec\n",
      "Global step:  4382 - [=====>------------------------]  20% - acc: 0.8203 - loss: 1.6311 - 213.0 sample/sec\n",
      "Global step:  4392 - [======>-----------------------]  23% - acc: 0.8438 - loss: 1.6199 - 214.9 sample/sec\n",
      "Global step:  4402 - [=======>----------------------]  26% - acc: 0.8281 - loss: 1.6371 - 225.4 sample/sec\n",
      "Global step:  4412 - [========>---------------------]  28% - acc: 0.7812 - loss: 1.6661 - 244.3 sample/sec\n",
      "Global step:  4422 - [========>---------------------]  31% - acc: 0.8516 - loss: 1.6100 - 219.1 sample/sec\n",
      "Global step:  4432 - [=========>--------------------]  33% - acc: 0.7969 - loss: 1.6686 - 211.7 sample/sec\n",
      "Global step:  4442 - [==========>-------------------]  36% - acc: 0.8047 - loss: 1.6490 - 245.0 sample/sec\n",
      "Global step:  4452 - [===========>------------------]  38% - acc: 0.8203 - loss: 1.6473 - 188.3 sample/sec\n",
      "Global step:  4462 - [===========>------------------]  41% - acc: 0.8203 - loss: 1.6476 - 198.3 sample/sec\n",
      "Global step:  4472 - [============>-----------------]  43% - acc: 0.8281 - loss: 1.6302 - 235.9 sample/sec\n",
      "Global step:  4482 - [=============>----------------]  46% - acc: 0.8047 - loss: 1.6586 - 202.1 sample/sec\n",
      "Global step:  4492 - [==============>---------------]  49% - acc: 0.7969 - loss: 1.6651 - 222.0 sample/sec\n",
      "Global step:  4502 - [==============>---------------]  51% - acc: 0.7891 - loss: 1.6915 - 268.3 sample/sec\n",
      "Global step:  4512 - [===============>--------------]  54% - acc: 0.8047 - loss: 1.6597 - 216.4 sample/sec\n",
      "Global step:  4522 - [================>-------------]  56% - acc: 0.8594 - loss: 1.6059 - 208.3 sample/sec\n",
      "Global step:  4532 - [=================>------------]  59% - acc: 0.7969 - loss: 1.6638 - 175.6 sample/sec\n",
      "Global step:  4542 - [=================>------------]  61% - acc: 0.7891 - loss: 1.6710 - 197.8 sample/sec\n",
      "Global step:  4552 - [==================>-----------]  64% - acc: 0.7969 - loss: 1.6691 - 178.9 sample/sec\n",
      "Global step:  4562 - [===================>----------]  66% - acc: 0.8047 - loss: 1.6630 - 208.4 sample/sec\n",
      "Global step:  4572 - [====================>---------]  69% - acc: 0.7500 - loss: 1.7185 - 202.2 sample/sec\n",
      "Global step:  4582 - [====================>---------]  72% - acc: 0.8594 - loss: 1.6161 - 223.4 sample/sec\n",
      "Global step:  4592 - [=====================>--------]  74% - acc: 0.7812 - loss: 1.6730 - 258.9 sample/sec\n",
      "Global step:  4602 - [======================>-------]  77% - acc: 0.7969 - loss: 1.6624 - 221.1 sample/sec\n",
      "Global step:  4612 - [======================>-------]  79% - acc: 0.7656 - loss: 1.6948 - 193.0 sample/sec\n",
      "Global step:  4622 - [=======================>------]  82% - acc: 0.7656 - loss: 1.6862 - 207.9 sample/sec\n",
      "Global step:  4632 - [========================>-----]  84% - acc: 0.8516 - loss: 1.6014 - 206.7 sample/sec\n",
      "Global step:  4642 - [=========================>----]  87% - acc: 0.7500 - loss: 1.7090 - 256.1 sample/sec\n",
      "Global step:  4652 - [==========================>---]  90% - acc: 0.8125 - loss: 1.6437 - 266.9 sample/sec\n",
      "Global step:  4662 - [==========================>---]  92% - acc: 0.8438 - loss: 1.6211 - 215.0 sample/sec\n",
      "Global step:  4672 - [===========================>--]  95% - acc: 0.8047 - loss: 1.6565 - 236.4 sample/sec\n",
      "Global step:  4682 - [============================>-]  97% - acc: 0.8359 - loss: 1.6300 - 263.3 sample/sec\n",
      "Global step:  4692 - [=============================>] 100% - acc: 0.8500 - loss: 1.6154 - 290.4 sample/sec\n",
      "\n",
      "Epoch 12 - accuracy: 73.88% (7388/10000) - time: 00:04:05.67\n",
      "This epoch receive better accuracy: 73.88 > 73.44. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 13/60\n",
      "\n",
      "Global step:  4693 - [>-----------------------------]   0% - acc: 0.7969 - loss: 1.6651 - 241.3 sample/sec\n",
      "Global step:  4703 - [>-----------------------------]   3% - acc: 0.7969 - loss: 1.6692 - 192.1 sample/sec\n",
      "Global step:  4713 - [=>----------------------------]   5% - acc: 0.8750 - loss: 1.5834 - 256.4 sample/sec\n",
      "Global step:  4723 - [==>---------------------------]   8% - acc: 0.8672 - loss: 1.6087 - 201.1 sample/sec\n",
      "Global step:  4733 - [==>---------------------------]  10% - acc: 0.8047 - loss: 1.6555 - 195.5 sample/sec\n",
      "Global step:  4743 - [===>--------------------------]  13% - acc: 0.8359 - loss: 1.6234 - 196.0 sample/sec\n",
      "Global step:  4753 - [====>-------------------------]  15% - acc: 0.8203 - loss: 1.6443 - 210.0 sample/sec\n",
      "Global step:  4763 - [=====>------------------------]  18% - acc: 0.8125 - loss: 1.6474 - 201.0 sample/sec\n",
      "Global step:  4773 - [=====>------------------------]  20% - acc: 0.8594 - loss: 1.6026 - 225.2 sample/sec\n",
      "Global step:  4783 - [======>-----------------------]  23% - acc: 0.8672 - loss: 1.6051 - 186.0 sample/sec\n",
      "Global step:  4793 - [=======>----------------------]  26% - acc: 0.8438 - loss: 1.6066 - 310.2 sample/sec\n",
      "Global step:  4803 - [========>---------------------]  28% - acc: 0.8125 - loss: 1.6584 - 287.0 sample/sec\n",
      "Global step:  4813 - [========>---------------------]  31% - acc: 0.8984 - loss: 1.5709 - 340.0 sample/sec\n",
      "Global step:  4823 - [=========>--------------------]  33% - acc: 0.8047 - loss: 1.6592 - 342.5 sample/sec\n",
      "Global step:  4833 - [==========>-------------------]  36% - acc: 0.8359 - loss: 1.6289 - 347.9 sample/sec\n",
      "Global step:  4843 - [===========>------------------]  38% - acc: 0.8203 - loss: 1.6325 - 349.7 sample/sec\n",
      "Global step:  4853 - [===========>------------------]  41% - acc: 0.8203 - loss: 1.6377 - 350.2 sample/sec\n",
      "Global step:  4863 - [============>-----------------]  43% - acc: 0.8281 - loss: 1.6353 - 346.7 sample/sec\n",
      "Global step:  4873 - [=============>----------------]  46% - acc: 0.8359 - loss: 1.6244 - 355.6 sample/sec\n",
      "Global step:  4883 - [==============>---------------]  49% - acc: 0.8203 - loss: 1.6472 - 375.7 sample/sec\n",
      "Global step:  4893 - [==============>---------------]  51% - acc: 0.7812 - loss: 1.6802 - 372.5 sample/sec\n",
      "Global step:  4903 - [===============>--------------]  54% - acc: 0.8281 - loss: 1.6366 - 372.5 sample/sec\n",
      "Global step:  4913 - [================>-------------]  56% - acc: 0.8594 - loss: 1.5929 - 374.4 sample/sec\n",
      "Global step:  4923 - [=================>------------]  59% - acc: 0.7969 - loss: 1.6595 - 367.0 sample/sec\n",
      "Global step:  4933 - [=================>------------]  61% - acc: 0.8047 - loss: 1.6540 - 376.5 sample/sec\n",
      "Global step:  4943 - [==================>-----------]  64% - acc: 0.8203 - loss: 1.6440 - 367.2 sample/sec\n",
      "Global step:  4953 - [===================>----------]  66% - acc: 0.8359 - loss: 1.6271 - 371.5 sample/sec\n",
      "Global step:  4963 - [====================>---------]  69% - acc: 0.7969 - loss: 1.6561 - 362.8 sample/sec\n",
      "Global step:  4973 - [====================>---------]  72% - acc: 0.8594 - loss: 1.6039 - 375.0 sample/sec\n",
      "Global step:  4983 - [=====================>--------]  74% - acc: 0.8359 - loss: 1.6205 - 371.5 sample/sec\n",
      "Global step:  4993 - [======================>-------]  77% - acc: 0.7656 - loss: 1.6913 - 352.7 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  5003 - [======================>-------]  79% - acc: 0.7188 - loss: 1.7326 - 292.5 sample/sec\n",
      "Global step:  5013 - [=======================>------]  82% - acc: 0.8281 - loss: 1.6376 - 267.4 sample/sec\n",
      "Global step:  5023 - [========================>-----]  84% - acc: 0.8906 - loss: 1.5753 - 274.1 sample/sec\n",
      "Global step:  5033 - [=========================>----]  87% - acc: 0.8281 - loss: 1.6432 - 279.8 sample/sec\n",
      "Global step:  5043 - [==========================>---]  90% - acc: 0.8438 - loss: 1.6215 - 276.7 sample/sec\n",
      "Global step:  5053 - [==========================>---]  92% - acc: 0.8984 - loss: 1.5667 - 285.3 sample/sec\n",
      "Global step:  5063 - [===========================>--]  95% - acc: 0.8359 - loss: 1.6198 - 282.1 sample/sec\n",
      "Global step:  5073 - [============================>-]  97% - acc: 0.8359 - loss: 1.6337 - 298.7 sample/sec\n",
      "Global step:  5083 - [=============================>] 100% - acc: 0.8625 - loss: 1.6049 - 506.7 sample/sec\n",
      "\n",
      "Epoch 13 - accuracy: 73.94% (7394/10000) - time: 00:03:06.70\n",
      "This epoch receive better accuracy: 73.94 > 73.88. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 14/60\n",
      "\n",
      "Global step:  5084 - [>-----------------------------]   0% - acc: 0.8203 - loss: 1.6395 - 299.9 sample/sec\n",
      "Global step:  5094 - [>-----------------------------]   3% - acc: 0.8438 - loss: 1.6220 - 320.1 sample/sec\n",
      "Global step:  5104 - [=>----------------------------]   5% - acc: 0.8906 - loss: 1.5730 - 315.0 sample/sec\n",
      "Global step:  5114 - [==>---------------------------]   8% - acc: 0.8672 - loss: 1.5927 - 310.7 sample/sec\n",
      "Global step:  5124 - [==>---------------------------]  10% - acc: 0.8828 - loss: 1.5829 - 319.5 sample/sec\n",
      "Global step:  5134 - [===>--------------------------]  13% - acc: 0.8594 - loss: 1.6049 - 338.1 sample/sec\n",
      "Global step:  5144 - [====>-------------------------]  15% - acc: 0.8359 - loss: 1.6258 - 335.5 sample/sec\n",
      "Global step:  5154 - [=====>------------------------]  18% - acc: 0.8125 - loss: 1.6439 - 320.4 sample/sec\n",
      "Global step:  5164 - [=====>------------------------]  20% - acc: 0.8438 - loss: 1.6147 - 304.9 sample/sec\n",
      "Global step:  5174 - [======>-----------------------]  23% - acc: 0.8359 - loss: 1.6234 - 339.1 sample/sec\n",
      "Global step:  5184 - [=======>----------------------]  26% - acc: 0.8594 - loss: 1.5931 - 340.0 sample/sec\n",
      "Global step:  5194 - [========>---------------------]  28% - acc: 0.8203 - loss: 1.6445 - 327.0 sample/sec\n",
      "Global step:  5204 - [========>---------------------]  31% - acc: 0.8828 - loss: 1.5800 - 323.3 sample/sec\n",
      "Global step:  5214 - [=========>--------------------]  33% - acc: 0.8281 - loss: 1.6332 - 315.6 sample/sec\n",
      "Global step:  5224 - [==========>-------------------]  36% - acc: 0.7812 - loss: 1.6738 - 322.2 sample/sec\n",
      "Global step:  5234 - [===========>------------------]  38% - acc: 0.8594 - loss: 1.5989 - 307.4 sample/sec\n",
      "Global step:  5244 - [===========>------------------]  41% - acc: 0.8594 - loss: 1.6004 - 310.7 sample/sec\n",
      "Global step:  5254 - [============>-----------------]  43% - acc: 0.8672 - loss: 1.5976 - 314.1 sample/sec\n",
      "Global step:  5264 - [=============>----------------]  46% - acc: 0.8203 - loss: 1.6343 - 309.4 sample/sec\n",
      "Global step:  5274 - [==============>---------------]  49% - acc: 0.8438 - loss: 1.6219 - 303.1 sample/sec\n",
      "Global step:  5284 - [==============>---------------]  51% - acc: 0.8047 - loss: 1.6556 - 306.6 sample/sec\n",
      "Global step:  5294 - [===============>--------------]  54% - acc: 0.8281 - loss: 1.6337 - 309.1 sample/sec\n",
      "Global step:  5304 - [================>-------------]  56% - acc: 0.8828 - loss: 1.5822 - 308.0 sample/sec\n",
      "Global step:  5314 - [=================>------------]  59% - acc: 0.8047 - loss: 1.6485 - 322.7 sample/sec\n",
      "Global step:  5324 - [=================>------------]  61% - acc: 0.7812 - loss: 1.6808 - 322.1 sample/sec\n",
      "Global step:  5334 - [==================>-----------]  64% - acc: 0.8125 - loss: 1.6504 - 332.0 sample/sec\n",
      "Global step:  5344 - [===================>----------]  66% - acc: 0.7969 - loss: 1.6591 - 321.9 sample/sec\n",
      "Global step:  5354 - [====================>---------]  69% - acc: 0.7734 - loss: 1.6784 - 333.7 sample/sec\n",
      "Global step:  5364 - [====================>---------]  72% - acc: 0.8672 - loss: 1.5923 - 338.6 sample/sec\n",
      "Global step:  5374 - [=====================>--------]  74% - acc: 0.8438 - loss: 1.6195 - 337.4 sample/sec\n",
      "Global step:  5384 - [======================>-------]  77% - acc: 0.8281 - loss: 1.6384 - 343.4 sample/sec\n",
      "Global step:  5394 - [======================>-------]  79% - acc: 0.7500 - loss: 1.7111 - 333.9 sample/sec\n",
      "Global step:  5404 - [=======================>------]  82% - acc: 0.8047 - loss: 1.6535 - 328.7 sample/sec\n",
      "Global step:  5414 - [========================>-----]  84% - acc: 0.9141 - loss: 1.5523 - 315.4 sample/sec\n",
      "Global step:  5424 - [=========================>----]  87% - acc: 0.7891 - loss: 1.6677 - 303.1 sample/sec\n",
      "Global step:  5434 - [==========================>---]  90% - acc: 0.8359 - loss: 1.6201 - 317.2 sample/sec\n",
      "Global step:  5444 - [==========================>---]  92% - acc: 0.8672 - loss: 1.5950 - 322.2 sample/sec\n",
      "Global step:  5454 - [===========================>--]  95% - acc: 0.8516 - loss: 1.6108 - 299.3 sample/sec\n",
      "Global step:  5464 - [============================>-]  97% - acc: 0.8438 - loss: 1.6197 - 293.5 sample/sec\n",
      "Global step:  5474 - [=============================>] 100% - acc: 0.8375 - loss: 1.6260 - 454.3 sample/sec\n",
      "\n",
      "Epoch 14 - accuracy: 74.09% (7409/10000) - time: 00:02:48.90\n",
      "This epoch receive better accuracy: 74.09 > 73.94. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 15/60\n",
      "\n",
      "Global step:  5475 - [>-----------------------------]   0% - acc: 0.8672 - loss: 1.5873 - 281.6 sample/sec\n",
      "Global step:  5485 - [>-----------------------------]   3% - acc: 0.8359 - loss: 1.6254 - 278.5 sample/sec\n",
      "Global step:  5495 - [=>----------------------------]   5% - acc: 0.8750 - loss: 1.5954 - 285.9 sample/sec\n",
      "Global step:  5505 - [==>---------------------------]   8% - acc: 0.8672 - loss: 1.5945 - 290.3 sample/sec\n",
      "Global step:  5515 - [==>---------------------------]  10% - acc: 0.8203 - loss: 1.6441 - 286.9 sample/sec\n",
      "Global step:  5525 - [===>--------------------------]  13% - acc: 0.8438 - loss: 1.6039 - 291.0 sample/sec\n",
      "Global step:  5535 - [====>-------------------------]  15% - acc: 0.8516 - loss: 1.6098 - 302.6 sample/sec\n",
      "Global step:  5545 - [=====>------------------------]  18% - acc: 0.8906 - loss: 1.5783 - 306.8 sample/sec\n",
      "Global step:  5555 - [=====>------------------------]  20% - acc: 0.8672 - loss: 1.5832 - 298.7 sample/sec\n",
      "Global step:  5565 - [======>-----------------------]  23% - acc: 0.9062 - loss: 1.5612 - 311.4 sample/sec\n",
      "Global step:  5575 - [=======>----------------------]  26% - acc: 0.8828 - loss: 1.5799 - 307.6 sample/sec\n",
      "Global step:  5585 - [========>---------------------]  28% - acc: 0.8047 - loss: 1.6642 - 306.3 sample/sec\n",
      "Global step:  5595 - [========>---------------------]  31% - acc: 0.8359 - loss: 1.6169 - 302.6 sample/sec\n",
      "Global step:  5605 - [=========>--------------------]  33% - acc: 0.8125 - loss: 1.6450 - 311.1 sample/sec\n",
      "Global step:  5615 - [==========>-------------------]  36% - acc: 0.7969 - loss: 1.6692 - 322.0 sample/sec\n",
      "Global step:  5625 - [===========>------------------]  38% - acc: 0.8672 - loss: 1.5952 - 321.9 sample/sec\n",
      "Global step:  5635 - [===========>------------------]  41% - acc: 0.8359 - loss: 1.6197 - 331.7 sample/sec\n",
      "Global step:  5645 - [============>-----------------]  43% - acc: 0.8359 - loss: 1.6152 - 345.1 sample/sec\n",
      "Global step:  5655 - [=============>----------------]  46% - acc: 0.8438 - loss: 1.6134 - 356.9 sample/sec\n",
      "Global step:  5665 - [==============>---------------]  49% - acc: 0.8203 - loss: 1.6449 - 346.1 sample/sec\n",
      "Global step:  5675 - [==============>---------------]  51% - acc: 0.7891 - loss: 1.6614 - 362.2 sample/sec\n",
      "Global step:  5685 - [===============>--------------]  54% - acc: 0.8516 - loss: 1.6153 - 358.2 sample/sec\n",
      "Global step:  5695 - [================>-------------]  56% - acc: 0.8672 - loss: 1.5918 - 360.1 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  5705 - [=================>------------]  59% - acc: 0.8516 - loss: 1.6098 - 350.2 sample/sec\n",
      "Global step:  5715 - [=================>------------]  61% - acc: 0.8047 - loss: 1.6538 - 353.6 sample/sec\n",
      "Global step:  5725 - [==================>-----------]  64% - acc: 0.8047 - loss: 1.6521 - 336.5 sample/sec\n",
      "Global step:  5735 - [===================>----------]  66% - acc: 0.8516 - loss: 1.6179 - 321.1 sample/sec\n",
      "Global step:  5745 - [====================>---------]  69% - acc: 0.8438 - loss: 1.6213 - 319.6 sample/sec\n",
      "Global step:  5755 - [====================>---------]  72% - acc: 0.8672 - loss: 1.5972 - 308.9 sample/sec\n",
      "Global step:  5765 - [=====================>--------]  74% - acc: 0.8828 - loss: 1.5817 - 314.9 sample/sec\n",
      "Global step:  5775 - [======================>-------]  77% - acc: 0.8516 - loss: 1.6068 - 303.4 sample/sec\n",
      "Global step:  5785 - [======================>-------]  79% - acc: 0.7812 - loss: 1.6820 - 294.5 sample/sec\n",
      "Global step:  5795 - [=======================>------]  82% - acc: 0.8359 - loss: 1.6220 - 301.1 sample/sec\n",
      "Global step:  5805 - [========================>-----]  84% - acc: 0.9219 - loss: 1.5369 - 325.5 sample/sec\n",
      "Global step:  5815 - [=========================>----]  87% - acc: 0.8047 - loss: 1.6555 - 322.0 sample/sec\n",
      "Global step:  5825 - [==========================>---]  90% - acc: 0.8594 - loss: 1.6031 - 334.8 sample/sec\n",
      "Global step:  5835 - [==========================>---]  92% - acc: 0.8516 - loss: 1.6095 - 343.2 sample/sec\n",
      "Global step:  5845 - [===========================>--]  95% - acc: 0.8359 - loss: 1.6184 - 339.8 sample/sec\n",
      "Global step:  5855 - [============================>-]  97% - acc: 0.8125 - loss: 1.6539 - 346.0 sample/sec\n",
      "Global step:  5865 - [=============================>] 100% - acc: 0.8500 - loss: 1.6098 - 551.4 sample/sec\n",
      "\n",
      "Epoch 15 - accuracy: 75.07% (7507/10000) - time: 00:02:46.65\n",
      "This epoch receive better accuracy: 75.07 > 74.09. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 16/60\n",
      "\n",
      "Global step:  5866 - [>-----------------------------]   0% - acc: 0.9141 - loss: 1.5509 - 337.5 sample/sec\n",
      "Global step:  5876 - [>-----------------------------]   3% - acc: 0.8594 - loss: 1.6052 - 325.7 sample/sec\n",
      "Global step:  5886 - [=>----------------------------]   5% - acc: 0.8906 - loss: 1.5644 - 329.4 sample/sec\n",
      "Global step:  5896 - [==>---------------------------]   8% - acc: 0.8984 - loss: 1.5635 - 312.1 sample/sec\n",
      "Global step:  5906 - [==>---------------------------]  10% - acc: 0.8672 - loss: 1.5883 - 315.8 sample/sec\n",
      "Global step:  5916 - [===>--------------------------]  13% - acc: 0.8828 - loss: 1.5730 - 287.3 sample/sec\n",
      "Global step:  5926 - [====>-------------------------]  15% - acc: 0.8750 - loss: 1.5953 - 297.1 sample/sec\n",
      "Global step:  5936 - [=====>------------------------]  18% - acc: 0.8594 - loss: 1.6056 - 309.0 sample/sec\n",
      "Global step:  5946 - [=====>------------------------]  20% - acc: 0.8828 - loss: 1.5747 - 324.2 sample/sec\n",
      "Global step:  5956 - [======>-----------------------]  23% - acc: 0.8594 - loss: 1.6012 - 321.8 sample/sec\n",
      "Global step:  5966 - [=======>----------------------]  26% - acc: 0.8906 - loss: 1.5719 - 337.8 sample/sec\n",
      "Global step:  5976 - [========>---------------------]  28% - acc: 0.8359 - loss: 1.6187 - 336.4 sample/sec\n",
      "Global step:  5986 - [========>---------------------]  31% - acc: 0.8594 - loss: 1.5998 - 347.2 sample/sec\n",
      "Global step:  5996 - [=========>--------------------]  33% - acc: 0.8281 - loss: 1.6363 - 335.5 sample/sec\n",
      "Global step:  6006 - [==========>-------------------]  36% - acc: 0.8438 - loss: 1.6210 - 321.1 sample/sec\n",
      "Global step:  6016 - [===========>------------------]  38% - acc: 0.8281 - loss: 1.6417 - 329.5 sample/sec\n",
      "Global step:  6026 - [===========>------------------]  41% - acc: 0.8281 - loss: 1.6326 - 320.3 sample/sec\n",
      "Global step:  6036 - [============>-----------------]  43% - acc: 0.8672 - loss: 1.6035 - 329.4 sample/sec\n",
      "Global step:  6046 - [=============>----------------]  46% - acc: 0.8203 - loss: 1.6308 - 328.8 sample/sec\n",
      "Global step:  6056 - [==============>---------------]  49% - acc: 0.8438 - loss: 1.6272 - 312.4 sample/sec\n",
      "Global step:  6066 - [==============>---------------]  51% - acc: 0.8047 - loss: 1.6550 - 327.3 sample/sec\n",
      "Global step:  6076 - [===============>--------------]  54% - acc: 0.8516 - loss: 1.6216 - 311.5 sample/sec\n",
      "Global step:  6086 - [================>-------------]  56% - acc: 0.9062 - loss: 1.5617 - 320.6 sample/sec\n",
      "Global step:  6096 - [=================>------------]  59% - acc: 0.8281 - loss: 1.6331 - 283.4 sample/sec\n",
      "Global step:  6106 - [=================>------------]  61% - acc: 0.8281 - loss: 1.6392 - 250.6 sample/sec\n",
      "Global step:  6116 - [==================>-----------]  64% - acc: 0.8203 - loss: 1.6399 - 272.1 sample/sec\n",
      "Global step:  6126 - [===================>----------]  66% - acc: 0.8203 - loss: 1.6399 - 267.5 sample/sec\n",
      "Global step:  6136 - [====================>---------]  69% - acc: 0.8203 - loss: 1.6326 - 224.1 sample/sec\n",
      "Global step:  6146 - [====================>---------]  72% - acc: 0.8984 - loss: 1.5796 - 215.4 sample/sec\n",
      "Global step:  6156 - [=====================>--------]  74% - acc: 0.8516 - loss: 1.6148 - 180.9 sample/sec\n",
      "Global step:  6166 - [======================>-------]  77% - acc: 0.8672 - loss: 1.5874 - 176.0 sample/sec\n",
      "Global step:  6176 - [======================>-------]  79% - acc: 0.7812 - loss: 1.6725 - 175.2 sample/sec\n",
      "Global step:  6186 - [=======================>------]  82% - acc: 0.8594 - loss: 1.6091 - 208.2 sample/sec\n",
      "Global step:  6196 - [========================>-----]  84% - acc: 0.9062 - loss: 1.5535 - 256.6 sample/sec\n",
      "Global step:  6206 - [=========================>----]  87% - acc: 0.8438 - loss: 1.6182 - 276.3 sample/sec\n",
      "Global step:  6216 - [==========================>---]  90% - acc: 0.8672 - loss: 1.6008 - 269.9 sample/sec\n",
      "Global step:  6226 - [==========================>---]  92% - acc: 0.8906 - loss: 1.5689 - 286.1 sample/sec\n",
      "Global step:  6236 - [===========================>--]  95% - acc: 0.8359 - loss: 1.6268 - 293.5 sample/sec\n",
      "Global step:  6246 - [============================>-]  97% - acc: 0.8281 - loss: 1.6365 - 309.0 sample/sec\n",
      "Global step:  6256 - [=============================>] 100% - acc: 0.8500 - loss: 1.6144 - 505.8 sample/sec\n",
      "\n",
      "Epoch 16 - accuracy: 74.33% (7433/10000) - time: 00:03:08.69\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 17/60\n",
      "\n",
      "Global step:  6257 - [>-----------------------------]   0% - acc: 0.8672 - loss: 1.5949 - 314.6 sample/sec\n",
      "Global step:  6267 - [>-----------------------------]   3% - acc: 0.8672 - loss: 1.5977 - 287.3 sample/sec\n",
      "Global step:  6277 - [=>----------------------------]   5% - acc: 0.9062 - loss: 1.5496 - 290.8 sample/sec\n",
      "Global step:  6287 - [==>---------------------------]   8% - acc: 0.8594 - loss: 1.6003 - 316.4 sample/sec\n",
      "Global step:  6297 - [==>---------------------------]  10% - acc: 0.8828 - loss: 1.5746 - 309.1 sample/sec\n",
      "Global step:  6307 - [===>--------------------------]  13% - acc: 0.8750 - loss: 1.5918 - 283.1 sample/sec\n",
      "Global step:  6317 - [====>-------------------------]  15% - acc: 0.8906 - loss: 1.5750 - 316.6 sample/sec\n",
      "Global step:  6327 - [=====>------------------------]  18% - acc: 0.8359 - loss: 1.6223 - 315.5 sample/sec\n",
      "Global step:  6337 - [=====>------------------------]  20% - acc: 0.8672 - loss: 1.5940 - 326.3 sample/sec\n",
      "Global step:  6347 - [======>-----------------------]  23% - acc: 0.8984 - loss: 1.5591 - 331.8 sample/sec\n",
      "Global step:  6357 - [=======>----------------------]  26% - acc: 0.8828 - loss: 1.5723 - 333.5 sample/sec\n",
      "Global step:  6367 - [========>---------------------]  28% - acc: 0.8359 - loss: 1.6290 - 293.0 sample/sec\n",
      "Global step:  6377 - [========>---------------------]  31% - acc: 0.8906 - loss: 1.5678 - 261.1 sample/sec\n",
      "Global step:  6387 - [=========>--------------------]  33% - acc: 0.8047 - loss: 1.6540 - 215.7 sample/sec\n",
      "Global step:  6397 - [==========>-------------------]  36% - acc: 0.8359 - loss: 1.6174 - 218.4 sample/sec\n",
      "Global step:  6407 - [===========>------------------]  38% - acc: 0.8906 - loss: 1.5726 - 185.5 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  6417 - [===========>------------------]  41% - acc: 0.8906 - loss: 1.5733 - 164.1 sample/sec\n",
      "Global step:  6427 - [============>-----------------]  43% - acc: 0.8438 - loss: 1.6231 - 170.4 sample/sec\n",
      "Global step:  6437 - [=============>----------------]  46% - acc: 0.8594 - loss: 1.6026 - 209.0 sample/sec\n",
      "Global step:  6447 - [==============>---------------]  49% - acc: 0.8750 - loss: 1.5882 - 209.5 sample/sec\n",
      "Global step:  6457 - [==============>---------------]  51% - acc: 0.8047 - loss: 1.6620 - 202.6 sample/sec\n",
      "Global step:  6467 - [===============>--------------]  54% - acc: 0.8125 - loss: 1.6450 - 204.5 sample/sec\n",
      "Global step:  6477 - [================>-------------]  56% - acc: 0.9062 - loss: 1.5567 - 233.0 sample/sec\n",
      "Global step:  6487 - [=================>------------]  59% - acc: 0.8594 - loss: 1.5996 - 248.5 sample/sec\n",
      "Global step:  6497 - [=================>------------]  61% - acc: 0.7812 - loss: 1.6695 - 268.1 sample/sec\n",
      "Global step:  6507 - [==================>-----------]  64% - acc: 0.7969 - loss: 1.6690 - 288.4 sample/sec\n",
      "Global step:  6517 - [===================>----------]  66% - acc: 0.8047 - loss: 1.6546 - 280.3 sample/sec\n",
      "Global step:  6527 - [====================>---------]  69% - acc: 0.8125 - loss: 1.6411 - 288.4 sample/sec\n",
      "Global step:  6537 - [====================>---------]  72% - acc: 0.8438 - loss: 1.6169 - 283.1 sample/sec\n",
      "Global step:  6547 - [=====================>--------]  74% - acc: 0.8828 - loss: 1.5835 - 283.4 sample/sec\n",
      "Global step:  6557 - [======================>-------]  77% - acc: 0.8516 - loss: 1.6076 - 238.8 sample/sec\n",
      "Global step:  6567 - [======================>-------]  79% - acc: 0.7734 - loss: 1.6812 - 237.7 sample/sec\n",
      "Global step:  6577 - [=======================>------]  82% - acc: 0.8672 - loss: 1.5916 - 219.6 sample/sec\n",
      "Global step:  6587 - [========================>-----]  84% - acc: 0.9219 - loss: 1.5532 - 213.1 sample/sec\n",
      "Global step:  6597 - [=========================>----]  87% - acc: 0.8125 - loss: 1.6519 - 203.5 sample/sec\n",
      "Global step:  6607 - [==========================>---]  90% - acc: 0.8750 - loss: 1.5916 - 244.2 sample/sec\n",
      "Global step:  6617 - [==========================>---]  92% - acc: 0.8516 - loss: 1.6116 - 262.0 sample/sec\n",
      "Global step:  6627 - [===========================>--]  95% - acc: 0.8516 - loss: 1.6156 - 277.1 sample/sec\n",
      "Global step:  6637 - [============================>-]  97% - acc: 0.8359 - loss: 1.6249 - 295.7 sample/sec\n",
      "Global step:  6647 - [=============================>] 100% - acc: 0.8750 - loss: 1.5843 - 447.1 sample/sec\n",
      "\n",
      "Epoch 17 - accuracy: 75.65% (7565/10000) - time: 00:03:33.70\n",
      "This epoch receive better accuracy: 75.65 > 75.07. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 18/60\n",
      "\n",
      "Global step:  6648 - [>-----------------------------]   0% - acc: 0.8828 - loss: 1.5754 - 249.0 sample/sec\n",
      "Global step:  6658 - [>-----------------------------]   3% - acc: 0.8750 - loss: 1.5844 - 241.7 sample/sec\n",
      "Global step:  6668 - [=>----------------------------]   5% - acc: 0.8750 - loss: 1.5829 - 235.5 sample/sec\n",
      "Global step:  6678 - [==>---------------------------]   8% - acc: 0.8672 - loss: 1.5976 - 261.4 sample/sec\n",
      "Global step:  6688 - [==>---------------------------]  10% - acc: 0.8906 - loss: 1.5763 - 239.4 sample/sec\n",
      "Global step:  6698 - [===>--------------------------]  13% - acc: 0.8203 - loss: 1.6324 - 248.9 sample/sec\n",
      "Global step:  6708 - [====>-------------------------]  15% - acc: 0.8750 - loss: 1.5874 - 239.2 sample/sec\n",
      "Global step:  6718 - [=====>------------------------]  18% - acc: 0.8750 - loss: 1.5807 - 254.7 sample/sec\n",
      "Global step:  6728 - [=====>------------------------]  20% - acc: 0.9062 - loss: 1.5507 - 227.0 sample/sec\n",
      "Global step:  6738 - [======>-----------------------]  23% - acc: 0.8672 - loss: 1.5895 - 246.9 sample/sec\n",
      "Global step:  6748 - [=======>----------------------]  26% - acc: 0.9141 - loss: 1.5467 - 250.2 sample/sec\n",
      "Global step:  6758 - [========>---------------------]  28% - acc: 0.7969 - loss: 1.6583 - 268.0 sample/sec\n",
      "Global step:  6768 - [========>---------------------]  31% - acc: 0.8672 - loss: 1.5892 - 269.2 sample/sec\n",
      "Global step:  6778 - [=========>--------------------]  33% - acc: 0.8281 - loss: 1.6387 - 282.1 sample/sec\n",
      "Global step:  6788 - [==========>-------------------]  36% - acc: 0.8438 - loss: 1.6143 - 263.9 sample/sec\n",
      "Global step:  6798 - [===========>------------------]  38% - acc: 0.8672 - loss: 1.5929 - 243.2 sample/sec\n",
      "Global step:  6808 - [===========>------------------]  41% - acc: 0.8594 - loss: 1.5972 - 211.8 sample/sec\n",
      "Global step:  6818 - [============>-----------------]  43% - acc: 0.8281 - loss: 1.6310 - 192.0 sample/sec\n",
      "Global step:  6828 - [=============>----------------]  46% - acc: 0.8438 - loss: 1.6256 - 186.2 sample/sec\n",
      "Global step:  6838 - [==============>---------------]  49% - acc: 0.8438 - loss: 1.6141 - 165.2 sample/sec\n",
      "Global step:  6848 - [==============>---------------]  51% - acc: 0.8203 - loss: 1.6461 - 165.0 sample/sec\n",
      "Global step:  6858 - [===============>--------------]  54% - acc: 0.8672 - loss: 1.6005 - 170.6 sample/sec\n",
      "Global step:  6868 - [================>-------------]  56% - acc: 0.8984 - loss: 1.5629 - 206.4 sample/sec\n",
      "Global step:  6878 - [=================>------------]  59% - acc: 0.8281 - loss: 1.6275 - 248.9 sample/sec\n",
      "Global step:  6888 - [=================>------------]  61% - acc: 0.8047 - loss: 1.6515 - 242.2 sample/sec\n",
      "Global step:  6898 - [==================>-----------]  64% - acc: 0.8203 - loss: 1.6478 - 238.5 sample/sec\n",
      "Global step:  6908 - [===================>----------]  66% - acc: 0.8438 - loss: 1.6213 - 216.4 sample/sec\n",
      "Global step:  6918 - [====================>---------]  69% - acc: 0.8438 - loss: 1.6115 - 214.5 sample/sec\n",
      "Global step:  6928 - [====================>---------]  72% - acc: 0.8750 - loss: 1.5848 - 213.5 sample/sec\n",
      "Global step:  6938 - [=====================>--------]  74% - acc: 0.8594 - loss: 1.5957 - 192.3 sample/sec\n",
      "Global step:  6948 - [======================>-------]  77% - acc: 0.8750 - loss: 1.5927 - 155.0 sample/sec\n",
      "Global step:  6958 - [======================>-------]  79% - acc: 0.8281 - loss: 1.6323 - 167.6 sample/sec\n",
      "Global step:  6968 - [=======================>------]  82% - acc: 0.8750 - loss: 1.5894 - 149.4 sample/sec\n",
      "Global step:  6978 - [========================>-----]  84% - acc: 0.9453 - loss: 1.5189 - 185.0 sample/sec\n",
      "Global step:  6988 - [=========================>----]  87% - acc: 0.8672 - loss: 1.5961 - 195.9 sample/sec\n",
      "Global step:  6998 - [==========================>---]  90% - acc: 0.8516 - loss: 1.6071 - 168.9 sample/sec\n",
      "Global step:  7008 - [==========================>---]  92% - acc: 0.9062 - loss: 1.5558 - 205.7 sample/sec\n",
      "Global step:  7018 - [===========================>--]  95% - acc: 0.8906 - loss: 1.5740 - 187.3 sample/sec\n",
      "Global step:  7028 - [============================>-]  97% - acc: 0.8828 - loss: 1.5824 - 201.2 sample/sec\n",
      "Global step:  7038 - [=============================>] 100% - acc: 0.8875 - loss: 1.5684 - 331.2 sample/sec\n",
      "\n",
      "Epoch 18 - accuracy: 75.85% (7585/10000) - time: 00:04:14.41\n",
      "This epoch receive better accuracy: 75.85 > 75.65. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 19/60\n",
      "\n",
      "Global step:  7039 - [>-----------------------------]   0% - acc: 0.9062 - loss: 1.5472 - 180.3 sample/sec\n",
      "Global step:  7049 - [>-----------------------------]   3% - acc: 0.8203 - loss: 1.6388 - 166.9 sample/sec\n",
      "Global step:  7059 - [=>----------------------------]   5% - acc: 0.8828 - loss: 1.5794 - 161.0 sample/sec\n",
      "Global step:  7069 - [==>---------------------------]   8% - acc: 0.9141 - loss: 1.5534 - 178.6 sample/sec\n",
      "Global step:  7079 - [==>---------------------------]  10% - acc: 0.8750 - loss: 1.5968 - 181.7 sample/sec\n",
      "Global step:  7089 - [===>--------------------------]  13% - acc: 0.9062 - loss: 1.5620 - 193.4 sample/sec\n",
      "Global step:  7099 - [====>-------------------------]  15% - acc: 0.8984 - loss: 1.5623 - 212.9 sample/sec\n",
      "Global step:  7109 - [=====>------------------------]  18% - acc: 0.8672 - loss: 1.5814 - 228.3 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  7119 - [=====>------------------------]  20% - acc: 0.8750 - loss: 1.5886 - 234.8 sample/sec\n",
      "Global step:  7129 - [======>-----------------------]  23% - acc: 0.8438 - loss: 1.6184 - 259.3 sample/sec\n",
      "Global step:  7139 - [=======>----------------------]  26% - acc: 0.9062 - loss: 1.5503 - 275.7 sample/sec\n",
      "Global step:  7149 - [========>---------------------]  28% - acc: 0.8438 - loss: 1.6152 - 289.3 sample/sec\n",
      "Global step:  7159 - [========>---------------------]  31% - acc: 0.9219 - loss: 1.5377 - 281.6 sample/sec\n",
      "Global step:  7169 - [=========>--------------------]  33% - acc: 0.8594 - loss: 1.5989 - 269.2 sample/sec\n",
      "Global step:  7179 - [==========>-------------------]  36% - acc: 0.8594 - loss: 1.6015 - 268.3 sample/sec\n",
      "Global step:  7189 - [===========>------------------]  38% - acc: 0.8828 - loss: 1.5840 - 237.1 sample/sec\n",
      "Global step:  7199 - [===========>------------------]  41% - acc: 0.8906 - loss: 1.5735 - 253.9 sample/sec\n",
      "Global step:  7209 - [============>-----------------]  43% - acc: 0.8516 - loss: 1.6067 - 202.8 sample/sec\n",
      "Global step:  7219 - [=============>----------------]  46% - acc: 0.8672 - loss: 1.5979 - 182.0 sample/sec\n",
      "Global step:  7229 - [==============>---------------]  49% - acc: 0.8359 - loss: 1.6188 - 165.0 sample/sec\n",
      "Global step:  7239 - [==============>---------------]  51% - acc: 0.8281 - loss: 1.6329 - 149.9 sample/sec\n",
      "Global step:  7249 - [===============>--------------]  54% - acc: 0.8359 - loss: 1.6327 - 142.4 sample/sec\n",
      "Global step:  7259 - [================>-------------]  56% - acc: 0.8984 - loss: 1.5533 - 178.0 sample/sec\n",
      "Global step:  7269 - [=================>------------]  59% - acc: 0.8438 - loss: 1.6212 - 201.8 sample/sec\n",
      "Global step:  7279 - [=================>------------]  61% - acc: 0.8203 - loss: 1.6434 - 209.7 sample/sec\n",
      "Global step:  7289 - [==================>-----------]  64% - acc: 0.8125 - loss: 1.6537 - 218.5 sample/sec\n",
      "Global step:  7299 - [===================>----------]  66% - acc: 0.8125 - loss: 1.6458 - 231.6 sample/sec\n",
      "Global step:  7309 - [====================>---------]  69% - acc: 0.8672 - loss: 1.5950 - 223.0 sample/sec\n",
      "Global step:  7319 - [====================>---------]  72% - acc: 0.8828 - loss: 1.5826 - 223.5 sample/sec\n",
      "Global step:  7329 - [=====================>--------]  74% - acc: 0.9141 - loss: 1.5537 - 249.3 sample/sec\n",
      "Global step:  7339 - [======================>-------]  77% - acc: 0.8828 - loss: 1.5749 - 231.1 sample/sec\n",
      "Global step:  7349 - [======================>-------]  79% - acc: 0.8125 - loss: 1.6421 - 231.0 sample/sec\n",
      "Global step:  7359 - [=======================>------]  82% - acc: 0.8438 - loss: 1.6129 - 193.8 sample/sec\n",
      "Global step:  7369 - [========================>-----]  84% - acc: 0.9453 - loss: 1.5136 - 194.4 sample/sec\n",
      "Global step:  7379 - [=========================>----]  87% - acc: 0.8672 - loss: 1.5999 - 170.2 sample/sec\n",
      "Global step:  7389 - [==========================>---]  90% - acc: 0.8750 - loss: 1.5918 - 147.8 sample/sec\n",
      "Global step:  7399 - [==========================>---]  92% - acc: 0.8984 - loss: 1.5587 - 150.1 sample/sec\n",
      "Global step:  7409 - [===========================>--]  95% - acc: 0.8438 - loss: 1.6256 - 173.4 sample/sec\n",
      "Global step:  7419 - [============================>-]  97% - acc: 0.8984 - loss: 1.5691 - 173.8 sample/sec\n",
      "Global step:  7429 - [=============================>] 100% - acc: 0.9000 - loss: 1.5571 - 254.5 sample/sec\n",
      "\n",
      "Epoch 19 - accuracy: 75.41% (7541/10000) - time: 00:04:26.25\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 20/60\n",
      "\n",
      "Global step:  7430 - [>-----------------------------]   0% - acc: 0.9141 - loss: 1.5545 - 255.2 sample/sec\n",
      "Global step:  7440 - [>-----------------------------]   3% - acc: 0.8594 - loss: 1.6012 - 213.7 sample/sec\n",
      "Global step:  7450 - [=>----------------------------]   5% - acc: 0.9141 - loss: 1.5465 - 234.1 sample/sec\n",
      "Global step:  7460 - [==>---------------------------]   8% - acc: 0.8906 - loss: 1.5680 - 235.2 sample/sec\n",
      "Global step:  7470 - [==>---------------------------]  10% - acc: 0.8906 - loss: 1.5648 - 246.5 sample/sec\n",
      "Global step:  7480 - [===>--------------------------]  13% - acc: 0.8828 - loss: 1.5807 - 241.9 sample/sec\n",
      "Global step:  7490 - [====>-------------------------]  15% - acc: 0.9141 - loss: 1.5545 - 251.4 sample/sec\n",
      "Global step:  7500 - [=====>------------------------]  18% - acc: 0.8750 - loss: 1.5960 - 227.8 sample/sec\n",
      "Global step:  7510 - [=====>------------------------]  20% - acc: 0.9141 - loss: 1.5497 - 236.7 sample/sec\n",
      "Global step:  7520 - [======>-----------------------]  23% - acc: 0.8828 - loss: 1.5808 - 213.1 sample/sec\n",
      "Global step:  7530 - [=======>----------------------]  26% - acc: 0.9141 - loss: 1.5482 - 196.2 sample/sec\n",
      "Global step:  7540 - [========>---------------------]  28% - acc: 0.8672 - loss: 1.5964 - 167.8 sample/sec\n",
      "Global step:  7550 - [========>---------------------]  31% - acc: 0.9141 - loss: 1.5473 - 166.9 sample/sec\n",
      "Global step:  7560 - [=========>--------------------]  33% - acc: 0.8203 - loss: 1.6355 - 166.1 sample/sec\n",
      "Global step:  7570 - [==========>-------------------]  36% - acc: 0.8516 - loss: 1.6055 - 151.6 sample/sec\n",
      "Global step:  7580 - [===========>------------------]  38% - acc: 0.8906 - loss: 1.5635 - 156.4 sample/sec\n",
      "Global step:  7590 - [===========>------------------]  41% - acc: 0.8672 - loss: 1.5952 - 161.1 sample/sec\n",
      "Global step:  7600 - [============>-----------------]  43% - acc: 0.8750 - loss: 1.5866 - 171.4 sample/sec\n",
      "Global step:  7610 - [=============>----------------]  46% - acc: 0.8594 - loss: 1.5986 - 168.6 sample/sec\n",
      "Global step:  7620 - [==============>---------------]  49% - acc: 0.8984 - loss: 1.5665 - 231.0 sample/sec\n",
      "Global step:  7630 - [==============>---------------]  51% - acc: 0.8203 - loss: 1.6390 - 231.4 sample/sec\n",
      "Global step:  7640 - [===============>--------------]  54% - acc: 0.8672 - loss: 1.6013 - 254.0 sample/sec\n",
      "Global step:  7650 - [================>-------------]  56% - acc: 0.9453 - loss: 1.5247 - 261.1 sample/sec\n",
      "Global step:  7660 - [=================>------------]  59% - acc: 0.8438 - loss: 1.6201 - 288.9 sample/sec\n",
      "Global step:  7670 - [=================>------------]  61% - acc: 0.8203 - loss: 1.6406 - 283.0 sample/sec\n",
      "Global step:  7680 - [==================>-----------]  64% - acc: 0.8516 - loss: 1.6052 - 254.7 sample/sec\n",
      "Global step:  7690 - [===================>----------]  66% - acc: 0.8906 - loss: 1.5763 - 261.8 sample/sec\n",
      "Global step:  7700 - [====================>---------]  69% - acc: 0.8359 - loss: 1.6216 - 240.8 sample/sec\n",
      "Global step:  7710 - [====================>---------]  72% - acc: 0.8906 - loss: 1.5734 - 220.2 sample/sec\n",
      "Global step:  7720 - [=====================>--------]  74% - acc: 0.8906 - loss: 1.5702 - 193.4 sample/sec\n",
      "Global step:  7730 - [======================>-------]  77% - acc: 0.8828 - loss: 1.5771 - 154.5 sample/sec\n",
      "Global step:  7740 - [======================>-------]  79% - acc: 0.8438 - loss: 1.6201 - 141.2 sample/sec\n",
      "Global step:  7750 - [=======================>------]  82% - acc: 0.8594 - loss: 1.6002 - 152.4 sample/sec\n",
      "Global step:  7760 - [========================>-----]  84% - acc: 0.9297 - loss: 1.5343 - 183.1 sample/sec\n",
      "Global step:  7770 - [=========================>----]  87% - acc: 0.8516 - loss: 1.6171 - 201.9 sample/sec\n",
      "Global step:  7780 - [==========================>---]  90% - acc: 0.8906 - loss: 1.5756 - 249.9 sample/sec\n",
      "Global step:  7790 - [==========================>---]  92% - acc: 0.8828 - loss: 1.5752 - 274.9 sample/sec\n",
      "Global step:  7800 - [===========================>--]  95% - acc: 0.8750 - loss: 1.5868 - 280.8 sample/sec\n",
      "Global step:  7810 - [============================>-]  97% - acc: 0.8672 - loss: 1.5950 - 284.5 sample/sec\n",
      "Global step:  7820 - [=============================>] 100% - acc: 0.8875 - loss: 1.5748 - 400.1 sample/sec\n",
      "\n",
      "Epoch 20 - accuracy: 76.02% (7602/10000) - time: 00:04:11.74\n",
      "This epoch receive better accuracy: 76.02 > 75.85. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 21/60\n",
      "\n",
      "Global step:  7821 - [>-----------------------------]   0% - acc: 0.9141 - loss: 1.5402 - 259.8 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  7831 - [>-----------------------------]   3% - acc: 0.8906 - loss: 1.5731 - 218.7 sample/sec\n",
      "Global step:  7841 - [=>----------------------------]   5% - acc: 0.9297 - loss: 1.5350 - 216.7 sample/sec\n",
      "Global step:  7851 - [==>---------------------------]   8% - acc: 0.9062 - loss: 1.5621 - 205.2 sample/sec\n",
      "Global step:  7861 - [==>---------------------------]  10% - acc: 0.8672 - loss: 1.6017 - 177.6 sample/sec\n",
      "Global step:  7871 - [===>--------------------------]  13% - acc: 0.8750 - loss: 1.5800 - 158.2 sample/sec\n",
      "Global step:  7881 - [====>-------------------------]  15% - acc: 0.8750 - loss: 1.5831 - 156.8 sample/sec\n",
      "Global step:  7891 - [=====>------------------------]  18% - acc: 0.8203 - loss: 1.6365 - 159.2 sample/sec\n",
      "Global step:  7901 - [=====>------------------------]  20% - acc: 0.8906 - loss: 1.5606 - 145.4 sample/sec\n",
      "Global step:  7911 - [======>-----------------------]  23% - acc: 0.8828 - loss: 1.5783 - 172.5 sample/sec\n",
      "Global step:  7921 - [=======>----------------------]  26% - acc: 0.8984 - loss: 1.5608 - 175.3 sample/sec\n",
      "Global step:  7931 - [========>---------------------]  28% - acc: 0.8750 - loss: 1.5876 - 176.5 sample/sec\n",
      "Global step:  7941 - [========>---------------------]  31% - acc: 0.9219 - loss: 1.5360 - 194.1 sample/sec\n",
      "Global step:  7951 - [=========>--------------------]  33% - acc: 0.8750 - loss: 1.5866 - 186.7 sample/sec\n",
      "Global step:  7961 - [==========>-------------------]  36% - acc: 0.8281 - loss: 1.6369 - 181.1 sample/sec\n",
      "Global step:  7971 - [===========>------------------]  38% - acc: 0.8906 - loss: 1.5624 - 183.9 sample/sec\n",
      "Global step:  7981 - [===========>------------------]  41% - acc: 0.8672 - loss: 1.5961 - 198.9 sample/sec\n",
      "Global step:  7991 - [============>-----------------]  43% - acc: 0.8672 - loss: 1.5904 - 201.7 sample/sec\n",
      "Global step:  8001 - [=============>----------------]  46% - acc: 0.8828 - loss: 1.5777 - 216.6 sample/sec\n",
      "Global step:  8011 - [==============>---------------]  49% - acc: 0.8672 - loss: 1.5910 - 209.0 sample/sec\n",
      "Global step:  8021 - [==============>---------------]  51% - acc: 0.8203 - loss: 1.6419 - 186.9 sample/sec\n",
      "Global step:  8031 - [===============>--------------]  54% - acc: 0.8672 - loss: 1.5969 - 177.2 sample/sec\n",
      "Global step:  8041 - [================>-------------]  56% - acc: 0.9297 - loss: 1.5313 - 194.8 sample/sec\n",
      "Global step:  8051 - [=================>------------]  59% - acc: 0.8594 - loss: 1.6003 - 229.4 sample/sec\n",
      "Global step:  8061 - [=================>------------]  61% - acc: 0.8516 - loss: 1.6156 - 226.3 sample/sec\n",
      "Global step:  8071 - [==================>-----------]  64% - acc: 0.8516 - loss: 1.6144 - 228.5 sample/sec\n",
      "Global step:  8081 - [===================>----------]  66% - acc: 0.9062 - loss: 1.5620 - 225.3 sample/sec\n",
      "Global step:  8091 - [====================>---------]  69% - acc: 0.8672 - loss: 1.5907 - 215.7 sample/sec\n",
      "Global step:  8101 - [====================>---------]  72% - acc: 0.9141 - loss: 1.5561 - 200.0 sample/sec\n",
      "Global step:  8111 - [=====================>--------]  74% - acc: 0.8984 - loss: 1.5525 - 165.2 sample/sec\n",
      "Global step:  8121 - [======================>-------]  77% - acc: 0.8828 - loss: 1.5796 - 185.7 sample/sec\n",
      "Global step:  8131 - [======================>-------]  79% - acc: 0.8203 - loss: 1.6334 - 167.1 sample/sec\n",
      "Global step:  8141 - [=======================>------]  82% - acc: 0.8281 - loss: 1.6218 - 148.7 sample/sec\n",
      "Global step:  8151 - [========================>-----]  84% - acc: 0.9609 - loss: 1.5020 - 158.9 sample/sec\n",
      "Global step:  8161 - [=========================>----]  87% - acc: 0.8516 - loss: 1.6071 - 165.8 sample/sec\n",
      "Global step:  8171 - [==========================>---]  90% - acc: 0.8672 - loss: 1.5824 - 213.2 sample/sec\n",
      "Global step:  8181 - [==========================>---]  92% - acc: 0.8750 - loss: 1.5856 - 223.8 sample/sec\n",
      "Global step:  8191 - [===========================>--]  95% - acc: 0.8125 - loss: 1.6394 - 250.7 sample/sec\n",
      "Global step:  8201 - [============================>-]  97% - acc: 0.8516 - loss: 1.6044 - 253.0 sample/sec\n",
      "Global step:  8211 - [=============================>] 100% - acc: 0.8875 - loss: 1.5689 - 442.0 sample/sec\n",
      "\n",
      "Epoch 21 - accuracy: 74.39% (7439/10000) - time: 00:04:35.99\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 22/60\n",
      "\n",
      "Global step:  8212 - [>-----------------------------]   0% - acc: 0.8828 - loss: 1.5701 - 205.6 sample/sec\n",
      "Global step:  8222 - [>-----------------------------]   3% - acc: 0.9141 - loss: 1.5475 - 168.0 sample/sec\n",
      "Global step:  8232 - [=>----------------------------]   5% - acc: 0.9141 - loss: 1.5484 - 167.1 sample/sec\n",
      "Global step:  8242 - [==>---------------------------]   8% - acc: 0.8984 - loss: 1.5597 - 173.5 sample/sec\n",
      "Global step:  8252 - [==>---------------------------]  10% - acc: 0.8906 - loss: 1.5669 - 165.0 sample/sec\n",
      "Global step:  8262 - [===>--------------------------]  13% - acc: 0.8672 - loss: 1.5963 - 172.1 sample/sec\n",
      "Global step:  8272 - [====>-------------------------]  15% - acc: 0.9062 - loss: 1.5547 - 185.2 sample/sec\n",
      "Global step:  8282 - [=====>------------------------]  18% - acc: 0.8828 - loss: 1.5786 - 210.1 sample/sec\n",
      "Global step:  8292 - [=====>------------------------]  20% - acc: 0.9453 - loss: 1.5156 - 212.4 sample/sec\n",
      "Global step:  8302 - [======>-----------------------]  23% - acc: 0.9219 - loss: 1.5394 - 203.2 sample/sec\n",
      "Global step:  8312 - [=======>----------------------]  26% - acc: 0.9688 - loss: 1.4955 - 216.7 sample/sec\n",
      "Global step:  8322 - [========>---------------------]  28% - acc: 0.8594 - loss: 1.5954 - 205.9 sample/sec\n",
      "Global step:  8332 - [========>---------------------]  31% - acc: 0.9453 - loss: 1.5196 - 210.2 sample/sec\n",
      "Global step:  8342 - [=========>--------------------]  33% - acc: 0.8984 - loss: 1.5678 - 197.0 sample/sec\n",
      "Global step:  8352 - [==========>-------------------]  36% - acc: 0.8984 - loss: 1.5646 - 187.6 sample/sec\n",
      "Global step:  8362 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5372 - 210.8 sample/sec\n",
      "Global step:  8372 - [===========>------------------]  41% - acc: 0.9062 - loss: 1.5536 - 229.9 sample/sec\n",
      "Global step:  8382 - [============>-----------------]  43% - acc: 0.8906 - loss: 1.5674 - 239.5 sample/sec\n",
      "Global step:  8392 - [=============>----------------]  46% - acc: 0.8984 - loss: 1.5641 - 229.8 sample/sec\n",
      "Global step:  8402 - [==============>---------------]  49% - acc: 0.8672 - loss: 1.5908 - 221.8 sample/sec\n",
      "Global step:  8412 - [==============>---------------]  51% - acc: 0.8281 - loss: 1.6302 - 227.2 sample/sec\n",
      "Global step:  8422 - [===============>--------------]  54% - acc: 0.9141 - loss: 1.5554 - 243.3 sample/sec\n",
      "Global step:  8432 - [================>-------------]  56% - acc: 0.9531 - loss: 1.5090 - 267.7 sample/sec\n",
      "Global step:  8442 - [=================>------------]  59% - acc: 0.8828 - loss: 1.5789 - 230.2 sample/sec\n",
      "Global step:  8452 - [=================>------------]  61% - acc: 0.8438 - loss: 1.6170 - 197.0 sample/sec\n",
      "Global step:  8462 - [==================>-----------]  64% - acc: 0.8672 - loss: 1.5937 - 215.6 sample/sec\n",
      "Global step:  8472 - [===================>----------]  66% - acc: 0.9062 - loss: 1.5507 - 220.5 sample/sec\n",
      "Global step:  8482 - [====================>---------]  69% - acc: 0.9062 - loss: 1.5523 - 166.4 sample/sec\n",
      "Global step:  8492 - [====================>---------]  72% - acc: 0.9141 - loss: 1.5469 - 138.7 sample/sec\n",
      "Global step:  8502 - [=====================>--------]  74% - acc: 0.9453 - loss: 1.5171 - 148.9 sample/sec\n",
      "Global step:  8512 - [======================>-------]  77% - acc: 0.8828 - loss: 1.5752 - 224.9 sample/sec\n",
      "Global step:  8522 - [======================>-------]  79% - acc: 0.8594 - loss: 1.6018 - 260.2 sample/sec\n",
      "Global step:  8532 - [=======================>------]  82% - acc: 0.9062 - loss: 1.5629 - 285.7 sample/sec\n",
      "Global step:  8542 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4882 - 294.3 sample/sec\n",
      "Global step:  8552 - [=========================>----]  87% - acc: 0.8984 - loss: 1.5662 - 294.9 sample/sec\n",
      "Global step:  8562 - [==========================>---]  90% - acc: 0.9062 - loss: 1.5549 - 281.1 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  8572 - [==========================>---]  92% - acc: 0.9375 - loss: 1.5192 - 246.9 sample/sec\n",
      "Global step:  8582 - [===========================>--]  95% - acc: 0.8906 - loss: 1.5686 - 206.9 sample/sec\n",
      "Global step:  8592 - [============================>-]  97% - acc: 0.9062 - loss: 1.5530 - 202.1 sample/sec\n",
      "Global step:  8602 - [=============================>] 100% - acc: 0.9125 - loss: 1.5413 - 357.0 sample/sec\n",
      "\n",
      "Epoch 22 - accuracy: 77.60% (7760/10000) - time: 00:04:15.66\n",
      "This epoch receive better accuracy: 77.60 > 76.02. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 23/60\n",
      "\n",
      "Global step:  8603 - [>-----------------------------]   0% - acc: 0.9219 - loss: 1.5381 - 216.7 sample/sec\n",
      "Global step:  8613 - [>-----------------------------]   3% - acc: 0.9062 - loss: 1.5502 - 192.7 sample/sec\n",
      "Global step:  8623 - [=>----------------------------]   5% - acc: 0.9297 - loss: 1.5324 - 208.4 sample/sec\n",
      "Global step:  8633 - [==>---------------------------]   8% - acc: 0.9375 - loss: 1.5285 - 217.0 sample/sec\n",
      "Global step:  8643 - [==>---------------------------]  10% - acc: 0.9141 - loss: 1.5481 - 269.3 sample/sec\n",
      "Global step:  8653 - [===>--------------------------]  13% - acc: 0.9062 - loss: 1.5585 - 304.7 sample/sec\n",
      "Global step:  8663 - [====>-------------------------]  15% - acc: 0.9062 - loss: 1.5546 - 289.2 sample/sec\n",
      "Global step:  8673 - [=====>------------------------]  18% - acc: 0.8984 - loss: 1.5656 - 316.9 sample/sec\n",
      "Global step:  8683 - [=====>------------------------]  20% - acc: 0.9375 - loss: 1.5191 - 319.7 sample/sec\n",
      "Global step:  8693 - [======>-----------------------]  23% - acc: 0.9375 - loss: 1.5280 - 323.2 sample/sec\n",
      "Global step:  8703 - [=======>----------------------]  26% - acc: 0.9609 - loss: 1.4972 - 273.9 sample/sec\n",
      "Global step:  8713 - [========>---------------------]  28% - acc: 0.8828 - loss: 1.5777 - 232.0 sample/sec\n",
      "Global step:  8723 - [========>---------------------]  31% - acc: 0.9688 - loss: 1.4958 - 185.3 sample/sec\n",
      "Global step:  8733 - [=========>--------------------]  33% - acc: 0.8906 - loss: 1.5695 - 179.2 sample/sec\n",
      "Global step:  8743 - [==========>-------------------]  36% - acc: 0.9062 - loss: 1.5557 - 163.6 sample/sec\n",
      "Global step:  8753 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5338 - 159.3 sample/sec\n",
      "Global step:  8763 - [===========>------------------]  41% - acc: 0.9141 - loss: 1.5467 - 170.5 sample/sec\n",
      "Global step:  8773 - [============>-----------------]  43% - acc: 0.9062 - loss: 1.5580 - 203.3 sample/sec\n",
      "Global step:  8783 - [=============>----------------]  46% - acc: 0.9141 - loss: 1.5535 - 239.9 sample/sec\n",
      "Global step:  8793 - [==============>---------------]  49% - acc: 0.8984 - loss: 1.5630 - 274.2 sample/sec\n",
      "Global step:  8803 - [==============>---------------]  51% - acc: 0.8438 - loss: 1.6167 - 314.4 sample/sec\n",
      "Global step:  8813 - [===============>--------------]  54% - acc: 0.9141 - loss: 1.5485 - 318.2 sample/sec\n",
      "Global step:  8823 - [================>-------------]  56% - acc: 0.9531 - loss: 1.5103 - 339.0 sample/sec\n",
      "Global step:  8833 - [=================>------------]  59% - acc: 0.8984 - loss: 1.5707 - 350.8 sample/sec\n",
      "Global step:  8843 - [=================>------------]  61% - acc: 0.8516 - loss: 1.6097 - 351.8 sample/sec\n",
      "Global step:  8853 - [==================>-----------]  64% - acc: 0.8672 - loss: 1.5927 - 342.0 sample/sec\n",
      "Global step:  8863 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5339 - 345.8 sample/sec\n",
      "Global step:  8873 - [====================>---------]  69% - acc: 0.9062 - loss: 1.5530 - 343.6 sample/sec\n",
      "Global step:  8883 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5339 - 313.0 sample/sec\n",
      "Global step:  8893 - [=====================>--------]  74% - acc: 0.9453 - loss: 1.5159 - 293.2 sample/sec\n",
      "Global step:  8903 - [======================>-------]  77% - acc: 0.8984 - loss: 1.5622 - 280.6 sample/sec\n",
      "Global step:  8913 - [======================>-------]  79% - acc: 0.8672 - loss: 1.5941 - 233.7 sample/sec\n",
      "Global step:  8923 - [=======================>------]  82% - acc: 0.9062 - loss: 1.5559 - 250.8 sample/sec\n",
      "Global step:  8933 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4852 - 231.5 sample/sec\n",
      "Global step:  8943 - [=========================>----]  87% - acc: 0.9062 - loss: 1.5580 - 211.2 sample/sec\n",
      "Global step:  8953 - [==========================>---]  90% - acc: 0.9141 - loss: 1.5491 - 189.5 sample/sec\n",
      "Global step:  8963 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5161 - 172.5 sample/sec\n",
      "Global step:  8973 - [===========================>--]  95% - acc: 0.8984 - loss: 1.5611 - 165.1 sample/sec\n",
      "Global step:  8983 - [============================>-]  97% - acc: 0.9219 - loss: 1.5387 - 178.8 sample/sec\n",
      "Global step:  8993 - [=============================>] 100% - acc: 0.9250 - loss: 1.5361 - 279.7 sample/sec\n",
      "\n",
      "Epoch 23 - accuracy: 77.59% (7759/10000) - time: 00:03:47.43\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 24/60\n",
      "\n",
      "Global step:  8994 - [>-----------------------------]   0% - acc: 0.9375 - loss: 1.5267 - 178.2 sample/sec\n",
      "Global step:  9004 - [>-----------------------------]   3% - acc: 0.9297 - loss: 1.5343 - 184.5 sample/sec\n",
      "Global step:  9014 - [=>----------------------------]   5% - acc: 0.9297 - loss: 1.5323 - 232.0 sample/sec\n",
      "Global step:  9024 - [==>---------------------------]   8% - acc: 0.9375 - loss: 1.5228 - 241.5 sample/sec\n",
      "Global step:  9034 - [==>---------------------------]  10% - acc: 0.9219 - loss: 1.5380 - 247.4 sample/sec\n",
      "Global step:  9044 - [===>--------------------------]  13% - acc: 0.9297 - loss: 1.5367 - 279.5 sample/sec\n",
      "Global step:  9054 - [====>-------------------------]  15% - acc: 0.9141 - loss: 1.5487 - 275.5 sample/sec\n",
      "Global step:  9064 - [=====>------------------------]  18% - acc: 0.8984 - loss: 1.5621 - 279.6 sample/sec\n",
      "Global step:  9074 - [=====>------------------------]  20% - acc: 0.9531 - loss: 1.5091 - 254.9 sample/sec\n",
      "Global step:  9084 - [======>-----------------------]  23% - acc: 0.9375 - loss: 1.5254 - 281.7 sample/sec\n",
      "Global step:  9094 - [=======>----------------------]  26% - acc: 0.9688 - loss: 1.4946 - 287.6 sample/sec\n",
      "Global step:  9104 - [========>---------------------]  28% - acc: 0.8828 - loss: 1.5780 - 290.2 sample/sec\n",
      "Global step:  9114 - [========>---------------------]  31% - acc: 0.9688 - loss: 1.4927 - 290.3 sample/sec\n",
      "Global step:  9124 - [=========>--------------------]  33% - acc: 0.8984 - loss: 1.5629 - 300.2 sample/sec\n",
      "Global step:  9134 - [==========>-------------------]  36% - acc: 0.9062 - loss: 1.5572 - 262.3 sample/sec\n",
      "Global step:  9144 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5350 - 296.1 sample/sec\n",
      "Global step:  9154 - [===========>------------------]  41% - acc: 0.9141 - loss: 1.5459 - 269.7 sample/sec\n",
      "Global step:  9164 - [============>-----------------]  43% - acc: 0.9141 - loss: 1.5477 - 281.8 sample/sec\n",
      "Global step:  9174 - [=============>----------------]  46% - acc: 0.9141 - loss: 1.5463 - 289.3 sample/sec\n",
      "Global step:  9184 - [==============>---------------]  49% - acc: 0.9219 - loss: 1.5482 - 288.2 sample/sec\n",
      "Global step:  9194 - [==============>---------------]  51% - acc: 0.8516 - loss: 1.6104 - 259.3 sample/sec\n",
      "Global step:  9204 - [===============>--------------]  54% - acc: 0.9141 - loss: 1.5472 - 281.7 sample/sec\n",
      "Global step:  9214 - [================>-------------]  56% - acc: 0.9609 - loss: 1.5037 - 292.5 sample/sec\n",
      "Global step:  9224 - [=================>------------]  59% - acc: 0.9062 - loss: 1.5583 - 267.2 sample/sec\n",
      "Global step:  9234 - [=================>------------]  61% - acc: 0.8516 - loss: 1.6067 - 260.3 sample/sec\n",
      "Global step:  9244 - [==================>-----------]  64% - acc: 0.8750 - loss: 1.5852 - 247.0 sample/sec\n",
      "Global step:  9254 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5320 - 231.0 sample/sec\n",
      "Global step:  9264 - [====================>---------]  69% - acc: 0.9062 - loss: 1.5515 - 208.6 sample/sec\n",
      "Global step:  9274 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5320 - 210.0 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  9284 - [=====================>--------]  74% - acc: 0.9453 - loss: 1.5159 - 215.4 sample/sec\n",
      "Global step:  9294 - [======================>-------]  77% - acc: 0.8984 - loss: 1.5619 - 223.5 sample/sec\n",
      "Global step:  9304 - [======================>-------]  79% - acc: 0.8672 - loss: 1.5934 - 254.2 sample/sec\n",
      "Global step:  9314 - [=======================>------]  82% - acc: 0.9062 - loss: 1.5550 - 252.0 sample/sec\n",
      "Global step:  9324 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4871 - 290.9 sample/sec\n",
      "Global step:  9334 - [=========================>----]  87% - acc: 0.9062 - loss: 1.5553 - 303.5 sample/sec\n",
      "Global step:  9344 - [==========================>---]  90% - acc: 0.9141 - loss: 1.5470 - 318.3 sample/sec\n",
      "Global step:  9354 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5158 - 332.9 sample/sec\n",
      "Global step:  9364 - [===========================>--]  95% - acc: 0.9062 - loss: 1.5550 - 337.6 sample/sec\n",
      "Global step:  9374 - [============================>-]  97% - acc: 0.9375 - loss: 1.5275 - 338.0 sample/sec\n",
      "Global step:  9384 - [=============================>] 100% - acc: 0.9250 - loss: 1.5361 - 534.1 sample/sec\n",
      "\n",
      "Epoch 24 - accuracy: 77.71% (7771/10000) - time: 00:03:18.97\n",
      "This epoch receive better accuracy: 77.71 > 77.60. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 25/60\n",
      "\n",
      "Global step:  9385 - [>-----------------------------]   0% - acc: 0.9375 - loss: 1.5239 - 337.9 sample/sec\n",
      "Global step:  9395 - [>-----------------------------]   3% - acc: 0.9453 - loss: 1.5216 - 315.2 sample/sec\n",
      "Global step:  9405 - [=>----------------------------]   5% - acc: 0.9297 - loss: 1.5311 - 265.8 sample/sec\n",
      "Global step:  9415 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5169 - 268.7 sample/sec\n",
      "Global step:  9425 - [==>---------------------------]  10% - acc: 0.9297 - loss: 1.5317 - 237.5 sample/sec\n",
      "Global step:  9435 - [===>--------------------------]  13% - acc: 0.9297 - loss: 1.5343 - 245.9 sample/sec\n",
      "Global step:  9445 - [====>-------------------------]  15% - acc: 0.9141 - loss: 1.5467 - 246.5 sample/sec\n",
      "Global step:  9455 - [=====>------------------------]  18% - acc: 0.9062 - loss: 1.5554 - 220.4 sample/sec\n",
      "Global step:  9465 - [=====>------------------------]  20% - acc: 0.9531 - loss: 1.5058 - 207.9 sample/sec\n",
      "Global step:  9475 - [======>-----------------------]  23% - acc: 0.9375 - loss: 1.5244 - 238.0 sample/sec\n",
      "Global step:  9485 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4863 - 258.1 sample/sec\n",
      "Global step:  9495 - [========>---------------------]  28% - acc: 0.8828 - loss: 1.5777 - 264.9 sample/sec\n",
      "Global step:  9505 - [========>---------------------]  31% - acc: 0.9688 - loss: 1.4925 - 238.6 sample/sec\n",
      "Global step:  9515 - [=========>--------------------]  33% - acc: 0.8984 - loss: 1.5634 - 275.6 sample/sec\n",
      "Global step:  9525 - [==========>-------------------]  36% - acc: 0.9062 - loss: 1.5552 - 264.0 sample/sec\n",
      "Global step:  9535 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5314 - 238.1 sample/sec\n",
      "Global step:  9545 - [===========>------------------]  41% - acc: 0.9219 - loss: 1.5423 - 251.2 sample/sec\n",
      "Global step:  9555 - [============>-----------------]  43% - acc: 0.9141 - loss: 1.5473 - 237.7 sample/sec\n",
      "Global step:  9565 - [=============>----------------]  46% - acc: 0.9141 - loss: 1.5457 - 260.9 sample/sec\n",
      "Global step:  9575 - [==============>---------------]  49% - acc: 0.9219 - loss: 1.5393 - 256.1 sample/sec\n",
      "Global step:  9585 - [==============>---------------]  51% - acc: 0.8516 - loss: 1.6115 - 269.8 sample/sec\n",
      "Global step:  9595 - [===============>--------------]  54% - acc: 0.9141 - loss: 1.5468 - 272.5 sample/sec\n",
      "Global step:  9605 - [================>-------------]  56% - acc: 0.9609 - loss: 1.5005 - 256.8 sample/sec\n",
      "Global step:  9615 - [=================>------------]  59% - acc: 0.9062 - loss: 1.5556 - 263.9 sample/sec\n",
      "Global step:  9625 - [=================>------------]  61% - acc: 0.8594 - loss: 1.6017 - 268.5 sample/sec\n",
      "Global step:  9635 - [==================>-----------]  64% - acc: 0.8828 - loss: 1.5832 - 291.1 sample/sec\n",
      "Global step:  9645 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5317 - 295.2 sample/sec\n",
      "Global step:  9655 - [====================>---------]  69% - acc: 0.9219 - loss: 1.5392 - 302.0 sample/sec\n",
      "Global step:  9665 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5318 - 276.3 sample/sec\n",
      "Global step:  9675 - [=====================>--------]  74% - acc: 0.9453 - loss: 1.5162 - 294.1 sample/sec\n",
      "Global step:  9685 - [======================>-------]  77% - acc: 0.8984 - loss: 1.5595 - 300.1 sample/sec\n",
      "Global step:  9695 - [======================>-------]  79% - acc: 0.8672 - loss: 1.5937 - 304.8 sample/sec\n",
      "Global step:  9705 - [=======================>------]  82% - acc: 0.9062 - loss: 1.5549 - 298.7 sample/sec\n",
      "Global step:  9715 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 280.8 sample/sec\n",
      "Global step:  9725 - [=========================>----]  87% - acc: 0.9062 - loss: 1.5546 - 287.8 sample/sec\n",
      "Global step:  9735 - [==========================>---]  90% - acc: 0.9141 - loss: 1.5461 - 276.2 sample/sec\n",
      "Global step:  9745 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5153 - 242.5 sample/sec\n",
      "Global step:  9755 - [===========================>--]  95% - acc: 0.9062 - loss: 1.5544 - 257.5 sample/sec\n",
      "Global step:  9765 - [============================>-]  97% - acc: 0.9375 - loss: 1.5246 - 237.5 sample/sec\n",
      "Global step:  9775 - [=============================>] 100% - acc: 0.9250 - loss: 1.5358 - 347.1 sample/sec\n",
      "\n",
      "Epoch 25 - accuracy: 77.84% (7784/10000) - time: 00:03:26.03\n",
      "This epoch receive better accuracy: 77.84 > 77.71. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 26/60\n",
      "\n",
      "Global step:  9776 - [>-----------------------------]   0% - acc: 0.9375 - loss: 1.5237 - 210.4 sample/sec\n",
      "Global step:  9786 - [>-----------------------------]   3% - acc: 0.9453 - loss: 1.5169 - 235.6 sample/sec\n",
      "Global step:  9796 - [=>----------------------------]   5% - acc: 0.9297 - loss: 1.5296 - 251.4 sample/sec\n",
      "Global step:  9806 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5161 - 278.7 sample/sec\n",
      "Global step:  9816 - [==>---------------------------]  10% - acc: 0.9297 - loss: 1.5314 - 272.8 sample/sec\n",
      "Global step:  9826 - [===>--------------------------]  13% - acc: 0.9297 - loss: 1.5315 - 262.1 sample/sec\n",
      "Global step:  9836 - [====>-------------------------]  15% - acc: 0.9141 - loss: 1.5464 - 294.7 sample/sec\n",
      "Global step:  9846 - [=====>------------------------]  18% - acc: 0.9062 - loss: 1.5564 - 272.6 sample/sec\n",
      "Global step:  9856 - [=====>------------------------]  20% - acc: 0.9609 - loss: 1.5001 - 228.3 sample/sec\n",
      "Global step:  9866 - [======>-----------------------]  23% - acc: 0.9375 - loss: 1.5243 - 187.4 sample/sec\n",
      "Global step:  9876 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4849 - 218.0 sample/sec\n",
      "Global step:  9886 - [========>---------------------]  28% - acc: 0.8906 - loss: 1.5720 - 225.8 sample/sec\n",
      "Global step:  9896 - [========>---------------------]  31% - acc: 0.9688 - loss: 1.4926 - 254.9 sample/sec\n",
      "Global step:  9906 - [=========>--------------------]  33% - acc: 0.8984 - loss: 1.5622 - 271.3 sample/sec\n",
      "Global step:  9916 - [==========>-------------------]  36% - acc: 0.9062 - loss: 1.5562 - 267.2 sample/sec\n",
      "Global step:  9926 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5310 - 287.3 sample/sec\n",
      "Global step:  9936 - [===========>------------------]  41% - acc: 0.9219 - loss: 1.5389 - 301.8 sample/sec\n",
      "Global step:  9946 - [============>-----------------]  43% - acc: 0.9141 - loss: 1.5479 - 245.0 sample/sec\n",
      "Global step:  9956 - [=============>----------------]  46% - acc: 0.9141 - loss: 1.5433 - 299.9 sample/sec\n",
      "Global step:  9966 - [==============>---------------]  49% - acc: 0.9219 - loss: 1.5399 - 290.0 sample/sec\n",
      "Global step:  9976 - [==============>---------------]  51% - acc: 0.8516 - loss: 1.6071 - 298.4 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  9986 - [===============>--------------]  54% - acc: 0.9141 - loss: 1.5469 - 229.6 sample/sec\n",
      "Global step:  9996 - [================>-------------]  56% - acc: 0.9609 - loss: 1.5008 - 262.9 sample/sec\n",
      "Global step: 10006 - [=================>------------]  59% - acc: 0.9062 - loss: 1.5560 - 266.0 sample/sec\n",
      "Global step: 10016 - [=================>------------]  61% - acc: 0.8594 - loss: 1.6005 - 264.8 sample/sec\n",
      "Global step: 10026 - [==================>-----------]  64% - acc: 0.8828 - loss: 1.5782 - 248.1 sample/sec\n",
      "Global step: 10036 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5311 - 252.2 sample/sec\n",
      "Global step: 10046 - [====================>---------]  69% - acc: 0.9297 - loss: 1.5327 - 221.1 sample/sec\n",
      "Global step: 10056 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5336 - 218.4 sample/sec\n",
      "Global step: 10066 - [=====================>--------]  74% - acc: 0.9453 - loss: 1.5159 - 219.8 sample/sec\n",
      "Global step: 10076 - [======================>-------]  77% - acc: 0.9062 - loss: 1.5546 - 198.6 sample/sec\n",
      "Global step: 10086 - [======================>-------]  79% - acc: 0.8672 - loss: 1.5929 - 179.0 sample/sec\n",
      "Global step: 10096 - [=======================>------]  82% - acc: 0.9062 - loss: 1.5550 - 206.7 sample/sec\n",
      "Global step: 10106 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 237.1 sample/sec\n",
      "Global step: 10116 - [=========================>----]  87% - acc: 0.9062 - loss: 1.5545 - 263.3 sample/sec\n",
      "Global step: 10126 - [==========================>---]  90% - acc: 0.9141 - loss: 1.5485 - 281.9 sample/sec\n",
      "Global step: 10136 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5158 - 309.9 sample/sec\n",
      "Global step: 10146 - [===========================>--]  95% - acc: 0.9062 - loss: 1.5539 - 328.3 sample/sec\n",
      "Global step: 10156 - [============================>-]  97% - acc: 0.9375 - loss: 1.5244 - 353.4 sample/sec\n",
      "Global step: 10166 - [=============================>] 100% - acc: 0.9250 - loss: 1.5346 - 548.5 sample/sec\n",
      "\n",
      "Epoch 26 - accuracy: 77.89% (7789/10000) - time: 00:03:27.41\n",
      "This epoch receive better accuracy: 77.89 > 77.84. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 27/60\n",
      "\n",
      "Global step: 10167 - [>-----------------------------]   0% - acc: 0.9375 - loss: 1.5230 - 276.3 sample/sec\n",
      "Global step: 10177 - [>-----------------------------]   3% - acc: 0.9453 - loss: 1.5161 - 248.6 sample/sec\n",
      "Global step: 10187 - [=>----------------------------]   5% - acc: 0.9375 - loss: 1.5242 - 255.9 sample/sec\n",
      "Global step: 10197 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5156 - 278.5 sample/sec\n",
      "Global step: 10207 - [==>---------------------------]  10% - acc: 0.9297 - loss: 1.5320 - 271.0 sample/sec\n",
      "Global step: 10217 - [===>--------------------------]  13% - acc: 0.9375 - loss: 1.5247 - 295.3 sample/sec\n",
      "Global step: 10227 - [====>-------------------------]  15% - acc: 0.9141 - loss: 1.5428 - 297.0 sample/sec\n",
      "Global step: 10237 - [=====>------------------------]  18% - acc: 0.9062 - loss: 1.5550 - 299.7 sample/sec\n",
      "Global step: 10247 - [=====>------------------------]  20% - acc: 0.9609 - loss: 1.5000 - 294.9 sample/sec\n",
      "Global step: 10257 - [======>-----------------------]  23% - acc: 0.9375 - loss: 1.5241 - 298.8 sample/sec\n",
      "Global step: 10267 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4851 - 255.9 sample/sec\n",
      "Global step: 10277 - [========>---------------------]  28% - acc: 0.9062 - loss: 1.5601 - 294.1 sample/sec\n",
      "Global step: 10287 - [========>---------------------]  31% - acc: 0.9688 - loss: 1.4924 - 295.3 sample/sec\n",
      "Global step: 10297 - [=========>--------------------]  33% - acc: 0.8984 - loss: 1.5605 - 324.2 sample/sec\n",
      "Global step: 10307 - [==========>-------------------]  36% - acc: 0.9062 - loss: 1.5546 - 350.0 sample/sec\n",
      "Global step: 10317 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5314 - 349.2 sample/sec\n",
      "Global step: 10327 - [===========>------------------]  41% - acc: 0.9219 - loss: 1.5390 - 339.5 sample/sec\n",
      "Global step: 10337 - [============>-----------------]  43% - acc: 0.9141 - loss: 1.5474 - 336.0 sample/sec\n",
      "Global step: 10347 - [=============>----------------]  46% - acc: 0.9219 - loss: 1.5381 - 353.2 sample/sec\n",
      "Global step: 10357 - [==============>---------------]  49% - acc: 0.9219 - loss: 1.5378 - 341.4 sample/sec\n",
      "Global step: 10367 - [==============>---------------]  51% - acc: 0.8594 - loss: 1.6023 - 326.9 sample/sec\n",
      "Global step: 10377 - [===============>--------------]  54% - acc: 0.9141 - loss: 1.5464 - 317.8 sample/sec\n",
      "Global step: 10387 - [================>-------------]  56% - acc: 0.9609 - loss: 1.5003 - 292.7 sample/sec\n",
      "Global step: 10397 - [=================>------------]  59% - acc: 0.9062 - loss: 1.5555 - 283.8 sample/sec\n",
      "Global step: 10407 - [=================>------------]  61% - acc: 0.8672 - loss: 1.5943 - 306.9 sample/sec\n",
      "Global step: 10417 - [==================>-----------]  64% - acc: 0.8828 - loss: 1.5781 - 292.6 sample/sec\n",
      "Global step: 10427 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5312 - 298.6 sample/sec\n",
      "Global step: 10437 - [====================>---------]  69% - acc: 0.9297 - loss: 1.5331 - 323.7 sample/sec\n",
      "Global step: 10447 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 328.4 sample/sec\n",
      "Global step: 10457 - [=====================>--------]  74% - acc: 0.9453 - loss: 1.5156 - 333.0 sample/sec\n",
      "Global step: 10467 - [======================>-------]  77% - acc: 0.9062 - loss: 1.5545 - 329.5 sample/sec\n",
      "Global step: 10477 - [======================>-------]  79% - acc: 0.8672 - loss: 1.5932 - 337.6 sample/sec\n",
      "Global step: 10487 - [=======================>------]  82% - acc: 0.9062 - loss: 1.5555 - 319.4 sample/sec\n",
      "Global step: 10497 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 338.9 sample/sec\n",
      "Global step: 10507 - [=========================>----]  87% - acc: 0.9062 - loss: 1.5549 - 344.4 sample/sec\n",
      "Global step: 10517 - [==========================>---]  90% - acc: 0.9219 - loss: 1.5408 - 345.7 sample/sec\n",
      "Global step: 10527 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5157 - 351.4 sample/sec\n",
      "Global step: 10537 - [===========================>--]  95% - acc: 0.9141 - loss: 1.5492 - 342.4 sample/sec\n",
      "Global step: 10547 - [============================>-]  97% - acc: 0.9375 - loss: 1.5237 - 326.3 sample/sec\n",
      "Global step: 10557 - [=============================>] 100% - acc: 0.9375 - loss: 1.5237 - 515.7 sample/sec\n",
      "\n",
      "Epoch 27 - accuracy: 77.93% (7793/10000) - time: 00:02:53.27\n",
      "This epoch receive better accuracy: 77.93 > 77.89. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 28/60\n",
      "\n",
      "Global step: 10558 - [>-----------------------------]   0% - acc: 0.9453 - loss: 1.5156 - 312.8 sample/sec\n",
      "Global step: 10568 - [>-----------------------------]   3% - acc: 0.9453 - loss: 1.5156 - 309.3 sample/sec\n",
      "Global step: 10578 - [=>----------------------------]   5% - acc: 0.9375 - loss: 1.5238 - 304.5 sample/sec\n",
      "Global step: 10588 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5162 - 303.2 sample/sec\n",
      "Global step: 10598 - [==>---------------------------]  10% - acc: 0.9297 - loss: 1.5314 - 325.0 sample/sec\n",
      "Global step: 10608 - [===>--------------------------]  13% - acc: 0.9375 - loss: 1.5251 - 314.8 sample/sec\n",
      "Global step: 10618 - [====>-------------------------]  15% - acc: 0.9219 - loss: 1.5390 - 319.7 sample/sec\n",
      "Global step: 10628 - [=====>------------------------]  18% - acc: 0.9062 - loss: 1.5551 - 292.9 sample/sec\n",
      "Global step: 10638 - [=====>------------------------]  20% - acc: 0.9609 - loss: 1.5000 - 286.6 sample/sec\n",
      "Global step: 10648 - [======>-----------------------]  23% - acc: 0.9453 - loss: 1.5180 - 272.1 sample/sec\n",
      "Global step: 10658 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4854 - 302.2 sample/sec\n",
      "Global step: 10668 - [========>---------------------]  28% - acc: 0.9062 - loss: 1.5550 - 306.5 sample/sec\n",
      "Global step: 10678 - [========>---------------------]  31% - acc: 0.9688 - loss: 1.4925 - 298.6 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 10688 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5543 - 320.4 sample/sec\n",
      "Global step: 10698 - [==========>-------------------]  36% - acc: 0.9062 - loss: 1.5550 - 294.2 sample/sec\n",
      "Global step: 10708 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5314 - 327.0 sample/sec\n",
      "Global step: 10718 - [===========>------------------]  41% - acc: 0.9219 - loss: 1.5389 - 322.9 sample/sec\n",
      "Global step: 10728 - [============>-----------------]  43% - acc: 0.9141 - loss: 1.5476 - 323.2 sample/sec\n",
      "Global step: 10738 - [=============>----------------]  46% - acc: 0.9219 - loss: 1.5358 - 317.3 sample/sec\n",
      "Global step: 10748 - [==============>---------------]  49% - acc: 0.9297 - loss: 1.5311 - 323.5 sample/sec\n",
      "Global step: 10758 - [==============>---------------]  51% - acc: 0.8594 - loss: 1.6000 - 276.6 sample/sec\n",
      "Global step: 10768 - [===============>--------------]  54% - acc: 0.9141 - loss: 1.5447 - 301.1 sample/sec\n",
      "Global step: 10778 - [================>-------------]  56% - acc: 0.9609 - loss: 1.5004 - 281.1 sample/sec\n",
      "Global step: 10788 - [=================>------------]  59% - acc: 0.9062 - loss: 1.5554 - 279.9 sample/sec\n",
      "Global step: 10798 - [=================>------------]  61% - acc: 0.8672 - loss: 1.5953 - 325.5 sample/sec\n",
      "Global step: 10808 - [==================>-----------]  64% - acc: 0.8828 - loss: 1.5765 - 286.9 sample/sec\n",
      "Global step: 10818 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5316 - 300.4 sample/sec\n",
      "Global step: 10828 - [====================>---------]  69% - acc: 0.9297 - loss: 1.5307 - 308.5 sample/sec\n",
      "Global step: 10838 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5316 - 296.5 sample/sec\n",
      "Global step: 10848 - [=====================>--------]  74% - acc: 0.9453 - loss: 1.5140 - 309.6 sample/sec\n",
      "Global step: 10858 - [======================>-------]  77% - acc: 0.9062 - loss: 1.5557 - 293.1 sample/sec\n",
      "Global step: 10868 - [======================>-------]  79% - acc: 0.8672 - loss: 1.5927 - 279.7 sample/sec\n",
      "Global step: 10878 - [=======================>------]  82% - acc: 0.9062 - loss: 1.5548 - 306.5 sample/sec\n",
      "Global step: 10888 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4849 - 270.9 sample/sec\n",
      "Global step: 10898 - [=========================>----]  87% - acc: 0.9062 - loss: 1.5549 - 263.1 sample/sec\n",
      "Global step: 10908 - [==========================>---]  90% - acc: 0.9219 - loss: 1.5385 - 257.6 sample/sec\n",
      "Global step: 10918 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5156 - 250.5 sample/sec\n",
      "Global step: 10928 - [===========================>--]  95% - acc: 0.9141 - loss: 1.5465 - 265.8 sample/sec\n",
      "Global step: 10938 - [============================>-]  97% - acc: 0.9375 - loss: 1.5236 - 300.4 sample/sec\n",
      "Global step: 10948 - [=============================>] 100% - acc: 0.9375 - loss: 1.5246 - 468.6 sample/sec\n",
      "\n",
      "Epoch 28 - accuracy: 77.88% (7788/10000) - time: 00:02:59.04\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 29/60\n",
      "\n",
      "Global step: 10949 - [>-----------------------------]   0% - acc: 0.9453 - loss: 1.5125 - 301.5 sample/sec\n",
      "Global step: 10959 - [>-----------------------------]   3% - acc: 0.9453 - loss: 1.5172 - 287.5 sample/sec\n",
      "Global step: 10969 - [=>----------------------------]   5% - acc: 0.9375 - loss: 1.5246 - 292.8 sample/sec\n",
      "Global step: 10979 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5161 - 266.4 sample/sec\n",
      "Global step: 10989 - [==>---------------------------]  10% - acc: 0.9297 - loss: 1.5314 - 207.2 sample/sec\n",
      "Global step: 10999 - [===>--------------------------]  13% - acc: 0.9375 - loss: 1.5234 - 222.1 sample/sec\n",
      "Global step: 11009 - [====>-------------------------]  15% - acc: 0.9219 - loss: 1.5392 - 195.6 sample/sec\n",
      "Global step: 11019 - [=====>------------------------]  18% - acc: 0.9062 - loss: 1.5553 - 215.3 sample/sec\n",
      "Global step: 11029 - [=====>------------------------]  20% - acc: 0.9609 - loss: 1.5001 - 202.5 sample/sec\n",
      "Global step: 11039 - [======>-----------------------]  23% - acc: 0.9453 - loss: 1.5172 - 241.8 sample/sec\n",
      "Global step: 11049 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4858 - 233.4 sample/sec\n",
      "Global step: 11059 - [========>---------------------]  28% - acc: 0.9062 - loss: 1.5549 - 199.0 sample/sec\n",
      "Global step: 11069 - [========>---------------------]  31% - acc: 0.9688 - loss: 1.4927 - 198.6 sample/sec\n",
      "Global step: 11079 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5543 - 190.3 sample/sec\n",
      "Global step: 11089 - [==========>-------------------]  36% - acc: 0.9062 - loss: 1.5547 - 180.6 sample/sec\n",
      "Global step: 11099 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5326 - 189.2 sample/sec\n",
      "Global step: 11109 - [===========>------------------]  41% - acc: 0.9219 - loss: 1.5394 - 172.2 sample/sec\n",
      "Global step: 11119 - [============>-----------------]  43% - acc: 0.9141 - loss: 1.5472 - 188.0 sample/sec\n",
      "Global step: 11129 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5316 - 201.4 sample/sec\n",
      "Global step: 11139 - [==============>---------------]  49% - acc: 0.9297 - loss: 1.5307 - 192.6 sample/sec\n",
      "Global step: 11149 - [==============>---------------]  51% - acc: 0.8672 - loss: 1.5946 - 252.0 sample/sec\n",
      "Global step: 11159 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5388 - 245.0 sample/sec\n",
      "Global step: 11169 - [================>-------------]  56% - acc: 0.9609 - loss: 1.5006 - 266.1 sample/sec\n",
      "Global step: 11179 - [=================>------------]  59% - acc: 0.9062 - loss: 1.5563 - 213.8 sample/sec\n",
      "Global step: 11189 - [=================>------------]  61% - acc: 0.8750 - loss: 1.5894 - 228.2 sample/sec\n",
      "Global step: 11199 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5709 - 237.1 sample/sec\n",
      "Global step: 11209 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5313 - 285.5 sample/sec\n",
      "Global step: 11219 - [====================>---------]  69% - acc: 0.9297 - loss: 1.5334 - 264.1 sample/sec\n",
      "Global step: 11229 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 314.6 sample/sec\n",
      "Global step: 11239 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5081 - 319.4 sample/sec\n",
      "Global step: 11249 - [======================>-------]  77% - acc: 0.9062 - loss: 1.5547 - 317.1 sample/sec\n",
      "Global step: 11259 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5858 - 332.9 sample/sec\n",
      "Global step: 11269 - [=======================>------]  82% - acc: 0.9062 - loss: 1.5549 - 320.3 sample/sec\n",
      "Global step: 11279 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 334.5 sample/sec\n",
      "Global step: 11289 - [=========================>----]  87% - acc: 0.9062 - loss: 1.5541 - 332.9 sample/sec\n",
      "Global step: 11299 - [==========================>---]  90% - acc: 0.9219 - loss: 1.5385 - 348.2 sample/sec\n",
      "Global step: 11309 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5158 - 329.2 sample/sec\n",
      "Global step: 11319 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5395 - 305.9 sample/sec\n",
      "Global step: 11329 - [============================>-]  97% - acc: 0.9375 - loss: 1.5237 - 287.6 sample/sec\n",
      "Global step: 11339 - [=============================>] 100% - acc: 0.9375 - loss: 1.5237 - 477.0 sample/sec\n",
      "\n",
      "Epoch 29 - accuracy: 77.67% (7767/10000) - time: 00:03:36.44\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 30/60\n",
      "\n",
      "Global step: 11340 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5081 - 260.6 sample/sec\n",
      "Global step: 11350 - [>-----------------------------]   3% - acc: 0.9453 - loss: 1.5139 - 235.5 sample/sec\n",
      "Global step: 11360 - [=>----------------------------]   5% - acc: 0.9375 - loss: 1.5238 - 198.9 sample/sec\n",
      "Global step: 11370 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5164 - 182.4 sample/sec\n",
      "Global step: 11380 - [==>---------------------------]  10% - acc: 0.9297 - loss: 1.5314 - 178.2 sample/sec\n",
      "Global step: 11390 - [===>--------------------------]  13% - acc: 0.9453 - loss: 1.5178 - 203.3 sample/sec\n",
      "Global step: 11400 - [====>-------------------------]  15% - acc: 0.9219 - loss: 1.5364 - 251.2 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 11410 - [=====>------------------------]  18% - acc: 0.9062 - loss: 1.5554 - 296.5 sample/sec\n",
      "Global step: 11420 - [=====>------------------------]  20% - acc: 0.9609 - loss: 1.5006 - 293.1 sample/sec\n",
      "Global step: 11430 - [======>-----------------------]  23% - acc: 0.9453 - loss: 1.5161 - 320.0 sample/sec\n",
      "Global step: 11440 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4854 - 310.4 sample/sec\n",
      "Global step: 11450 - [========>---------------------]  28% - acc: 0.9062 - loss: 1.5552 - 300.5 sample/sec\n",
      "Global step: 11460 - [========>---------------------]  31% - acc: 0.9688 - loss: 1.4925 - 308.3 sample/sec\n",
      "Global step: 11470 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5543 - 331.2 sample/sec\n",
      "Global step: 11480 - [==========>-------------------]  36% - acc: 0.9062 - loss: 1.5549 - 324.0 sample/sec\n",
      "Global step: 11490 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5314 - 330.6 sample/sec\n",
      "Global step: 11500 - [===========>------------------]  41% - acc: 0.9219 - loss: 1.5388 - 315.0 sample/sec\n",
      "Global step: 11510 - [============>-----------------]  43% - acc: 0.9141 - loss: 1.5471 - 316.1 sample/sec\n",
      "Global step: 11520 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5334 - 315.1 sample/sec\n",
      "Global step: 11530 - [==============>---------------]  49% - acc: 0.9297 - loss: 1.5320 - 322.5 sample/sec\n",
      "Global step: 11540 - [==============>---------------]  51% - acc: 0.8672 - loss: 1.5937 - 327.6 sample/sec\n",
      "Global step: 11550 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5390 - 329.5 sample/sec\n",
      "Global step: 11560 - [================>-------------]  56% - acc: 0.9609 - loss: 1.5002 - 327.4 sample/sec\n",
      "Global step: 11570 - [=================>------------]  59% - acc: 0.9062 - loss: 1.5548 - 332.1 sample/sec\n",
      "Global step: 11580 - [=================>------------]  61% - acc: 0.8750 - loss: 1.5861 - 343.4 sample/sec\n",
      "Global step: 11590 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5705 - 329.1 sample/sec\n",
      "Global step: 11600 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5310 - 326.7 sample/sec\n",
      "Global step: 11610 - [====================>---------]  69% - acc: 0.9297 - loss: 1.5313 - 342.9 sample/sec\n",
      "Global step: 11620 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5316 - 339.7 sample/sec\n",
      "Global step: 11630 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5132 - 345.8 sample/sec\n",
      "Global step: 11640 - [======================>-------]  77% - acc: 0.9062 - loss: 1.5548 - 332.9 sample/sec\n",
      "Global step: 11650 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5853 - 335.1 sample/sec\n",
      "Global step: 11660 - [=======================>------]  82% - acc: 0.9062 - loss: 1.5548 - 328.9 sample/sec\n",
      "Global step: 11670 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4848 - 324.9 sample/sec\n",
      "Global step: 11680 - [=========================>----]  87% - acc: 0.9062 - loss: 1.5546 - 313.6 sample/sec\n",
      "Global step: 11690 - [==========================>---]  90% - acc: 0.9219 - loss: 1.5383 - 307.6 sample/sec\n",
      "Global step: 11700 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5181 - 299.1 sample/sec\n",
      "Global step: 11710 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5387 - 301.6 sample/sec\n",
      "Global step: 11720 - [============================>-]  97% - acc: 0.9375 - loss: 1.5236 - 302.3 sample/sec\n",
      "Global step: 11730 - [=============================>] 100% - acc: 0.9375 - loss: 1.5234 - 478.2 sample/sec\n",
      "\n",
      "Epoch 30 - accuracy: 77.88% (7788/10000) - time: 00:03:01.15\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 31/60\n",
      "\n",
      "Global step: 11731 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5085 - 307.6 sample/sec\n",
      "Global step: 11741 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5094 - 320.4 sample/sec\n",
      "Global step: 11751 - [=>----------------------------]   5% - acc: 0.9375 - loss: 1.5234 - 323.9 sample/sec\n",
      "Global step: 11761 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5156 - 326.5 sample/sec\n",
      "Global step: 11771 - [==>---------------------------]  10% - acc: 0.9297 - loss: 1.5319 - 321.3 sample/sec\n",
      "Global step: 11781 - [===>--------------------------]  13% - acc: 0.9453 - loss: 1.5160 - 342.2 sample/sec\n",
      "Global step: 11791 - [====>-------------------------]  15% - acc: 0.9297 - loss: 1.5315 - 323.4 sample/sec\n",
      "Global step: 11801 - [=====>------------------------]  18% - acc: 0.9062 - loss: 1.5548 - 328.2 sample/sec\n",
      "Global step: 11811 - [=====>------------------------]  20% - acc: 0.9609 - loss: 1.5000 - 335.8 sample/sec\n",
      "Global step: 11821 - [======>-----------------------]  23% - acc: 0.9453 - loss: 1.5161 - 336.5 sample/sec\n",
      "Global step: 11831 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4848 - 326.2 sample/sec\n",
      "Global step: 11841 - [========>---------------------]  28% - acc: 0.9062 - loss: 1.5550 - 320.1 sample/sec\n",
      "Global step: 11851 - [========>---------------------]  31% - acc: 0.9688 - loss: 1.4926 - 321.6 sample/sec\n",
      "Global step: 11861 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5542 - 309.4 sample/sec\n",
      "Global step: 11871 - [==========>-------------------]  36% - acc: 0.8984 - loss: 1.5593 - 322.7 sample/sec\n",
      "Global step: 11881 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5313 - 319.2 sample/sec\n",
      "Global step: 11891 - [===========>------------------]  41% - acc: 0.9219 - loss: 1.5389 - 314.9 sample/sec\n",
      "Global step: 11901 - [============>-----------------]  43% - acc: 0.9141 - loss: 1.5458 - 310.1 sample/sec\n",
      "Global step: 11911 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5319 - 308.3 sample/sec\n",
      "Global step: 11921 - [==============>---------------]  49% - acc: 0.9297 - loss: 1.5308 - 308.0 sample/sec\n",
      "Global step: 11931 - [==============>---------------]  51% - acc: 0.8672 - loss: 1.5936 - 328.4 sample/sec\n",
      "Global step: 11941 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5388 - 331.7 sample/sec\n",
      "Global step: 11951 - [================>-------------]  56% - acc: 0.9609 - loss: 1.5000 - 342.8 sample/sec\n",
      "Global step: 11961 - [=================>------------]  59% - acc: 0.9062 - loss: 1.5550 - 342.2 sample/sec\n",
      "Global step: 11971 - [=================>------------]  61% - acc: 0.8750 - loss: 1.5862 - 353.6 sample/sec\n",
      "Global step: 11981 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5704 - 347.2 sample/sec\n",
      "Global step: 11991 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5312 - 347.6 sample/sec\n",
      "Global step: 12001 - [====================>---------]  69% - acc: 0.9297 - loss: 1.5313 - 353.2 sample/sec\n",
      "Global step: 12011 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 339.5 sample/sec\n",
      "Global step: 12021 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5081 - 335.9 sample/sec\n",
      "Global step: 12031 - [======================>-------]  77% - acc: 0.9062 - loss: 1.5540 - 335.3 sample/sec\n",
      "Global step: 12041 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5856 - 327.0 sample/sec\n",
      "Global step: 12051 - [=======================>------]  82% - acc: 0.9062 - loss: 1.5546 - 336.9 sample/sec\n",
      "Global step: 12061 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 317.2 sample/sec\n",
      "Global step: 12071 - [=========================>----]  87% - acc: 0.9062 - loss: 1.5536 - 330.1 sample/sec\n",
      "Global step: 12081 - [==========================>---]  90% - acc: 0.9219 - loss: 1.5386 - 315.0 sample/sec\n",
      "Global step: 12091 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5156 - 293.0 sample/sec\n",
      "Global step: 12101 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5388 - 293.5 sample/sec\n",
      "Global step: 12111 - [============================>-]  97% - acc: 0.9375 - loss: 1.5237 - 320.0 sample/sec\n",
      "Global step: 12121 - [=============================>] 100% - acc: 0.9375 - loss: 1.5233 - 473.5 sample/sec\n",
      "\n",
      "Epoch 31 - accuracy: 77.88% (7788/10000) - time: 00:02:44.70\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 32/60\n",
      "\n",
      "Global step: 12122 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5081 - 320.3 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 12132 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5081 - 313.7 sample/sec\n",
      "Global step: 12142 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5163 - 305.4 sample/sec\n",
      "Global step: 12152 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5156 - 331.1 sample/sec\n",
      "Global step: 12162 - [==>---------------------------]  10% - acc: 0.9297 - loss: 1.5324 - 330.1 sample/sec\n",
      "Global step: 12172 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5080 - 330.0 sample/sec\n",
      "Global step: 12182 - [====>-------------------------]  15% - acc: 0.9297 - loss: 1.5312 - 337.8 sample/sec\n",
      "Global step: 12192 - [=====>------------------------]  18% - acc: 0.9062 - loss: 1.5522 - 297.5 sample/sec\n",
      "Global step: 12202 - [=====>------------------------]  20% - acc: 0.9609 - loss: 1.5002 - 343.5 sample/sec\n",
      "Global step: 12212 - [======>-----------------------]  23% - acc: 0.9453 - loss: 1.5162 - 340.9 sample/sec\n",
      "Global step: 12222 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4848 - 338.7 sample/sec\n",
      "Global step: 12232 - [========>---------------------]  28% - acc: 0.9062 - loss: 1.5550 - 318.7 sample/sec\n",
      "Global step: 12242 - [========>---------------------]  31% - acc: 0.9688 - loss: 1.4924 - 323.3 sample/sec\n",
      "Global step: 12252 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5542 - 319.8 sample/sec\n",
      "Global step: 12262 - [==========>-------------------]  36% - acc: 0.9062 - loss: 1.5545 - 315.0 sample/sec\n",
      "Global step: 12272 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5313 - 310.8 sample/sec\n",
      "Global step: 12282 - [===========>------------------]  41% - acc: 0.9219 - loss: 1.5384 - 311.8 sample/sec\n",
      "Global step: 12292 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 313.0 sample/sec\n",
      "Global step: 12302 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5318 - 310.1 sample/sec\n",
      "Global step: 12312 - [==============>---------------]  49% - acc: 0.9297 - loss: 1.5314 - 310.8 sample/sec\n",
      "Global step: 12322 - [==============>---------------]  51% - acc: 0.8672 - loss: 1.5935 - 321.7 sample/sec\n",
      "Global step: 12332 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5386 - 332.3 sample/sec\n",
      "Global step: 12342 - [================>-------------]  56% - acc: 0.9609 - loss: 1.4998 - 317.6 sample/sec\n",
      "Global step: 12352 - [=================>------------]  59% - acc: 0.9062 - loss: 1.5534 - 319.6 sample/sec\n",
      "Global step: 12362 - [=================>------------]  61% - acc: 0.8750 - loss: 1.5862 - 331.7 sample/sec\n",
      "Global step: 12372 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5706 - 320.9 sample/sec\n",
      "Global step: 12382 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5311 - 323.5 sample/sec\n",
      "Global step: 12392 - [====================>---------]  69% - acc: 0.9297 - loss: 1.5315 - 331.5 sample/sec\n",
      "Global step: 12402 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 334.5 sample/sec\n",
      "Global step: 12412 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5080 - 338.9 sample/sec\n",
      "Global step: 12422 - [======================>-------]  77% - acc: 0.9141 - loss: 1.5475 - 334.8 sample/sec\n",
      "Global step: 12432 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5865 - 344.5 sample/sec\n",
      "Global step: 12442 - [=======================>------]  82% - acc: 0.9062 - loss: 1.5546 - 312.8 sample/sec\n",
      "Global step: 12452 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 336.1 sample/sec\n",
      "Global step: 12462 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5494 - 341.6 sample/sec\n",
      "Global step: 12472 - [==========================>---]  90% - acc: 0.9219 - loss: 1.5387 - 324.9 sample/sec\n",
      "Global step: 12482 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5157 - 325.3 sample/sec\n",
      "Global step: 12492 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5410 - 342.2 sample/sec\n",
      "Global step: 12502 - [============================>-]  97% - acc: 0.9375 - loss: 1.5236 - 317.2 sample/sec\n",
      "Global step: 12512 - [=============================>] 100% - acc: 0.9375 - loss: 1.5235 - 444.5 sample/sec\n",
      "\n",
      "Epoch 32 - accuracy: 78.07% (7807/10000) - time: 00:02:48.02\n",
      "This epoch receive better accuracy: 78.07 > 77.93. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 33/60\n",
      "\n",
      "Global step: 12513 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5080 - 198.9 sample/sec\n",
      "Global step: 12523 - [>-----------------------------]   3% - acc: 0.9453 - loss: 1.5130 - 201.5 sample/sec\n",
      "Global step: 12533 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5158 - 201.9 sample/sec\n",
      "Global step: 12543 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5157 - 199.5 sample/sec\n",
      "Global step: 12553 - [==>---------------------------]  10% - acc: 0.9297 - loss: 1.5311 - 207.8 sample/sec\n",
      "Global step: 12563 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5083 - 256.9 sample/sec\n",
      "Global step: 12573 - [====>-------------------------]  15% - acc: 0.9297 - loss: 1.5310 - 256.9 sample/sec\n",
      "Global step: 12583 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5472 - 239.3 sample/sec\n",
      "Global step: 12593 - [=====>------------------------]  20% - acc: 0.9609 - loss: 1.5000 - 233.4 sample/sec\n",
      "Global step: 12603 - [======>-----------------------]  23% - acc: 0.9453 - loss: 1.5177 - 264.3 sample/sec\n",
      "Global step: 12613 - [=======>----------------------]  26% - acc: 0.9688 - loss: 1.4895 - 282.5 sample/sec\n",
      "Global step: 12623 - [========>---------------------]  28% - acc: 0.9062 - loss: 1.5567 - 303.4 sample/sec\n",
      "Global step: 12633 - [========>---------------------]  31% - acc: 0.9688 - loss: 1.4923 - 320.5 sample/sec\n",
      "Global step: 12643 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5544 - 330.6 sample/sec\n",
      "Global step: 12653 - [==========>-------------------]  36% - acc: 0.9062 - loss: 1.5541 - 335.8 sample/sec\n",
      "Global step: 12663 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5312 - 339.4 sample/sec\n",
      "Global step: 12673 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5321 - 337.7 sample/sec\n",
      "Global step: 12683 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5398 - 323.9 sample/sec\n",
      "Global step: 12693 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5313 - 321.9 sample/sec\n",
      "Global step: 12703 - [==============>---------------]  49% - acc: 0.9297 - loss: 1.5335 - 347.8 sample/sec\n",
      "Global step: 12713 - [==============>---------------]  51% - acc: 0.8672 - loss: 1.5937 - 341.8 sample/sec\n",
      "Global step: 12723 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5390 - 338.0 sample/sec\n",
      "Global step: 12733 - [================>-------------]  56% - acc: 0.9609 - loss: 1.5010 - 340.0 sample/sec\n",
      "Global step: 12743 - [=================>------------]  59% - acc: 0.9141 - loss: 1.5472 - 357.1 sample/sec\n",
      "Global step: 12753 - [=================>------------]  61% - acc: 0.8750 - loss: 1.5854 - 344.4 sample/sec\n",
      "Global step: 12763 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5701 - 346.0 sample/sec\n",
      "Global step: 12773 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5314 - 340.7 sample/sec\n",
      "Global step: 12783 - [====================>---------]  69% - acc: 0.9297 - loss: 1.5306 - 346.2 sample/sec\n",
      "Global step: 12793 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5317 - 348.3 sample/sec\n",
      "Global step: 12803 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5080 - 341.8 sample/sec\n",
      "Global step: 12813 - [======================>-------]  77% - acc: 0.9141 - loss: 1.5459 - 332.6 sample/sec\n",
      "Global step: 12823 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5865 - 331.7 sample/sec\n",
      "Global step: 12833 - [=======================>------]  82% - acc: 0.9062 - loss: 1.5543 - 330.6 sample/sec\n",
      "Global step: 12843 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4848 - 330.3 sample/sec\n",
      "Global step: 12853 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5461 - 333.2 sample/sec\n",
      "Global step: 12863 - [==========================>---]  90% - acc: 0.9297 - loss: 1.5311 - 313.6 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 12873 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5156 - 341.1 sample/sec\n",
      "Global step: 12883 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5393 - 336.8 sample/sec\n",
      "Global step: 12893 - [============================>-]  97% - acc: 0.9375 - loss: 1.5234 - 321.4 sample/sec\n",
      "Global step: 12903 - [=============================>] 100% - acc: 0.9375 - loss: 1.5233 - 540.2 sample/sec\n",
      "\n",
      "Epoch 33 - accuracy: 77.93% (7793/10000) - time: 00:02:57.52\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 34/60\n",
      "\n",
      "Global step: 12904 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5081 - 349.0 sample/sec\n",
      "Global step: 12914 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5084 - 350.5 sample/sec\n",
      "Global step: 12924 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5159 - 341.2 sample/sec\n",
      "Global step: 12934 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5167 - 339.3 sample/sec\n",
      "Global step: 12944 - [==>---------------------------]  10% - acc: 0.9297 - loss: 1.5310 - 350.4 sample/sec\n",
      "Global step: 12954 - [===>--------------------------]  13% - acc: 0.9453 - loss: 1.5133 - 347.6 sample/sec\n",
      "Global step: 12964 - [====>-------------------------]  15% - acc: 0.9297 - loss: 1.5317 - 352.6 sample/sec\n",
      "Global step: 12974 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5472 - 345.2 sample/sec\n",
      "Global step: 12984 - [=====>------------------------]  20% - acc: 0.9609 - loss: 1.5002 - 344.6 sample/sec\n",
      "Global step: 12994 - [======>-----------------------]  23% - acc: 0.9453 - loss: 1.5192 - 354.5 sample/sec\n",
      "Global step: 13004 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4846 - 351.5 sample/sec\n",
      "Global step: 13014 - [========>---------------------]  28% - acc: 0.9062 - loss: 1.5552 - 336.5 sample/sec\n",
      "Global step: 13024 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4848 - 332.8 sample/sec\n",
      "Global step: 13034 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5547 - 340.1 sample/sec\n",
      "Global step: 13044 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5467 - 341.7 sample/sec\n",
      "Global step: 13054 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5314 - 315.2 sample/sec\n",
      "Global step: 13064 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5311 - 272.7 sample/sec\n",
      "Global step: 13074 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5395 - 252.4 sample/sec\n",
      "Global step: 13084 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5310 - 261.1 sample/sec\n",
      "Global step: 13094 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5267 - 255.8 sample/sec\n",
      "Global step: 13104 - [==============>---------------]  51% - acc: 0.8672 - loss: 1.5932 - 274.1 sample/sec\n",
      "Global step: 13114 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5391 - 271.8 sample/sec\n",
      "Global step: 13124 - [================>-------------]  56% - acc: 0.9609 - loss: 1.5001 - 279.0 sample/sec\n",
      "Global step: 13134 - [=================>------------]  59% - acc: 0.9141 - loss: 1.5477 - 303.0 sample/sec\n",
      "Global step: 13144 - [=================>------------]  61% - acc: 0.8828 - loss: 1.5781 - 293.8 sample/sec\n",
      "Global step: 13154 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5703 - 297.6 sample/sec\n",
      "Global step: 13164 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5312 - 276.1 sample/sec\n",
      "Global step: 13174 - [====================>---------]  69% - acc: 0.9375 - loss: 1.5250 - 303.3 sample/sec\n",
      "Global step: 13184 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5316 - 311.8 sample/sec\n",
      "Global step: 13194 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5080 - 309.6 sample/sec\n",
      "Global step: 13204 - [======================>-------]  77% - acc: 0.9219 - loss: 1.5390 - 286.5 sample/sec\n",
      "Global step: 13214 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5853 - 267.3 sample/sec\n",
      "Global step: 13224 - [=======================>------]  82% - acc: 0.9062 - loss: 1.5548 - 242.2 sample/sec\n",
      "Global step: 13234 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 238.6 sample/sec\n",
      "Global step: 13244 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5467 - 275.2 sample/sec\n",
      "Global step: 13254 - [==========================>---]  90% - acc: 0.9297 - loss: 1.5309 - 289.8 sample/sec\n",
      "Global step: 13264 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5159 - 292.2 sample/sec\n",
      "Global step: 13274 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5387 - 291.6 sample/sec\n",
      "Global step: 13284 - [============================>-]  97% - acc: 0.9375 - loss: 1.5234 - 268.0 sample/sec\n",
      "Global step: 13294 - [=============================>] 100% - acc: 0.9375 - loss: 1.5234 - 457.3 sample/sec\n",
      "\n",
      "Epoch 34 - accuracy: 77.83% (7783/10000) - time: 00:02:57.29\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 35/60\n",
      "\n",
      "Global step: 13295 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5081 - 318.1 sample/sec\n",
      "Global step: 13305 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5082 - 318.4 sample/sec\n",
      "Global step: 13315 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5158 - 322.3 sample/sec\n",
      "Global step: 13325 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5153 - 327.0 sample/sec\n",
      "Global step: 13335 - [==>---------------------------]  10% - acc: 0.9297 - loss: 1.5311 - 308.2 sample/sec\n",
      "Global step: 13345 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5081 - 308.1 sample/sec\n",
      "Global step: 13355 - [====>-------------------------]  15% - acc: 0.9297 - loss: 1.5292 - 316.0 sample/sec\n",
      "Global step: 13365 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5469 - 302.8 sample/sec\n",
      "Global step: 13375 - [=====>------------------------]  20% - acc: 0.9609 - loss: 1.5001 - 312.1 sample/sec\n",
      "Global step: 13385 - [======>-----------------------]  23% - acc: 0.9453 - loss: 1.5160 - 311.4 sample/sec\n",
      "Global step: 13395 - [=======>----------------------]  26% - acc: 0.9688 - loss: 1.4924 - 281.5 sample/sec\n",
      "Global step: 13405 - [========>---------------------]  28% - acc: 0.9062 - loss: 1.5543 - 305.9 sample/sec\n",
      "Global step: 13415 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4846 - 294.7 sample/sec\n",
      "Global step: 13425 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5542 - 300.8 sample/sec\n",
      "Global step: 13435 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5480 - 272.3 sample/sec\n",
      "Global step: 13445 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5310 - 293.0 sample/sec\n",
      "Global step: 13455 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5314 - 299.5 sample/sec\n",
      "Global step: 13465 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 283.3 sample/sec\n",
      "Global step: 13475 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5313 - 310.8 sample/sec\n",
      "Global step: 13485 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5232 - 311.9 sample/sec\n",
      "Global step: 13495 - [==============>---------------]  51% - acc: 0.8672 - loss: 1.5939 - 318.7 sample/sec\n",
      "Global step: 13505 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 324.4 sample/sec\n",
      "Global step: 13515 - [================>-------------]  56% - acc: 0.9609 - loss: 1.5002 - 341.0 sample/sec\n",
      "Global step: 13525 - [=================>------------]  59% - acc: 0.9141 - loss: 1.5479 - 346.4 sample/sec\n",
      "Global step: 13535 - [=================>------------]  61% - acc: 0.8828 - loss: 1.5779 - 348.5 sample/sec\n",
      "Global step: 13545 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5702 - 338.6 sample/sec\n",
      "Global step: 13555 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5310 - 347.7 sample/sec\n",
      "Global step: 13565 - [====================>---------]  69% - acc: 0.9375 - loss: 1.5235 - 358.0 sample/sec\n",
      "Global step: 13575 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5324 - 339.1 sample/sec\n",
      "Global step: 13585 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5080 - 342.4 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 13595 - [======================>-------]  77% - acc: 0.9219 - loss: 1.5371 - 298.6 sample/sec\n",
      "Global step: 13605 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5854 - 292.3 sample/sec\n",
      "Global step: 13615 - [=======================>------]  82% - acc: 0.9141 - loss: 1.5527 - 271.2 sample/sec\n",
      "Global step: 13625 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4859 - 290.2 sample/sec\n",
      "Global step: 13635 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5472 - 306.4 sample/sec\n",
      "Global step: 13645 - [==========================>---]  90% - acc: 0.9297 - loss: 1.5308 - 310.4 sample/sec\n",
      "Global step: 13655 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5156 - 260.0 sample/sec\n",
      "Global step: 13665 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5398 - 257.3 sample/sec\n",
      "Global step: 13675 - [============================>-]  97% - acc: 0.9375 - loss: 1.5235 - 216.4 sample/sec\n",
      "Global step: 13685 - [=============================>] 100% - acc: 0.9375 - loss: 1.5236 - 344.7 sample/sec\n",
      "\n",
      "Epoch 35 - accuracy: 77.86% (7786/10000) - time: 00:03:00.58\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 36/60\n",
      "\n",
      "Global step: 13686 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5084 - 197.1 sample/sec\n",
      "Global step: 13696 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5081 - 210.2 sample/sec\n",
      "Global step: 13706 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5160 - 215.5 sample/sec\n",
      "Global step: 13716 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5158 - 215.9 sample/sec\n",
      "Global step: 13726 - [==>---------------------------]  10% - acc: 0.9297 - loss: 1.5306 - 223.1 sample/sec\n",
      "Global step: 13736 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5080 - 241.2 sample/sec\n",
      "Global step: 13746 - [====>-------------------------]  15% - acc: 0.9375 - loss: 1.5231 - 258.0 sample/sec\n",
      "Global step: 13756 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5475 - 254.2 sample/sec\n",
      "Global step: 13766 - [=====>------------------------]  20% - acc: 0.9609 - loss: 1.4997 - 309.7 sample/sec\n",
      "Global step: 13776 - [======>-----------------------]  23% - acc: 0.9453 - loss: 1.5160 - 306.3 sample/sec\n",
      "Global step: 13786 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4854 - 306.3 sample/sec\n",
      "Global step: 13796 - [========>---------------------]  28% - acc: 0.9062 - loss: 1.5546 - 320.2 sample/sec\n",
      "Global step: 13806 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4847 - 325.4 sample/sec\n",
      "Global step: 13816 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5546 - 319.0 sample/sec\n",
      "Global step: 13826 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5467 - 341.2 sample/sec\n",
      "Global step: 13836 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5315 - 308.4 sample/sec\n",
      "Global step: 13846 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5314 - 270.2 sample/sec\n",
      "Global step: 13856 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 273.4 sample/sec\n",
      "Global step: 13866 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5313 - 279.6 sample/sec\n",
      "Global step: 13876 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5228 - 291.2 sample/sec\n",
      "Global step: 13886 - [==============>---------------]  51% - acc: 0.8672 - loss: 1.5930 - 295.7 sample/sec\n",
      "Global step: 13896 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5388 - 305.5 sample/sec\n",
      "Global step: 13906 - [================>-------------]  56% - acc: 0.9609 - loss: 1.5003 - 309.4 sample/sec\n",
      "Global step: 13916 - [=================>------------]  59% - acc: 0.9141 - loss: 1.5470 - 312.4 sample/sec\n",
      "Global step: 13926 - [=================>------------]  61% - acc: 0.8828 - loss: 1.5780 - 304.3 sample/sec\n",
      "Global step: 13936 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5703 - 323.7 sample/sec\n",
      "Global step: 13946 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5313 - 325.8 sample/sec\n",
      "Global step: 13956 - [====================>---------]  69% - acc: 0.9375 - loss: 1.5256 - 323.7 sample/sec\n",
      "Global step: 13966 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5317 - 339.7 sample/sec\n",
      "Global step: 13976 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5081 - 337.2 sample/sec\n",
      "Global step: 13986 - [======================>-------]  77% - acc: 0.9297 - loss: 1.5322 - 339.2 sample/sec\n",
      "Global step: 13996 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5853 - 329.9 sample/sec\n",
      "Global step: 14006 - [=======================>------]  82% - acc: 0.9062 - loss: 1.5512 - 348.3 sample/sec\n",
      "Global step: 14016 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4849 - 342.1 sample/sec\n",
      "Global step: 14026 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5474 - 359.6 sample/sec\n",
      "Global step: 14036 - [==========================>---]  90% - acc: 0.9297 - loss: 1.5311 - 356.3 sample/sec\n",
      "Global step: 14046 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5157 - 347.9 sample/sec\n",
      "Global step: 14056 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5384 - 343.3 sample/sec\n",
      "Global step: 14066 - [============================>-]  97% - acc: 0.9375 - loss: 1.5229 - 298.2 sample/sec\n",
      "Global step: 14076 - [=============================>] 100% - acc: 0.9375 - loss: 1.5235 - 468.5 sample/sec\n",
      "\n",
      "Epoch 36 - accuracy: 78.02% (7802/10000) - time: 00:03:00.64\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 37/60\n",
      "\n",
      "Global step: 14077 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5081 - 290.7 sample/sec\n",
      "Global step: 14087 - [>-----------------------------]   3% - acc: 0.9375 - loss: 1.5203 - 275.3 sample/sec\n",
      "Global step: 14097 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5157 - 270.1 sample/sec\n",
      "Global step: 14107 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5169 - 282.0 sample/sec\n",
      "Global step: 14117 - [==>---------------------------]  10% - acc: 0.9297 - loss: 1.5290 - 292.4 sample/sec\n",
      "Global step: 14127 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5090 - 304.7 sample/sec\n",
      "Global step: 14137 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5156 - 312.1 sample/sec\n",
      "Global step: 14147 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5474 - 322.4 sample/sec\n",
      "Global step: 14157 - [=====>------------------------]  20% - acc: 0.9609 - loss: 1.4989 - 324.4 sample/sec\n",
      "Global step: 14167 - [======>-----------------------]  23% - acc: 0.9453 - loss: 1.5197 - 334.8 sample/sec\n",
      "Global step: 14177 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4874 - 333.3 sample/sec\n",
      "Global step: 14187 - [========>---------------------]  28% - acc: 0.9062 - loss: 1.5548 - 320.5 sample/sec\n",
      "Global step: 14197 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4846 - 331.7 sample/sec\n",
      "Global step: 14207 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5557 - 325.2 sample/sec\n",
      "Global step: 14217 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5466 - 332.2 sample/sec\n",
      "Global step: 14227 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5313 - 320.0 sample/sec\n",
      "Global step: 14237 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5325 - 330.7 sample/sec\n",
      "Global step: 14247 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5395 - 334.6 sample/sec\n",
      "Global step: 14257 - [=============>----------------]  46% - acc: 0.9219 - loss: 1.5362 - 332.3 sample/sec\n",
      "Global step: 14267 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5229 - 338.3 sample/sec\n",
      "Global step: 14277 - [==============>---------------]  51% - acc: 0.8672 - loss: 1.5948 - 328.9 sample/sec\n",
      "Global step: 14287 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5426 - 318.8 sample/sec\n",
      "Global step: 14297 - [================>-------------]  56% - acc: 0.9609 - loss: 1.4997 - 323.3 sample/sec\n",
      "Global step: 14307 - [=================>------------]  59% - acc: 0.9141 - loss: 1.5469 - 325.0 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 14317 - [=================>------------]  61% - acc: 0.8828 - loss: 1.5781 - 314.4 sample/sec\n",
      "Global step: 14327 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5704 - 310.3 sample/sec\n",
      "Global step: 14337 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5315 - 312.7 sample/sec\n",
      "Global step: 14347 - [====================>---------]  69% - acc: 0.9375 - loss: 1.5254 - 324.2 sample/sec\n",
      "Global step: 14357 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5346 - 326.2 sample/sec\n",
      "Global step: 14367 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5084 - 322.4 sample/sec\n",
      "Global step: 14377 - [======================>-------]  77% - acc: 0.9297 - loss: 1.5315 - 318.1 sample/sec\n",
      "Global step: 14387 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5853 - 320.3 sample/sec\n",
      "Global step: 14397 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5436 - 323.4 sample/sec\n",
      "Global step: 14407 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 322.1 sample/sec\n",
      "Global step: 14417 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5482 - 308.9 sample/sec\n",
      "Global step: 14427 - [==========================>---]  90% - acc: 0.9297 - loss: 1.5308 - 326.9 sample/sec\n",
      "Global step: 14437 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5155 - 343.2 sample/sec\n",
      "Global step: 14447 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5391 - 344.2 sample/sec\n",
      "Global step: 14457 - [============================>-]  97% - acc: 0.9375 - loss: 1.5236 - 341.5 sample/sec\n",
      "Global step: 14467 - [=============================>] 100% - acc: 0.9375 - loss: 1.5237 - 535.2 sample/sec\n",
      "\n",
      "Epoch 37 - accuracy: 78.07% (7807/10000) - time: 00:02:46.74\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 38/60\n",
      "\n",
      "Global step: 14468 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5081 - 334.3 sample/sec\n",
      "Global step: 14478 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5116 - 321.8 sample/sec\n",
      "Global step: 14488 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5158 - 320.7 sample/sec\n",
      "Global step: 14498 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5161 - 333.6 sample/sec\n",
      "Global step: 14508 - [==>---------------------------]  10% - acc: 0.9453 - loss: 1.5157 - 331.0 sample/sec\n",
      "Global step: 14518 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5095 - 338.1 sample/sec\n",
      "Global step: 14528 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5154 - 350.5 sample/sec\n",
      "Global step: 14538 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5470 - 346.1 sample/sec\n",
      "Global step: 14548 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4932 - 349.3 sample/sec\n",
      "Global step: 14558 - [======>-----------------------]  23% - acc: 0.9453 - loss: 1.5164 - 345.5 sample/sec\n",
      "Global step: 14568 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4865 - 353.6 sample/sec\n",
      "Global step: 14578 - [========>---------------------]  28% - acc: 0.9062 - loss: 1.5533 - 345.5 sample/sec\n",
      "Global step: 14588 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4847 - 354.7 sample/sec\n",
      "Global step: 14598 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5546 - 356.1 sample/sec\n",
      "Global step: 14608 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5467 - 348.0 sample/sec\n",
      "Global step: 14618 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5318 - 347.7 sample/sec\n",
      "Global step: 14628 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5309 - 332.7 sample/sec\n",
      "Global step: 14638 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 334.4 sample/sec\n",
      "Global step: 14648 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5309 - 327.3 sample/sec\n",
      "Global step: 14658 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5232 - 311.8 sample/sec\n",
      "Global step: 14668 - [==============>---------------]  51% - acc: 0.8672 - loss: 1.5930 - 320.4 sample/sec\n",
      "Global step: 14678 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5395 - 321.8 sample/sec\n",
      "Global step: 14688 - [================>-------------]  56% - acc: 0.9609 - loss: 1.5002 - 320.4 sample/sec\n",
      "Global step: 14698 - [=================>------------]  59% - acc: 0.9141 - loss: 1.5467 - 319.2 sample/sec\n",
      "Global step: 14708 - [=================>------------]  61% - acc: 0.8828 - loss: 1.5791 - 325.4 sample/sec\n",
      "Global step: 14718 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5705 - 318.9 sample/sec\n",
      "Global step: 14728 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5312 - 317.0 sample/sec\n",
      "Global step: 14738 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5156 - 324.0 sample/sec\n",
      "Global step: 14748 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5339 - 320.5 sample/sec\n",
      "Global step: 14758 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5080 - 318.0 sample/sec\n",
      "Global step: 14768 - [======================>-------]  77% - acc: 0.9297 - loss: 1.5312 - 323.5 sample/sec\n",
      "Global step: 14778 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5851 - 314.3 sample/sec\n",
      "Global step: 14788 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5392 - 314.9 sample/sec\n",
      "Global step: 14798 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4849 - 324.1 sample/sec\n",
      "Global step: 14808 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5465 - 321.8 sample/sec\n",
      "Global step: 14818 - [==========================>---]  90% - acc: 0.9297 - loss: 1.5307 - 320.6 sample/sec\n",
      "Global step: 14828 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5153 - 326.0 sample/sec\n",
      "Global step: 14838 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5398 - 331.3 sample/sec\n",
      "Global step: 14848 - [============================>-]  97% - acc: 0.9375 - loss: 1.5233 - 330.2 sample/sec\n",
      "Global step: 14858 - [=============================>] 100% - acc: 0.9250 - loss: 1.5307 - 530.3 sample/sec\n",
      "\n",
      "Epoch 38 - accuracy: 77.99% (7799/10000) - time: 00:02:41.31\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 39/60\n",
      "\n",
      "Global step: 14859 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5080 - 339.2 sample/sec\n",
      "Global step: 14869 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5081 - 287.0 sample/sec\n",
      "Global step: 14879 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5155 - 293.0 sample/sec\n",
      "Global step: 14889 - [==>---------------------------]   8% - acc: 0.9375 - loss: 1.5193 - 312.3 sample/sec\n",
      "Global step: 14899 - [==>---------------------------]  10% - acc: 0.9453 - loss: 1.5172 - 317.4 sample/sec\n",
      "Global step: 14909 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5083 - 313.3 sample/sec\n",
      "Global step: 14919 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5158 - 322.1 sample/sec\n",
      "Global step: 14929 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5479 - 319.5 sample/sec\n",
      "Global step: 14939 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4926 - 326.9 sample/sec\n",
      "Global step: 14949 - [======>-----------------------]  23% - acc: 0.9453 - loss: 1.5158 - 324.4 sample/sec\n",
      "Global step: 14959 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4847 - 330.5 sample/sec\n",
      "Global step: 14969 - [========>---------------------]  28% - acc: 0.9219 - loss: 1.5410 - 313.9 sample/sec\n",
      "Global step: 14979 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4849 - 312.1 sample/sec\n",
      "Global step: 14989 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5548 - 291.9 sample/sec\n",
      "Global step: 14999 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5463 - 310.8 sample/sec\n",
      "Global step: 15009 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5309 - 289.2 sample/sec\n",
      "Global step: 15019 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5307 - 303.4 sample/sec\n",
      "Global step: 15029 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 286.3 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 15039 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5312 - 303.9 sample/sec\n",
      "Global step: 15049 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5236 - 281.6 sample/sec\n",
      "Global step: 15059 - [==============>---------------]  51% - acc: 0.8672 - loss: 1.5909 - 286.3 sample/sec\n",
      "Global step: 15069 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5391 - 289.2 sample/sec\n",
      "Global step: 15079 - [================>-------------]  56% - acc: 0.9609 - loss: 1.4992 - 298.0 sample/sec\n",
      "Global step: 15089 - [=================>------------]  59% - acc: 0.9141 - loss: 1.5456 - 310.2 sample/sec\n",
      "Global step: 15099 - [=================>------------]  61% - acc: 0.8750 - loss: 1.5836 - 317.3 sample/sec\n",
      "Global step: 15109 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5707 - 328.8 sample/sec\n",
      "Global step: 15119 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5315 - 344.4 sample/sec\n",
      "Global step: 15129 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 338.1 sample/sec\n",
      "Global step: 15139 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 344.2 sample/sec\n",
      "Global step: 15149 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5080 - 330.7 sample/sec\n",
      "Global step: 15159 - [======================>-------]  77% - acc: 0.9297 - loss: 1.5312 - 332.7 sample/sec\n",
      "Global step: 15169 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5847 - 336.7 sample/sec\n",
      "Global step: 15179 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5393 - 327.6 sample/sec\n",
      "Global step: 15189 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 324.9 sample/sec\n",
      "Global step: 15199 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5465 - 330.7 sample/sec\n",
      "Global step: 15209 - [==========================>---]  90% - acc: 0.9297 - loss: 1.5311 - 323.6 sample/sec\n",
      "Global step: 15219 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5154 - 326.6 sample/sec\n",
      "Global step: 15229 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5389 - 329.2 sample/sec\n",
      "Global step: 15239 - [============================>-]  97% - acc: 0.9375 - loss: 1.5235 - 321.3 sample/sec\n",
      "Global step: 15249 - [=============================>] 100% - acc: 0.9375 - loss: 1.5242 - 522.8 sample/sec\n",
      "\n",
      "Epoch 39 - accuracy: 77.83% (7783/10000) - time: 00:02:48.73\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 40/60\n",
      "\n",
      "Global step: 15250 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5081 - 334.7 sample/sec\n",
      "Global step: 15260 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5082 - 317.8 sample/sec\n",
      "Global step: 15270 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5153 - 320.3 sample/sec\n",
      "Global step: 15280 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5154 - 330.9 sample/sec\n",
      "Global step: 15290 - [==>---------------------------]  10% - acc: 0.9453 - loss: 1.5156 - 341.1 sample/sec\n",
      "Global step: 15300 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5081 - 343.4 sample/sec\n",
      "Global step: 15310 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5158 - 313.9 sample/sec\n",
      "Global step: 15320 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5470 - 301.0 sample/sec\n",
      "Global step: 15330 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4923 - 319.5 sample/sec\n",
      "Global step: 15340 - [======>-----------------------]  23% - acc: 0.9453 - loss: 1.5155 - 300.5 sample/sec\n",
      "Global step: 15350 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4846 - 303.6 sample/sec\n",
      "Global step: 15360 - [========>---------------------]  28% - acc: 0.9219 - loss: 1.5394 - 301.7 sample/sec\n",
      "Global step: 15370 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4847 - 302.0 sample/sec\n",
      "Global step: 15380 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5541 - 278.8 sample/sec\n",
      "Global step: 15390 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5466 - 286.4 sample/sec\n",
      "Global step: 15400 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5310 - 290.5 sample/sec\n",
      "Global step: 15410 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5311 - 310.1 sample/sec\n",
      "Global step: 15420 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5394 - 323.3 sample/sec\n",
      "Global step: 15430 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5312 - 316.3 sample/sec\n",
      "Global step: 15440 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5230 - 327.6 sample/sec\n",
      "Global step: 15450 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5775 - 327.6 sample/sec\n",
      "Global step: 15460 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5390 - 321.9 sample/sec\n",
      "Global step: 15470 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4927 - 324.5 sample/sec\n",
      "Global step: 15480 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5321 - 327.8 sample/sec\n",
      "Global step: 15490 - [=================>------------]  61% - acc: 0.8906 - loss: 1.5701 - 343.5 sample/sec\n",
      "Global step: 15500 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5705 - 324.9 sample/sec\n",
      "Global step: 15510 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5314 - 334.3 sample/sec\n",
      "Global step: 15520 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5156 - 339.0 sample/sec\n",
      "Global step: 15530 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5314 - 335.7 sample/sec\n",
      "Global step: 15540 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5082 - 335.6 sample/sec\n",
      "Global step: 15550 - [======================>-------]  77% - acc: 0.9297 - loss: 1.5312 - 317.8 sample/sec\n",
      "Global step: 15560 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5850 - 334.8 sample/sec\n",
      "Global step: 15570 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5390 - 325.3 sample/sec\n",
      "Global step: 15580 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 339.4 sample/sec\n",
      "Global step: 15590 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5467 - 322.1 sample/sec\n",
      "Global step: 15600 - [==========================>---]  90% - acc: 0.9297 - loss: 1.5308 - 328.9 sample/sec\n",
      "Global step: 15610 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5154 - 314.3 sample/sec\n",
      "Global step: 15620 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5384 - 314.6 sample/sec\n",
      "Global step: 15630 - [============================>-]  97% - acc: 0.9375 - loss: 1.5226 - 296.1 sample/sec\n",
      "Global step: 15640 - [=============================>] 100% - acc: 0.9375 - loss: 1.5233 - 489.3 sample/sec\n",
      "\n",
      "Epoch 40 - accuracy: 77.92% (7792/10000) - time: 00:02:47.66\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 41/60\n",
      "\n",
      "Global step: 15641 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5081 - 330.5 sample/sec\n",
      "Global step: 15651 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5081 - 318.1 sample/sec\n",
      "Global step: 15661 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5155 - 311.2 sample/sec\n",
      "Global step: 15671 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5153 - 312.3 sample/sec\n",
      "Global step: 15681 - [==>---------------------------]  10% - acc: 0.9453 - loss: 1.5155 - 306.0 sample/sec\n",
      "Global step: 15691 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5079 - 311.6 sample/sec\n",
      "Global step: 15701 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5151 - 305.4 sample/sec\n",
      "Global step: 15711 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5471 - 319.1 sample/sec\n",
      "Global step: 15721 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4925 - 319.9 sample/sec\n",
      "Global step: 15731 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5099 - 328.7 sample/sec\n",
      "Global step: 15741 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4845 - 324.9 sample/sec\n",
      "Global step: 15751 - [========>---------------------]  28% - acc: 0.9297 - loss: 1.5322 - 318.0 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 15761 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4846 - 339.9 sample/sec\n",
      "Global step: 15771 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5543 - 336.9 sample/sec\n",
      "Global step: 15781 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5466 - 329.7 sample/sec\n",
      "Global step: 15791 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5313 - 334.6 sample/sec\n",
      "Global step: 15801 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5307 - 336.5 sample/sec\n",
      "Global step: 15811 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 330.7 sample/sec\n",
      "Global step: 15821 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5307 - 322.1 sample/sec\n",
      "Global step: 15831 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5231 - 329.0 sample/sec\n",
      "Global step: 15841 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5775 - 324.1 sample/sec\n",
      "Global step: 15851 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5389 - 325.1 sample/sec\n",
      "Global step: 15861 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4925 - 325.6 sample/sec\n",
      "Global step: 15871 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5314 - 324.0 sample/sec\n",
      "Global step: 15881 - [=================>------------]  61% - acc: 0.8906 - loss: 1.5700 - 313.7 sample/sec\n",
      "Global step: 15891 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5703 - 319.7 sample/sec\n",
      "Global step: 15901 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5312 - 309.9 sample/sec\n",
      "Global step: 15911 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5161 - 318.9 sample/sec\n",
      "Global step: 15921 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 306.0 sample/sec\n",
      "Global step: 15931 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5078 - 315.3 sample/sec\n",
      "Global step: 15941 - [======================>-------]  77% - acc: 0.9297 - loss: 1.5309 - 316.7 sample/sec\n",
      "Global step: 15951 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5855 - 314.1 sample/sec\n",
      "Global step: 15961 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5410 - 312.5 sample/sec\n",
      "Global step: 15971 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 323.1 sample/sec\n",
      "Global step: 15981 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5465 - 325.9 sample/sec\n",
      "Global step: 15991 - [==========================>---]  90% - acc: 0.9297 - loss: 1.5308 - 311.9 sample/sec\n",
      "Global step: 16001 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5154 - 328.1 sample/sec\n",
      "Global step: 16011 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5384 - 328.5 sample/sec\n",
      "Global step: 16021 - [============================>-]  97% - acc: 0.9375 - loss: 1.5208 - 335.4 sample/sec\n",
      "Global step: 16031 - [=============================>] 100% - acc: 0.9375 - loss: 1.5232 - 517.2 sample/sec\n",
      "\n",
      "Epoch 41 - accuracy: 77.85% (7785/10000) - time: 00:02:46.12\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 42/60\n",
      "\n",
      "Global step: 16032 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5079 - 326.3 sample/sec\n",
      "Global step: 16042 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5080 - 310.4 sample/sec\n",
      "Global step: 16052 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5151 - 308.2 sample/sec\n",
      "Global step: 16062 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5155 - 319.3 sample/sec\n",
      "Global step: 16072 - [==>---------------------------]  10% - acc: 0.9453 - loss: 1.5158 - 313.6 sample/sec\n",
      "Global step: 16082 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5082 - 312.3 sample/sec\n",
      "Global step: 16092 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5152 - 311.7 sample/sec\n",
      "Global step: 16102 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5469 - 316.4 sample/sec\n",
      "Global step: 16112 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4925 - 302.3 sample/sec\n",
      "Global step: 16122 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5081 - 317.0 sample/sec\n",
      "Global step: 16132 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4847 - 307.6 sample/sec\n",
      "Global step: 16142 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5261 - 317.5 sample/sec\n",
      "Global step: 16152 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4854 - 320.7 sample/sec\n",
      "Global step: 16162 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5544 - 324.1 sample/sec\n",
      "Global step: 16172 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5464 - 304.2 sample/sec\n",
      "Global step: 16182 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5310 - 326.6 sample/sec\n",
      "Global step: 16192 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5308 - 317.5 sample/sec\n",
      "Global step: 16202 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5394 - 317.7 sample/sec\n",
      "Global step: 16212 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5308 - 322.4 sample/sec\n",
      "Global step: 16222 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5231 - 323.2 sample/sec\n",
      "Global step: 16232 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5784 - 308.6 sample/sec\n",
      "Global step: 16242 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 302.8 sample/sec\n",
      "Global step: 16252 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 313.0 sample/sec\n",
      "Global step: 16262 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5314 - 306.2 sample/sec\n",
      "Global step: 16272 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5638 - 310.7 sample/sec\n",
      "Global step: 16282 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5704 - 316.3 sample/sec\n",
      "Global step: 16292 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5311 - 322.1 sample/sec\n",
      "Global step: 16302 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 334.8 sample/sec\n",
      "Global step: 16312 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 331.1 sample/sec\n",
      "Global step: 16322 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5077 - 335.9 sample/sec\n",
      "Global step: 16332 - [======================>-------]  77% - acc: 0.9297 - loss: 1.5304 - 317.4 sample/sec\n",
      "Global step: 16342 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5847 - 323.3 sample/sec\n",
      "Global step: 16352 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5390 - 310.1 sample/sec\n",
      "Global step: 16362 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 319.0 sample/sec\n",
      "Global step: 16372 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5462 - 318.8 sample/sec\n",
      "Global step: 16382 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5235 - 312.9 sample/sec\n",
      "Global step: 16392 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 285.6 sample/sec\n",
      "Global step: 16402 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5385 - 314.3 sample/sec\n",
      "Global step: 16412 - [============================>-]  97% - acc: 0.9453 - loss: 1.5152 - 320.8 sample/sec\n",
      "Global step: 16422 - [=============================>] 100% - acc: 0.9375 - loss: 1.5234 - 503.4 sample/sec\n",
      "\n",
      "Epoch 42 - accuracy: 77.86% (7786/10000) - time: 00:02:49.18\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 43/60\n",
      "\n",
      "Global step: 16423 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5080 - 336.2 sample/sec\n",
      "Global step: 16433 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5080 - 316.9 sample/sec\n",
      "Global step: 16443 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5151 - 316.5 sample/sec\n",
      "Global step: 16453 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5153 - 316.6 sample/sec\n",
      "Global step: 16463 - [==>---------------------------]  10% - acc: 0.9453 - loss: 1.5157 - 317.5 sample/sec\n",
      "Global step: 16473 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5078 - 316.4 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 16483 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5151 - 336.0 sample/sec\n",
      "Global step: 16493 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5470 - 314.7 sample/sec\n",
      "Global step: 16503 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4923 - 310.3 sample/sec\n",
      "Global step: 16513 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 303.9 sample/sec\n",
      "Global step: 16523 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4846 - 316.7 sample/sec\n",
      "Global step: 16533 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5239 - 313.8 sample/sec\n",
      "Global step: 16543 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4847 - 300.8 sample/sec\n",
      "Global step: 16553 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5543 - 312.3 sample/sec\n",
      "Global step: 16563 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5462 - 319.2 sample/sec\n",
      "Global step: 16573 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5309 - 312.7 sample/sec\n",
      "Global step: 16583 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5308 - 317.6 sample/sec\n",
      "Global step: 16593 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 319.2 sample/sec\n",
      "Global step: 16603 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5309 - 321.5 sample/sec\n",
      "Global step: 16613 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5231 - 333.1 sample/sec\n",
      "Global step: 16623 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5781 - 339.3 sample/sec\n",
      "Global step: 16633 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 337.0 sample/sec\n",
      "Global step: 16643 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4920 - 336.5 sample/sec\n",
      "Global step: 16653 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5313 - 337.5 sample/sec\n",
      "Global step: 16663 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5625 - 345.3 sample/sec\n",
      "Global step: 16673 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5704 - 344.4 sample/sec\n",
      "Global step: 16683 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5311 - 348.4 sample/sec\n",
      "Global step: 16693 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 335.7 sample/sec\n",
      "Global step: 16703 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 332.3 sample/sec\n",
      "Global step: 16713 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5078 - 334.3 sample/sec\n",
      "Global step: 16723 - [======================>-------]  77% - acc: 0.9297 - loss: 1.5301 - 337.8 sample/sec\n",
      "Global step: 16733 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5845 - 325.8 sample/sec\n",
      "Global step: 16743 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5387 - 315.7 sample/sec\n",
      "Global step: 16753 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 330.9 sample/sec\n",
      "Global step: 16763 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5462 - 330.4 sample/sec\n",
      "Global step: 16773 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5227 - 345.2 sample/sec\n",
      "Global step: 16783 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 331.3 sample/sec\n",
      "Global step: 16793 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5385 - 336.1 sample/sec\n",
      "Global step: 16803 - [============================>-]  97% - acc: 0.9453 - loss: 1.5151 - 338.2 sample/sec\n",
      "Global step: 16813 - [=============================>] 100% - acc: 0.9375 - loss: 1.5233 - 537.2 sample/sec\n",
      "\n",
      "Epoch 43 - accuracy: 77.90% (7790/10000) - time: 00:02:44.22\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 44/60\n",
      "\n",
      "Global step: 16814 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5080 - 320.7 sample/sec\n",
      "Global step: 16824 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5081 - 305.4 sample/sec\n",
      "Global step: 16834 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5150 - 316.4 sample/sec\n",
      "Global step: 16844 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5153 - 324.7 sample/sec\n",
      "Global step: 16854 - [==>---------------------------]  10% - acc: 0.9453 - loss: 1.5156 - 316.2 sample/sec\n",
      "Global step: 16864 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5078 - 318.2 sample/sec\n",
      "Global step: 16874 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5150 - 327.4 sample/sec\n",
      "Global step: 16884 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5469 - 327.7 sample/sec\n",
      "Global step: 16894 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4922 - 339.0 sample/sec\n",
      "Global step: 16904 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 335.1 sample/sec\n",
      "Global step: 16914 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4846 - 330.8 sample/sec\n",
      "Global step: 16924 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5238 - 334.5 sample/sec\n",
      "Global step: 16934 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4846 - 334.0 sample/sec\n",
      "Global step: 16944 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5543 - 326.8 sample/sec\n",
      "Global step: 16954 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5461 - 329.8 sample/sec\n",
      "Global step: 16964 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5309 - 315.2 sample/sec\n",
      "Global step: 16974 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5307 - 316.0 sample/sec\n",
      "Global step: 16984 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 319.8 sample/sec\n",
      "Global step: 16994 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5308 - 319.0 sample/sec\n",
      "Global step: 17004 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5230 - 313.6 sample/sec\n",
      "Global step: 17014 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5780 - 314.5 sample/sec\n",
      "Global step: 17024 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 286.5 sample/sec\n",
      "Global step: 17034 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4920 - 304.5 sample/sec\n",
      "Global step: 17044 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5313 - 288.4 sample/sec\n",
      "Global step: 17054 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5624 - 296.4 sample/sec\n",
      "Global step: 17064 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5704 - 300.0 sample/sec\n",
      "Global step: 17074 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5310 - 311.1 sample/sec\n",
      "Global step: 17084 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 304.2 sample/sec\n",
      "Global step: 17094 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 319.7 sample/sec\n",
      "Global step: 17104 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5078 - 307.2 sample/sec\n",
      "Global step: 17114 - [======================>-------]  77% - acc: 0.9297 - loss: 1.5291 - 320.0 sample/sec\n",
      "Global step: 17124 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 309.6 sample/sec\n",
      "Global step: 17134 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5387 - 333.2 sample/sec\n",
      "Global step: 17144 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 328.7 sample/sec\n",
      "Global step: 17154 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5461 - 332.9 sample/sec\n",
      "Global step: 17164 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5226 - 326.0 sample/sec\n",
      "Global step: 17174 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 329.9 sample/sec\n",
      "Global step: 17184 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5384 - 323.8 sample/sec\n",
      "Global step: 17194 - [============================>-]  97% - acc: 0.9453 - loss: 1.5151 - 324.6 sample/sec\n",
      "Global step: 17204 - [=============================>] 100% - acc: 0.9375 - loss: 1.5233 - 525.2 sample/sec\n",
      "\n",
      "Epoch 44 - accuracy: 77.86% (7786/10000) - time: 00:02:48.07\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 45/60\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 17205 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5080 - 330.7 sample/sec\n",
      "Global step: 17215 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5081 - 314.8 sample/sec\n",
      "Global step: 17225 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5145 - 317.9 sample/sec\n",
      "Global step: 17235 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5153 - 321.5 sample/sec\n",
      "Global step: 17245 - [==>---------------------------]  10% - acc: 0.9453 - loss: 1.5154 - 315.2 sample/sec\n",
      "Global step: 17255 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5077 - 322.0 sample/sec\n",
      "Global step: 17265 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5150 - 314.8 sample/sec\n",
      "Global step: 17275 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5470 - 313.6 sample/sec\n",
      "Global step: 17285 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4922 - 310.3 sample/sec\n",
      "Global step: 17295 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 307.2 sample/sec\n",
      "Global step: 17305 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4845 - 318.8 sample/sec\n",
      "Global step: 17315 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5235 - 310.3 sample/sec\n",
      "Global step: 17325 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4846 - 302.6 sample/sec\n",
      "Global step: 17335 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5543 - 306.7 sample/sec\n",
      "Global step: 17345 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5461 - 307.3 sample/sec\n",
      "Global step: 17355 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5308 - 314.2 sample/sec\n",
      "Global step: 17365 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5307 - 316.6 sample/sec\n",
      "Global step: 17375 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 320.5 sample/sec\n",
      "Global step: 17385 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5307 - 306.6 sample/sec\n",
      "Global step: 17395 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5229 - 295.2 sample/sec\n",
      "Global step: 17405 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5780 - 297.7 sample/sec\n",
      "Global step: 17415 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 308.7 sample/sec\n",
      "Global step: 17425 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 322.3 sample/sec\n",
      "Global step: 17435 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5313 - 323.7 sample/sec\n",
      "Global step: 17445 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5623 - 322.7 sample/sec\n",
      "Global step: 17455 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5703 - 313.9 sample/sec\n",
      "Global step: 17465 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5310 - 325.8 sample/sec\n",
      "Global step: 17475 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 290.3 sample/sec\n",
      "Global step: 17485 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 261.7 sample/sec\n",
      "Global step: 17495 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5078 - 292.2 sample/sec\n",
      "Global step: 17505 - [======================>-------]  77% - acc: 0.9375 - loss: 1.5254 - 293.0 sample/sec\n",
      "Global step: 17515 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 269.3 sample/sec\n",
      "Global step: 17525 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5387 - 293.0 sample/sec\n",
      "Global step: 17535 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 279.6 sample/sec\n",
      "Global step: 17545 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5459 - 259.8 sample/sec\n",
      "Global step: 17555 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5226 - 279.9 sample/sec\n",
      "Global step: 17565 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 239.0 sample/sec\n",
      "Global step: 17575 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5383 - 275.2 sample/sec\n",
      "Global step: 17585 - [============================>-]  97% - acc: 0.9453 - loss: 1.5151 - 278.0 sample/sec\n",
      "Global step: 17595 - [=============================>] 100% - acc: 0.9375 - loss: 1.5233 - 468.5 sample/sec\n",
      "\n",
      "Epoch 45 - accuracy: 77.87% (7787/10000) - time: 00:02:58.77\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 46/60\n",
      "\n",
      "Global step: 17596 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5079 - 299.8 sample/sec\n",
      "Global step: 17606 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5081 - 305.0 sample/sec\n",
      "Global step: 17616 - [=>----------------------------]   5% - acc: 0.9453 - loss: 1.5120 - 271.1 sample/sec\n",
      "Global step: 17626 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5153 - 287.0 sample/sec\n",
      "Global step: 17636 - [==>---------------------------]  10% - acc: 0.9453 - loss: 1.5153 - 266.9 sample/sec\n",
      "Global step: 17646 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5077 - 274.2 sample/sec\n",
      "Global step: 17656 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5150 - 270.7 sample/sec\n",
      "Global step: 17666 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5470 - 285.8 sample/sec\n",
      "Global step: 17676 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 305.1 sample/sec\n",
      "Global step: 17686 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 298.9 sample/sec\n",
      "Global step: 17696 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4846 - 305.6 sample/sec\n",
      "Global step: 17706 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5234 - 324.2 sample/sec\n",
      "Global step: 17716 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4846 - 279.0 sample/sec\n",
      "Global step: 17726 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5543 - 307.6 sample/sec\n",
      "Global step: 17736 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5461 - 310.0 sample/sec\n",
      "Global step: 17746 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5307 - 304.8 sample/sec\n",
      "Global step: 17756 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5307 - 316.2 sample/sec\n",
      "Global step: 17766 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 306.4 sample/sec\n",
      "Global step: 17776 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5306 - 319.0 sample/sec\n",
      "Global step: 17786 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5228 - 312.3 sample/sec\n",
      "Global step: 17796 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5779 - 294.5 sample/sec\n",
      "Global step: 17806 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 304.7 sample/sec\n",
      "Global step: 17816 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4920 - 299.5 sample/sec\n",
      "Global step: 17826 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5312 - 312.0 sample/sec\n",
      "Global step: 17836 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5622 - 298.6 sample/sec\n",
      "Global step: 17846 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5703 - 324.4 sample/sec\n",
      "Global step: 17856 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5309 - 337.3 sample/sec\n",
      "Global step: 17866 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 330.3 sample/sec\n",
      "Global step: 17876 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 337.3 sample/sec\n",
      "Global step: 17886 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5078 - 322.4 sample/sec\n",
      "Global step: 17896 - [======================>-------]  77% - acc: 0.9375 - loss: 1.5233 - 338.1 sample/sec\n",
      "Global step: 17906 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 304.6 sample/sec\n",
      "Global step: 17916 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5387 - 303.9 sample/sec\n",
      "Global step: 17926 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 297.0 sample/sec\n",
      "Global step: 17936 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5457 - 285.4 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 17946 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5226 - 285.4 sample/sec\n",
      "Global step: 17956 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 292.0 sample/sec\n",
      "Global step: 17966 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5383 - 276.6 sample/sec\n",
      "Global step: 17976 - [============================>-]  97% - acc: 0.9453 - loss: 1.5151 - 282.8 sample/sec\n",
      "Global step: 17986 - [=============================>] 100% - acc: 0.9375 - loss: 1.5233 - 452.2 sample/sec\n",
      "\n",
      "Epoch 46 - accuracy: 77.91% (7791/10000) - time: 00:02:57.44\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 47/60\n",
      "\n",
      "Global step: 17987 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5079 - 319.4 sample/sec\n",
      "Global step: 17997 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5081 - 314.7 sample/sec\n",
      "Global step: 18007 - [=>----------------------------]   5% - acc: 0.9531 - loss: 1.5076 - 310.4 sample/sec\n",
      "Global step: 18017 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5153 - 311.5 sample/sec\n",
      "Global step: 18027 - [==>---------------------------]  10% - acc: 0.9453 - loss: 1.5151 - 321.3 sample/sec\n",
      "Global step: 18037 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5077 - 346.7 sample/sec\n",
      "Global step: 18047 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5149 - 326.2 sample/sec\n",
      "Global step: 18057 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5470 - 337.8 sample/sec\n",
      "Global step: 18067 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 337.7 sample/sec\n",
      "Global step: 18077 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 335.2 sample/sec\n",
      "Global step: 18087 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4846 - 322.8 sample/sec\n",
      "Global step: 18097 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5233 - 324.9 sample/sec\n",
      "Global step: 18107 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4846 - 304.5 sample/sec\n",
      "Global step: 18117 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5543 - 316.0 sample/sec\n",
      "Global step: 18127 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5460 - 303.0 sample/sec\n",
      "Global step: 18137 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5306 - 300.5 sample/sec\n",
      "Global step: 18147 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5307 - 302.5 sample/sec\n",
      "Global step: 18157 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 298.7 sample/sec\n",
      "Global step: 18167 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5307 - 292.8 sample/sec\n",
      "Global step: 18177 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5228 - 301.7 sample/sec\n",
      "Global step: 18187 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5778 - 268.7 sample/sec\n",
      "Global step: 18197 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 300.3 sample/sec\n",
      "Global step: 18207 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 300.1 sample/sec\n",
      "Global step: 18217 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5313 - 308.0 sample/sec\n",
      "Global step: 18227 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5621 - 300.8 sample/sec\n",
      "Global step: 18237 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5702 - 312.0 sample/sec\n",
      "Global step: 18247 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5309 - 316.8 sample/sec\n",
      "Global step: 18257 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 335.7 sample/sec\n",
      "Global step: 18267 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 345.1 sample/sec\n",
      "Global step: 18277 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5078 - 353.8 sample/sec\n",
      "Global step: 18287 - [======================>-------]  77% - acc: 0.9375 - loss: 1.5232 - 342.2 sample/sec\n",
      "Global step: 18297 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 342.4 sample/sec\n",
      "Global step: 18307 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5387 - 356.7 sample/sec\n",
      "Global step: 18317 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 356.5 sample/sec\n",
      "Global step: 18327 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5457 - 340.4 sample/sec\n",
      "Global step: 18337 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5226 - 357.2 sample/sec\n",
      "Global step: 18347 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 351.9 sample/sec\n",
      "Global step: 18357 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5383 - 357.6 sample/sec\n",
      "Global step: 18367 - [============================>-]  97% - acc: 0.9453 - loss: 1.5151 - 348.9 sample/sec\n",
      "Global step: 18377 - [=============================>] 100% - acc: 0.9375 - loss: 1.5233 - 539.3 sample/sec\n",
      "\n",
      "Epoch 47 - accuracy: 77.90% (7790/10000) - time: 00:02:43.94\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 48/60\n",
      "\n",
      "Global step: 18378 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5079 - 367.4 sample/sec\n",
      "Global step: 18388 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5081 - 353.9 sample/sec\n",
      "Global step: 18398 - [=>----------------------------]   5% - acc: 0.9531 - loss: 1.5075 - 362.0 sample/sec\n",
      "Global step: 18408 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5153 - 356.7 sample/sec\n",
      "Global step: 18418 - [==>---------------------------]  10% - acc: 0.9453 - loss: 1.5147 - 359.8 sample/sec\n",
      "Global step: 18428 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5077 - 341.4 sample/sec\n",
      "Global step: 18438 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5149 - 361.5 sample/sec\n",
      "Global step: 18448 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5470 - 353.0 sample/sec\n",
      "Global step: 18458 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 358.7 sample/sec\n",
      "Global step: 18468 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 346.4 sample/sec\n",
      "Global step: 18478 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4846 - 343.9 sample/sec\n",
      "Global step: 18488 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5232 - 338.2 sample/sec\n",
      "Global step: 18498 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4846 - 337.9 sample/sec\n",
      "Global step: 18508 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5543 - 339.6 sample/sec\n",
      "Global step: 18518 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5460 - 344.0 sample/sec\n",
      "Global step: 18528 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5305 - 349.0 sample/sec\n",
      "Global step: 18538 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5307 - 350.9 sample/sec\n",
      "Global step: 18548 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 352.9 sample/sec\n",
      "Global step: 18558 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5307 - 358.3 sample/sec\n",
      "Global step: 18568 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5228 - 348.5 sample/sec\n",
      "Global step: 18578 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5777 - 354.8 sample/sec\n",
      "Global step: 18588 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 361.2 sample/sec\n",
      "Global step: 18598 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 359.5 sample/sec\n",
      "Global step: 18608 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5313 - 355.2 sample/sec\n",
      "Global step: 18618 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5620 - 352.0 sample/sec\n",
      "Global step: 18628 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5702 - 360.4 sample/sec\n",
      "Global step: 18638 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5307 - 355.1 sample/sec\n",
      "Global step: 18648 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 360.5 sample/sec\n",
      "Global step: 18658 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 351.0 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 18668 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5078 - 351.9 sample/sec\n",
      "Global step: 18678 - [======================>-------]  77% - acc: 0.9375 - loss: 1.5231 - 355.9 sample/sec\n",
      "Global step: 18688 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 359.8 sample/sec\n",
      "Global step: 18698 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5387 - 345.5 sample/sec\n",
      "Global step: 18708 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 360.4 sample/sec\n",
      "Global step: 18718 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5457 - 344.4 sample/sec\n",
      "Global step: 18728 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5227 - 350.7 sample/sec\n",
      "Global step: 18738 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 352.1 sample/sec\n",
      "Global step: 18748 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5383 - 340.8 sample/sec\n",
      "Global step: 18758 - [============================>-]  97% - acc: 0.9453 - loss: 1.5151 - 351.8 sample/sec\n",
      "Global step: 18768 - [=============================>] 100% - acc: 0.9375 - loss: 1.5233 - 565.1 sample/sec\n",
      "\n",
      "Epoch 48 - accuracy: 77.88% (7788/10000) - time: 00:02:31.62\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 49/60\n",
      "\n",
      "Global step: 18769 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5079 - 355.4 sample/sec\n",
      "Global step: 18779 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5081 - 347.6 sample/sec\n",
      "Global step: 18789 - [=>----------------------------]   5% - acc: 0.9531 - loss: 1.5075 - 342.7 sample/sec\n",
      "Global step: 18799 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5152 - 342.1 sample/sec\n",
      "Global step: 18809 - [==>---------------------------]  10% - acc: 0.9531 - loss: 1.5132 - 352.2 sample/sec\n",
      "Global step: 18819 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5076 - 359.8 sample/sec\n",
      "Global step: 18829 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5149 - 358.6 sample/sec\n",
      "Global step: 18839 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5470 - 356.8 sample/sec\n",
      "Global step: 18849 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 358.9 sample/sec\n",
      "Global step: 18859 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 356.5 sample/sec\n",
      "Global step: 18869 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4845 - 350.9 sample/sec\n",
      "Global step: 18879 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5232 - 361.8 sample/sec\n",
      "Global step: 18889 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4846 - 353.5 sample/sec\n",
      "Global step: 18899 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5543 - 355.9 sample/sec\n",
      "Global step: 18909 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5460 - 355.4 sample/sec\n",
      "Global step: 18919 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5304 - 364.7 sample/sec\n",
      "Global step: 18929 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5307 - 356.6 sample/sec\n",
      "Global step: 18939 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 359.2 sample/sec\n",
      "Global step: 18949 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5306 - 353.4 sample/sec\n",
      "Global step: 18959 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5227 - 356.8 sample/sec\n",
      "Global step: 18969 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5775 - 357.8 sample/sec\n",
      "Global step: 18979 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 357.1 sample/sec\n",
      "Global step: 18989 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 354.1 sample/sec\n",
      "Global step: 18999 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5313 - 350.5 sample/sec\n",
      "Global step: 19009 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5620 - 357.8 sample/sec\n",
      "Global step: 19019 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5702 - 360.8 sample/sec\n",
      "Global step: 19029 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5307 - 361.4 sample/sec\n",
      "Global step: 19039 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 355.6 sample/sec\n",
      "Global step: 19049 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 353.8 sample/sec\n",
      "Global step: 19059 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5078 - 362.2 sample/sec\n",
      "Global step: 19069 - [======================>-------]  77% - acc: 0.9375 - loss: 1.5230 - 352.6 sample/sec\n",
      "Global step: 19079 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 359.0 sample/sec\n",
      "Global step: 19089 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5386 - 345.0 sample/sec\n",
      "Global step: 19099 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 359.6 sample/sec\n",
      "Global step: 19109 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5457 - 353.7 sample/sec\n",
      "Global step: 19119 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5226 - 347.7 sample/sec\n",
      "Global step: 19129 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 354.6 sample/sec\n",
      "Global step: 19139 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5383 - 350.2 sample/sec\n",
      "Global step: 19149 - [============================>-]  97% - acc: 0.9453 - loss: 1.5151 - 348.2 sample/sec\n",
      "Global step: 19159 - [=============================>] 100% - acc: 0.9375 - loss: 1.5232 - 572.6 sample/sec\n",
      "\n",
      "Epoch 49 - accuracy: 77.91% (7791/10000) - time: 00:02:30.24\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 50/60\n",
      "\n",
      "Global step: 19160 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5078 - 368.8 sample/sec\n",
      "Global step: 19170 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5081 - 357.4 sample/sec\n",
      "Global step: 19180 - [=>----------------------------]   5% - acc: 0.9531 - loss: 1.5075 - 347.5 sample/sec\n",
      "Global step: 19190 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5152 - 353.2 sample/sec\n",
      "Global step: 19200 - [==>---------------------------]  10% - acc: 0.9531 - loss: 1.5096 - 356.8 sample/sec\n",
      "Global step: 19210 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5075 - 348.8 sample/sec\n",
      "Global step: 19220 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5149 - 361.4 sample/sec\n",
      "Global step: 19230 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5470 - 352.7 sample/sec\n",
      "Global step: 19240 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 349.8 sample/sec\n",
      "Global step: 19250 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 358.7 sample/sec\n",
      "Global step: 19260 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4845 - 353.0 sample/sec\n",
      "Global step: 19270 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5232 - 361.5 sample/sec\n",
      "Global step: 19280 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4846 - 353.3 sample/sec\n",
      "Global step: 19290 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5542 - 357.7 sample/sec\n",
      "Global step: 19300 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5460 - 354.6 sample/sec\n",
      "Global step: 19310 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5304 - 350.9 sample/sec\n",
      "Global step: 19320 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5307 - 354.9 sample/sec\n",
      "Global step: 19330 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 353.5 sample/sec\n",
      "Global step: 19340 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5306 - 360.7 sample/sec\n",
      "Global step: 19350 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5226 - 355.0 sample/sec\n",
      "Global step: 19360 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5773 - 336.3 sample/sec\n",
      "Global step: 19370 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 346.8 sample/sec\n",
      "Global step: 19380 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 350.7 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 19390 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5313 - 356.3 sample/sec\n",
      "Global step: 19400 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5620 - 350.9 sample/sec\n",
      "Global step: 19410 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5702 - 356.5 sample/sec\n",
      "Global step: 19420 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5306 - 356.5 sample/sec\n",
      "Global step: 19430 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 357.5 sample/sec\n",
      "Global step: 19440 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 361.5 sample/sec\n",
      "Global step: 19450 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5078 - 348.5 sample/sec\n",
      "Global step: 19460 - [======================>-------]  77% - acc: 0.9375 - loss: 1.5220 - 364.2 sample/sec\n",
      "Global step: 19470 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 350.0 sample/sec\n",
      "Global step: 19480 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5386 - 353.7 sample/sec\n",
      "Global step: 19490 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4847 - 356.5 sample/sec\n",
      "Global step: 19500 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5457 - 354.0 sample/sec\n",
      "Global step: 19510 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5226 - 358.2 sample/sec\n",
      "Global step: 19520 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 355.9 sample/sec\n",
      "Global step: 19530 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5382 - 360.1 sample/sec\n",
      "Global step: 19540 - [============================>-]  97% - acc: 0.9453 - loss: 1.5150 - 360.6 sample/sec\n",
      "Global step: 19550 - [=============================>] 100% - acc: 0.9375 - loss: 1.5232 - 573.2 sample/sec\n",
      "\n",
      "Epoch 50 - accuracy: 77.82% (7782/10000) - time: 00:02:29.86\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 51/60\n",
      "\n",
      "Global step: 19551 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5078 - 370.7 sample/sec\n",
      "Global step: 19561 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5081 - 341.1 sample/sec\n",
      "Global step: 19571 - [=>----------------------------]   5% - acc: 0.9531 - loss: 1.5076 - 346.4 sample/sec\n",
      "Global step: 19581 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5153 - 359.1 sample/sec\n",
      "Global step: 19591 - [==>---------------------------]  10% - acc: 0.9531 - loss: 1.5085 - 351.8 sample/sec\n",
      "Global step: 19601 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5075 - 353.4 sample/sec\n",
      "Global step: 19611 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5149 - 357.1 sample/sec\n",
      "Global step: 19621 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5469 - 354.6 sample/sec\n",
      "Global step: 19631 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 352.7 sample/sec\n",
      "Global step: 19641 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 359.9 sample/sec\n",
      "Global step: 19651 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4844 - 358.2 sample/sec\n",
      "Global step: 19661 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5232 - 357.3 sample/sec\n",
      "Global step: 19671 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4846 - 357.6 sample/sec\n",
      "Global step: 19681 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5541 - 355.9 sample/sec\n",
      "Global step: 19691 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5460 - 357.2 sample/sec\n",
      "Global step: 19701 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5304 - 360.9 sample/sec\n",
      "Global step: 19711 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5306 - 361.0 sample/sec\n",
      "Global step: 19721 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 360.3 sample/sec\n",
      "Global step: 19731 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5306 - 358.9 sample/sec\n",
      "Global step: 19741 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5224 - 354.8 sample/sec\n",
      "Global step: 19751 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5772 - 357.2 sample/sec\n",
      "Global step: 19761 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5388 - 355.3 sample/sec\n",
      "Global step: 19771 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 352.2 sample/sec\n",
      "Global step: 19781 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5313 - 356.1 sample/sec\n",
      "Global step: 19791 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5620 - 357.6 sample/sec\n",
      "Global step: 19801 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5702 - 345.5 sample/sec\n",
      "Global step: 19811 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5306 - 352.6 sample/sec\n",
      "Global step: 19821 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 356.3 sample/sec\n",
      "Global step: 19831 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 356.1 sample/sec\n",
      "Global step: 19841 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5078 - 358.6 sample/sec\n",
      "Global step: 19851 - [======================>-------]  77% - acc: 0.9453 - loss: 1.5160 - 361.7 sample/sec\n",
      "Global step: 19861 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 351.8 sample/sec\n",
      "Global step: 19871 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5385 - 368.2 sample/sec\n",
      "Global step: 19881 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 353.4 sample/sec\n",
      "Global step: 19891 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5457 - 357.3 sample/sec\n",
      "Global step: 19901 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5226 - 358.9 sample/sec\n",
      "Global step: 19911 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 356.1 sample/sec\n",
      "Global step: 19921 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5382 - 360.9 sample/sec\n",
      "Global step: 19931 - [============================>-]  97% - acc: 0.9453 - loss: 1.5150 - 357.2 sample/sec\n",
      "Global step: 19941 - [=============================>] 100% - acc: 0.9375 - loss: 1.5232 - 580.7 sample/sec\n",
      "\n",
      "Epoch 51 - accuracy: 77.89% (7789/10000) - time: 00:02:29.57\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 52/60\n",
      "\n",
      "Global step: 19942 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5078 - 369.9 sample/sec\n",
      "Global step: 19952 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5081 - 354.3 sample/sec\n",
      "Global step: 19962 - [=>----------------------------]   5% - acc: 0.9531 - loss: 1.5075 - 366.7 sample/sec\n",
      "Global step: 19972 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5152 - 359.7 sample/sec\n",
      "Global step: 19982 - [==>---------------------------]  10% - acc: 0.9531 - loss: 1.5083 - 361.8 sample/sec\n",
      "Global step: 19992 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5075 - 359.6 sample/sec\n",
      "Global step: 20002 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5149 - 371.4 sample/sec\n",
      "Global step: 20012 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5469 - 360.0 sample/sec\n",
      "Global step: 20022 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 362.6 sample/sec\n",
      "Global step: 20032 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 365.8 sample/sec\n",
      "Global step: 20042 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4843 - 364.6 sample/sec\n",
      "Global step: 20052 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5232 - 360.3 sample/sec\n",
      "Global step: 20062 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4846 - 367.0 sample/sec\n",
      "Global step: 20072 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5539 - 361.2 sample/sec\n",
      "Global step: 20082 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5460 - 361.6 sample/sec\n",
      "Global step: 20092 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5304 - 354.5 sample/sec\n",
      "Global step: 20102 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5306 - 364.7 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 20112 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 363.4 sample/sec\n",
      "Global step: 20122 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5306 - 357.7 sample/sec\n",
      "Global step: 20132 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5223 - 358.1 sample/sec\n",
      "Global step: 20142 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5772 - 360.7 sample/sec\n",
      "Global step: 20152 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5388 - 366.1 sample/sec\n",
      "Global step: 20162 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 360.6 sample/sec\n",
      "Global step: 20172 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5313 - 372.3 sample/sec\n",
      "Global step: 20182 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5620 - 365.5 sample/sec\n",
      "Global step: 20192 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5701 - 358.8 sample/sec\n",
      "Global step: 20202 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5306 - 370.0 sample/sec\n",
      "Global step: 20212 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 366.7 sample/sec\n",
      "Global step: 20222 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 370.4 sample/sec\n",
      "Global step: 20232 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5078 - 376.0 sample/sec\n",
      "Global step: 20242 - [======================>-------]  77% - acc: 0.9453 - loss: 1.5157 - 363.3 sample/sec\n",
      "Global step: 20252 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 366.8 sample/sec\n",
      "Global step: 20262 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5385 - 364.5 sample/sec\n",
      "Global step: 20272 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 364.2 sample/sec\n",
      "Global step: 20282 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5457 - 363.4 sample/sec\n",
      "Global step: 20292 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5226 - 365.1 sample/sec\n",
      "Global step: 20302 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 365.7 sample/sec\n",
      "Global step: 20312 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5382 - 375.3 sample/sec\n",
      "Global step: 20322 - [============================>-]  97% - acc: 0.9453 - loss: 1.5150 - 367.0 sample/sec\n",
      "Global step: 20332 - [=============================>] 100% - acc: 0.9375 - loss: 1.5232 - 585.1 sample/sec\n",
      "\n",
      "Epoch 52 - accuracy: 77.90% (7790/10000) - time: 00:02:25.81\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 53/60\n",
      "\n",
      "Global step: 20333 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5078 - 373.0 sample/sec\n",
      "Global step: 20343 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5080 - 352.2 sample/sec\n",
      "Global step: 20353 - [=>----------------------------]   5% - acc: 0.9531 - loss: 1.5075 - 363.3 sample/sec\n",
      "Global step: 20363 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5152 - 367.7 sample/sec\n",
      "Global step: 20373 - [==>---------------------------]  10% - acc: 0.9531 - loss: 1.5082 - 360.6 sample/sec\n",
      "Global step: 20383 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5075 - 365.6 sample/sec\n",
      "Global step: 20393 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5149 - 360.1 sample/sec\n",
      "Global step: 20403 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5468 - 366.7 sample/sec\n",
      "Global step: 20413 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 370.7 sample/sec\n",
      "Global step: 20423 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 362.0 sample/sec\n",
      "Global step: 20433 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4843 - 368.1 sample/sec\n",
      "Global step: 20443 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5232 - 370.0 sample/sec\n",
      "Global step: 20453 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4846 - 366.8 sample/sec\n",
      "Global step: 20463 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5537 - 372.4 sample/sec\n",
      "Global step: 20473 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5460 - 368.6 sample/sec\n",
      "Global step: 20483 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5304 - 366.3 sample/sec\n",
      "Global step: 20493 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5305 - 364.0 sample/sec\n",
      "Global step: 20503 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 374.8 sample/sec\n",
      "Global step: 20513 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5306 - 357.7 sample/sec\n",
      "Global step: 20523 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5223 - 372.2 sample/sec\n",
      "Global step: 20533 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5771 - 370.4 sample/sec\n",
      "Global step: 20543 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 362.8 sample/sec\n",
      "Global step: 20553 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 361.0 sample/sec\n",
      "Global step: 20563 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5313 - 360.1 sample/sec\n",
      "Global step: 20573 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5620 - 361.4 sample/sec\n",
      "Global step: 20583 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5701 - 371.2 sample/sec\n",
      "Global step: 20593 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5306 - 372.0 sample/sec\n",
      "Global step: 20603 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 368.5 sample/sec\n",
      "Global step: 20613 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 368.7 sample/sec\n",
      "Global step: 20623 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5078 - 365.8 sample/sec\n",
      "Global step: 20633 - [======================>-------]  77% - acc: 0.9453 - loss: 1.5156 - 361.7 sample/sec\n",
      "Global step: 20643 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 365.9 sample/sec\n",
      "Global step: 20653 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5384 - 371.4 sample/sec\n",
      "Global step: 20663 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 366.8 sample/sec\n",
      "Global step: 20673 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5457 - 362.4 sample/sec\n",
      "Global step: 20683 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5226 - 370.8 sample/sec\n",
      "Global step: 20693 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 374.3 sample/sec\n",
      "Global step: 20703 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5382 - 374.4 sample/sec\n",
      "Global step: 20713 - [============================>-]  97% - acc: 0.9453 - loss: 1.5149 - 370.1 sample/sec\n",
      "Global step: 20723 - [=============================>] 100% - acc: 0.9375 - loss: 1.5232 - 588.6 sample/sec\n",
      "\n",
      "Epoch 53 - accuracy: 77.83% (7783/10000) - time: 00:02:25.41\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 54/60\n",
      "\n",
      "Global step: 20724 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5078 - 373.0 sample/sec\n",
      "Global step: 20734 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5080 - 368.2 sample/sec\n",
      "Global step: 20744 - [=>----------------------------]   5% - acc: 0.9531 - loss: 1.5074 - 359.9 sample/sec\n",
      "Global step: 20754 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5153 - 361.4 sample/sec\n",
      "Global step: 20764 - [==>---------------------------]  10% - acc: 0.9531 - loss: 1.5082 - 364.3 sample/sec\n",
      "Global step: 20774 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5075 - 363.1 sample/sec\n",
      "Global step: 20784 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5148 - 371.7 sample/sec\n",
      "Global step: 20794 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5468 - 367.1 sample/sec\n",
      "Global step: 20804 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 364.9 sample/sec\n",
      "Global step: 20814 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 371.2 sample/sec\n",
      "Global step: 20824 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4843 - 367.4 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 20834 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5231 - 360.9 sample/sec\n",
      "Global step: 20844 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4846 - 364.9 sample/sec\n",
      "Global step: 20854 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5534 - 362.2 sample/sec\n",
      "Global step: 20864 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5460 - 371.6 sample/sec\n",
      "Global step: 20874 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5304 - 368.2 sample/sec\n",
      "Global step: 20884 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5305 - 370.9 sample/sec\n",
      "Global step: 20894 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 366.4 sample/sec\n",
      "Global step: 20904 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5306 - 359.7 sample/sec\n",
      "Global step: 20914 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5223 - 362.7 sample/sec\n",
      "Global step: 20924 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5771 - 359.8 sample/sec\n",
      "Global step: 20934 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 369.5 sample/sec\n",
      "Global step: 20944 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 366.1 sample/sec\n",
      "Global step: 20954 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5313 - 367.2 sample/sec\n",
      "Global step: 20964 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5619 - 370.4 sample/sec\n",
      "Global step: 20974 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5700 - 373.0 sample/sec\n",
      "Global step: 20984 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5306 - 370.1 sample/sec\n",
      "Global step: 20994 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 365.8 sample/sec\n",
      "Global step: 21004 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 365.4 sample/sec\n",
      "Global step: 21014 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5077 - 365.1 sample/sec\n",
      "Global step: 21024 - [======================>-------]  77% - acc: 0.9453 - loss: 1.5156 - 363.1 sample/sec\n",
      "Global step: 21034 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 369.6 sample/sec\n",
      "Global step: 21044 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5384 - 369.5 sample/sec\n",
      "Global step: 21054 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 359.1 sample/sec\n",
      "Global step: 21064 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5457 - 358.6 sample/sec\n",
      "Global step: 21074 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5226 - 369.1 sample/sec\n",
      "Global step: 21084 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 367.8 sample/sec\n",
      "Global step: 21094 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5382 - 368.2 sample/sec\n",
      "Global step: 21104 - [============================>-]  97% - acc: 0.9453 - loss: 1.5148 - 363.9 sample/sec\n",
      "Global step: 21114 - [=============================>] 100% - acc: 0.9375 - loss: 1.5232 - 566.7 sample/sec\n",
      "\n",
      "Epoch 54 - accuracy: 77.87% (7787/10000) - time: 00:02:25.23\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 55/60\n",
      "\n",
      "Global step: 21115 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5078 - 378.9 sample/sec\n",
      "Global step: 21125 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5080 - 357.8 sample/sec\n",
      "Global step: 21135 - [=>----------------------------]   5% - acc: 0.9531 - loss: 1.5074 - 356.4 sample/sec\n",
      "Global step: 21145 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5153 - 361.7 sample/sec\n",
      "Global step: 21155 - [==>---------------------------]  10% - acc: 0.9531 - loss: 1.5082 - 365.1 sample/sec\n",
      "Global step: 21165 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5075 - 366.2 sample/sec\n",
      "Global step: 21175 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5149 - 363.0 sample/sec\n",
      "Global step: 21185 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5468 - 361.4 sample/sec\n",
      "Global step: 21195 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 363.3 sample/sec\n",
      "Global step: 21205 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 368.3 sample/sec\n",
      "Global step: 21215 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4843 - 366.4 sample/sec\n",
      "Global step: 21225 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5231 - 361.8 sample/sec\n",
      "Global step: 21235 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4845 - 364.8 sample/sec\n",
      "Global step: 21245 - [=========>--------------------]  33% - acc: 0.9062 - loss: 1.5524 - 333.6 sample/sec\n",
      "Global step: 21255 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5460 - 338.6 sample/sec\n",
      "Global step: 21265 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5304 - 353.1 sample/sec\n",
      "Global step: 21275 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5304 - 357.0 sample/sec\n",
      "Global step: 21285 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 356.4 sample/sec\n",
      "Global step: 21295 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5306 - 348.0 sample/sec\n",
      "Global step: 21305 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5223 - 329.9 sample/sec\n",
      "Global step: 21315 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5770 - 352.8 sample/sec\n",
      "Global step: 21325 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 354.7 sample/sec\n",
      "Global step: 21335 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 350.0 sample/sec\n",
      "Global step: 21345 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5312 - 341.9 sample/sec\n",
      "Global step: 21355 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5620 - 283.4 sample/sec\n",
      "Global step: 21365 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5699 - 276.8 sample/sec\n",
      "Global step: 21375 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5306 - 260.2 sample/sec\n",
      "Global step: 21385 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 255.5 sample/sec\n",
      "Global step: 21395 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 259.6 sample/sec\n",
      "Global step: 21405 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5077 - 290.6 sample/sec\n",
      "Global step: 21415 - [======================>-------]  77% - acc: 0.9453 - loss: 1.5156 - 309.1 sample/sec\n",
      "Global step: 21425 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 323.1 sample/sec\n",
      "Global step: 21435 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5385 - 326.3 sample/sec\n",
      "Global step: 21445 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 342.5 sample/sec\n",
      "Global step: 21455 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5457 - 351.3 sample/sec\n",
      "Global step: 21465 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5226 - 356.9 sample/sec\n",
      "Global step: 21475 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 341.4 sample/sec\n",
      "Global step: 21485 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5382 - 286.4 sample/sec\n",
      "Global step: 21495 - [============================>-]  97% - acc: 0.9453 - loss: 1.5148 - 266.1 sample/sec\n",
      "Global step: 21505 - [=============================>] 100% - acc: 0.9375 - loss: 1.5232 - 396.8 sample/sec\n",
      "\n",
      "Epoch 55 - accuracy: 77.88% (7788/10000) - time: 00:02:48.65\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 56/60\n",
      "\n",
      "Global step: 21506 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5078 - 163.5 sample/sec\n",
      "Global step: 21516 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5080 - 156.3 sample/sec\n",
      "Global step: 21526 - [=>----------------------------]   5% - acc: 0.9531 - loss: 1.5074 - 163.6 sample/sec\n",
      "Global step: 21536 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5152 - 176.3 sample/sec\n",
      "Global step: 21546 - [==>---------------------------]  10% - acc: 0.9531 - loss: 1.5081 - 211.5 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 21556 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5075 - 271.2 sample/sec\n",
      "Global step: 21566 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5148 - 272.0 sample/sec\n",
      "Global step: 21576 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5468 - 288.0 sample/sec\n",
      "Global step: 21586 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 267.9 sample/sec\n",
      "Global step: 21596 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 286.9 sample/sec\n",
      "Global step: 21606 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4844 - 283.4 sample/sec\n",
      "Global step: 21616 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5231 - 277.4 sample/sec\n",
      "Global step: 21626 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4845 - 201.9 sample/sec\n",
      "Global step: 21636 - [=========>--------------------]  33% - acc: 0.9141 - loss: 1.5477 - 256.1 sample/sec\n",
      "Global step: 21646 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5460 - 221.0 sample/sec\n",
      "Global step: 21656 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5304 - 211.8 sample/sec\n",
      "Global step: 21666 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5303 - 217.1 sample/sec\n",
      "Global step: 21676 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 234.4 sample/sec\n",
      "Global step: 21686 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5306 - 250.9 sample/sec\n",
      "Global step: 21696 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5223 - 245.7 sample/sec\n",
      "Global step: 21706 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5770 - 246.0 sample/sec\n",
      "Global step: 21716 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 232.4 sample/sec\n",
      "Global step: 21726 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 238.4 sample/sec\n",
      "Global step: 21736 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5312 - 232.5 sample/sec\n",
      "Global step: 21746 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5619 - 234.0 sample/sec\n",
      "Global step: 21756 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5698 - 259.4 sample/sec\n",
      "Global step: 21766 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5306 - 239.4 sample/sec\n",
      "Global step: 21776 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 242.6 sample/sec\n",
      "Global step: 21786 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 215.2 sample/sec\n",
      "Global step: 21796 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5077 - 199.4 sample/sec\n",
      "Global step: 21806 - [======================>-------]  77% - acc: 0.9453 - loss: 1.5156 - 203.2 sample/sec\n",
      "Global step: 21816 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 232.9 sample/sec\n",
      "Global step: 21826 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5385 - 270.8 sample/sec\n",
      "Global step: 21836 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 264.2 sample/sec\n",
      "Global step: 21846 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5457 - 237.7 sample/sec\n",
      "Global step: 21856 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5225 - 251.5 sample/sec\n",
      "Global step: 21866 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 269.7 sample/sec\n",
      "Global step: 21876 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5382 - 282.6 sample/sec\n",
      "Global step: 21886 - [============================>-]  97% - acc: 0.9453 - loss: 1.5148 - 283.9 sample/sec\n",
      "Global step: 21896 - [=============================>] 100% - acc: 0.9375 - loss: 1.5232 - 412.8 sample/sec\n",
      "\n",
      "Epoch 56 - accuracy: 77.82% (7782/10000) - time: 00:03:46.64\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 57/60\n",
      "\n",
      "Global step: 21897 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5078 - 229.6 sample/sec\n",
      "Global step: 21907 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5080 - 224.1 sample/sec\n",
      "Global step: 21917 - [=>----------------------------]   5% - acc: 0.9531 - loss: 1.5074 - 222.5 sample/sec\n",
      "Global step: 21927 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5152 - 242.2 sample/sec\n",
      "Global step: 21937 - [==>---------------------------]  10% - acc: 0.9531 - loss: 1.5081 - 242.4 sample/sec\n",
      "Global step: 21947 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5075 - 246.0 sample/sec\n",
      "Global step: 21957 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5148 - 243.3 sample/sec\n",
      "Global step: 21967 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5468 - 251.4 sample/sec\n",
      "Global step: 21977 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 255.8 sample/sec\n",
      "Global step: 21987 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 253.1 sample/sec\n",
      "Global step: 21997 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4843 - 257.6 sample/sec\n",
      "Global step: 22007 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5231 - 280.1 sample/sec\n",
      "Global step: 22017 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4844 - 251.0 sample/sec\n",
      "Global step: 22027 - [=========>--------------------]  33% - acc: 0.9141 - loss: 1.5465 - 267.3 sample/sec\n",
      "Global step: 22037 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5460 - 252.9 sample/sec\n",
      "Global step: 22047 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5304 - 242.7 sample/sec\n",
      "Global step: 22057 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5303 - 226.3 sample/sec\n",
      "Global step: 22067 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 228.8 sample/sec\n",
      "Global step: 22077 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5306 - 232.1 sample/sec\n",
      "Global step: 22087 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5223 - 243.7 sample/sec\n",
      "Global step: 22097 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5770 - 249.3 sample/sec\n",
      "Global step: 22107 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5387 - 227.1 sample/sec\n",
      "Global step: 22117 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 213.0 sample/sec\n",
      "Global step: 22127 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5312 - 216.2 sample/sec\n",
      "Global step: 22137 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5619 - 231.6 sample/sec\n",
      "Global step: 22147 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5698 - 205.0 sample/sec\n",
      "Global step: 22157 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5306 - 218.3 sample/sec\n",
      "Global step: 22167 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 207.0 sample/sec\n",
      "Global step: 22177 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 258.3 sample/sec\n",
      "Global step: 22187 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5077 - 232.1 sample/sec\n",
      "Global step: 22197 - [======================>-------]  77% - acc: 0.9453 - loss: 1.5156 - 232.2 sample/sec\n",
      "Global step: 22207 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 250.1 sample/sec\n",
      "Global step: 22217 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5385 - 243.2 sample/sec\n",
      "Global step: 22227 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 259.6 sample/sec\n",
      "Global step: 22237 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5457 - 271.2 sample/sec\n",
      "Global step: 22247 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5226 - 253.5 sample/sec\n",
      "Global step: 22257 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 224.5 sample/sec\n",
      "Global step: 22267 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5382 - 197.3 sample/sec\n",
      "Global step: 22277 - [============================>-]  97% - acc: 0.9453 - loss: 1.5148 - 210.2 sample/sec\n",
      "Global step: 22287 - [=============================>] 100% - acc: 0.9375 - loss: 1.5232 - 319.6 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 57 - accuracy: 77.88% (7788/10000) - time: 00:03:48.72\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 58/60\n",
      "\n",
      "Global step: 22288 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5078 - 199.8 sample/sec\n",
      "Global step: 22298 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5079 - 202.0 sample/sec\n",
      "Global step: 22308 - [=>----------------------------]   5% - acc: 0.9531 - loss: 1.5074 - 201.1 sample/sec\n",
      "Global step: 22318 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5152 - 204.3 sample/sec\n",
      "Global step: 22328 - [==>---------------------------]  10% - acc: 0.9531 - loss: 1.5081 - 202.8 sample/sec\n",
      "Global step: 22338 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5074 - 225.1 sample/sec\n",
      "Global step: 22348 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5148 - 224.1 sample/sec\n",
      "Global step: 22358 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5468 - 214.5 sample/sec\n",
      "Global step: 22368 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 209.4 sample/sec\n",
      "Global step: 22378 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 214.6 sample/sec\n",
      "Global step: 22388 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4843 - 250.0 sample/sec\n",
      "Global step: 22398 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5231 - 264.1 sample/sec\n",
      "Global step: 22408 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4844 - 273.9 sample/sec\n",
      "Global step: 22418 - [=========>--------------------]  33% - acc: 0.9141 - loss: 1.5464 - 293.0 sample/sec\n",
      "Global step: 22428 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5460 - 275.9 sample/sec\n",
      "Global step: 22438 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5304 - 266.0 sample/sec\n",
      "Global step: 22448 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5302 - 256.2 sample/sec\n",
      "Global step: 22458 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 245.3 sample/sec\n",
      "Global step: 22468 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5306 - 238.2 sample/sec\n",
      "Global step: 22478 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5223 - 230.8 sample/sec\n",
      "Global step: 22488 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5770 - 235.6 sample/sec\n",
      "Global step: 22498 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5386 - 235.1 sample/sec\n",
      "Global step: 22508 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 235.7 sample/sec\n",
      "Global step: 22518 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5312 - 228.7 sample/sec\n",
      "Global step: 22528 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5619 - 239.5 sample/sec\n",
      "Global step: 22538 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5698 - 227.4 sample/sec\n",
      "Global step: 22548 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5306 - 247.4 sample/sec\n",
      "Global step: 22558 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 271.4 sample/sec\n",
      "Global step: 22568 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 277.4 sample/sec\n",
      "Global step: 22578 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5077 - 256.4 sample/sec\n",
      "Global step: 22588 - [======================>-------]  77% - acc: 0.9453 - loss: 1.5156 - 257.8 sample/sec\n",
      "Global step: 22598 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 241.7 sample/sec\n",
      "Global step: 22608 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5384 - 251.6 sample/sec\n",
      "Global step: 22618 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 227.4 sample/sec\n",
      "Global step: 22628 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5457 - 228.1 sample/sec\n",
      "Global step: 22638 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5225 - 231.0 sample/sec\n",
      "Global step: 22648 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 245.5 sample/sec\n",
      "Global step: 22658 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5382 - 239.6 sample/sec\n",
      "Global step: 22668 - [============================>-]  97% - acc: 0.9453 - loss: 1.5148 - 235.6 sample/sec\n",
      "Global step: 22678 - [=============================>] 100% - acc: 0.9375 - loss: 1.5232 - 358.3 sample/sec\n",
      "\n",
      "Epoch 58 - accuracy: 77.90% (7790/10000) - time: 00:03:45.23\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 59/60\n",
      "\n",
      "Global step: 22679 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5078 - 240.6 sample/sec\n",
      "Global step: 22689 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5079 - 268.3 sample/sec\n",
      "Global step: 22699 - [=>----------------------------]   5% - acc: 0.9531 - loss: 1.5074 - 265.6 sample/sec\n",
      "Global step: 22709 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5152 - 274.8 sample/sec\n",
      "Global step: 22719 - [==>---------------------------]  10% - acc: 0.9531 - loss: 1.5081 - 272.7 sample/sec\n",
      "Global step: 22729 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5074 - 278.4 sample/sec\n",
      "Global step: 22739 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5148 - 279.7 sample/sec\n",
      "Global step: 22749 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5468 - 286.7 sample/sec\n",
      "Global step: 22759 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 269.0 sample/sec\n",
      "Global step: 22769 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 266.1 sample/sec\n",
      "Global step: 22779 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4843 - 257.8 sample/sec\n",
      "Global step: 22789 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5231 - 271.9 sample/sec\n",
      "Global step: 22799 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4844 - 260.5 sample/sec\n",
      "Global step: 22809 - [=========>--------------------]  33% - acc: 0.9141 - loss: 1.5463 - 256.0 sample/sec\n",
      "Global step: 22819 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5460 - 253.3 sample/sec\n",
      "Global step: 22829 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5304 - 240.7 sample/sec\n",
      "Global step: 22839 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5301 - 248.4 sample/sec\n",
      "Global step: 22849 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 261.8 sample/sec\n",
      "Global step: 22859 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5306 - 246.8 sample/sec\n",
      "Global step: 22869 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5223 - 267.0 sample/sec\n",
      "Global step: 22879 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5770 - 253.2 sample/sec\n",
      "Global step: 22889 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5386 - 263.3 sample/sec\n",
      "Global step: 22899 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 254.4 sample/sec\n",
      "Global step: 22909 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5312 - 249.7 sample/sec\n",
      "Global step: 22919 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5619 - 256.9 sample/sec\n",
      "Global step: 22929 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5698 - 240.9 sample/sec\n",
      "Global step: 22939 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5306 - 241.3 sample/sec\n",
      "Global step: 22949 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 238.6 sample/sec\n",
      "Global step: 22959 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 237.5 sample/sec\n",
      "Global step: 22969 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5078 - 238.1 sample/sec\n",
      "Global step: 22979 - [======================>-------]  77% - acc: 0.9453 - loss: 1.5156 - 240.3 sample/sec\n",
      "Global step: 22989 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5844 - 241.7 sample/sec\n",
      "Global step: 22999 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5385 - 247.4 sample/sec\n",
      "Global step: 23009 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 248.0 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 23019 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5457 - 264.7 sample/sec\n",
      "Global step: 23029 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5226 - 250.0 sample/sec\n",
      "Global step: 23039 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5152 - 225.7 sample/sec\n",
      "Global step: 23049 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5382 - 255.5 sample/sec\n",
      "Global step: 23059 - [============================>-]  97% - acc: 0.9453 - loss: 1.5148 - 267.4 sample/sec\n",
      "Global step: 23069 - [=============================>] 100% - acc: 0.9375 - loss: 1.5232 - 308.0 sample/sec\n",
      "\n",
      "Epoch 59 - accuracy: 77.83% (7783/10000) - time: 00:03:35.19\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 60/60\n",
      "\n",
      "Global step: 23070 - [>-----------------------------]   0% - acc: 0.9531 - loss: 1.5078 - 219.5 sample/sec\n",
      "Global step: 23080 - [>-----------------------------]   3% - acc: 0.9531 - loss: 1.5078 - 211.0 sample/sec\n",
      "Global step: 23090 - [=>----------------------------]   5% - acc: 0.9531 - loss: 1.5074 - 229.8 sample/sec\n",
      "Global step: 23100 - [==>---------------------------]   8% - acc: 0.9453 - loss: 1.5153 - 233.2 sample/sec\n",
      "Global step: 23110 - [==>---------------------------]  10% - acc: 0.9531 - loss: 1.5081 - 254.9 sample/sec\n",
      "Global step: 23120 - [===>--------------------------]  13% - acc: 0.9531 - loss: 1.5075 - 236.0 sample/sec\n",
      "Global step: 23130 - [====>-------------------------]  15% - acc: 0.9453 - loss: 1.5148 - 244.8 sample/sec\n",
      "Global step: 23140 - [=====>------------------------]  18% - acc: 0.9141 - loss: 1.5468 - 242.3 sample/sec\n",
      "Global step: 23150 - [=====>------------------------]  20% - acc: 0.9688 - loss: 1.4921 - 234.0 sample/sec\n",
      "Global step: 23160 - [======>-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 233.5 sample/sec\n",
      "Global step: 23170 - [=======>----------------------]  26% - acc: 0.9766 - loss: 1.4844 - 213.9 sample/sec\n",
      "Global step: 23180 - [========>---------------------]  28% - acc: 0.9375 - loss: 1.5231 - 210.2 sample/sec\n",
      "Global step: 23190 - [========>---------------------]  31% - acc: 0.9766 - loss: 1.4844 - 225.9 sample/sec\n",
      "Global step: 23200 - [=========>--------------------]  33% - acc: 0.9141 - loss: 1.5463 - 222.7 sample/sec\n",
      "Global step: 23210 - [==========>-------------------]  36% - acc: 0.9141 - loss: 1.5461 - 245.8 sample/sec\n",
      "Global step: 23220 - [===========>------------------]  38% - acc: 0.9297 - loss: 1.5304 - 241.4 sample/sec\n",
      "Global step: 23230 - [===========>------------------]  41% - acc: 0.9297 - loss: 1.5297 - 252.9 sample/sec\n",
      "Global step: 23240 - [============>-----------------]  43% - acc: 0.9219 - loss: 1.5393 - 240.5 sample/sec\n",
      "Global step: 23250 - [=============>----------------]  46% - acc: 0.9297 - loss: 1.5306 - 258.8 sample/sec\n",
      "Global step: 23260 - [==============>---------------]  49% - acc: 0.9375 - loss: 1.5225 - 254.3 sample/sec\n",
      "Global step: 23270 - [==============>---------------]  51% - acc: 0.8828 - loss: 1.5770 - 221.8 sample/sec\n",
      "Global step: 23280 - [===============>--------------]  54% - acc: 0.9219 - loss: 1.5386 - 210.7 sample/sec\n",
      "Global step: 23290 - [================>-------------]  56% - acc: 0.9688 - loss: 1.4919 - 239.7 sample/sec\n",
      "Global step: 23300 - [=================>------------]  59% - acc: 0.9297 - loss: 1.5312 - 242.7 sample/sec\n",
      "Global step: 23310 - [=================>------------]  61% - acc: 0.8984 - loss: 1.5619 - 238.1 sample/sec\n",
      "Global step: 23320 - [==================>-----------]  64% - acc: 0.8906 - loss: 1.5697 - 220.7 sample/sec\n",
      "Global step: 23330 - [===================>----------]  66% - acc: 0.9297 - loss: 1.5306 - 165.9 sample/sec\n",
      "Global step: 23340 - [====================>---------]  69% - acc: 0.9453 - loss: 1.5155 - 174.6 sample/sec\n",
      "Global step: 23350 - [====================>---------]  72% - acc: 0.9297 - loss: 1.5315 - 162.5 sample/sec\n",
      "Global step: 23360 - [=====================>--------]  74% - acc: 0.9531 - loss: 1.5078 - 200.1 sample/sec\n",
      "Global step: 23370 - [======================>-------]  77% - acc: 0.9453 - loss: 1.5156 - 205.2 sample/sec\n",
      "Global step: 23380 - [======================>-------]  79% - acc: 0.8750 - loss: 1.5845 - 211.9 sample/sec\n",
      "Global step: 23390 - [=======================>------]  82% - acc: 0.9219 - loss: 1.5384 - 192.2 sample/sec\n",
      "Global step: 23400 - [========================>-----]  84% - acc: 0.9766 - loss: 1.4846 - 193.1 sample/sec\n",
      "Global step: 23410 - [=========================>----]  87% - acc: 0.9141 - loss: 1.5458 - 184.8 sample/sec\n",
      "Global step: 23420 - [==========================>---]  90% - acc: 0.9375 - loss: 1.5226 - 182.7 sample/sec\n",
      "Global step: 23430 - [==========================>---]  92% - acc: 0.9453 - loss: 1.5153 - 174.7 sample/sec\n",
      "Global step: 23440 - [===========================>--]  95% - acc: 0.9219 - loss: 1.5382 - 166.7 sample/sec\n",
      "Global step: 23450 - [============================>-]  97% - acc: 0.9453 - loss: 1.5147 - 164.0 sample/sec\n",
      "Global step: 23460 - [=============================>] 100% - acc: 0.9375 - loss: 1.5232 - 236.5 sample/sec\n",
      "\n",
      "Epoch 60 - accuracy: 77.85% (7785/10000) - time: 00:04:18.33\n",
      "###########################################################################################################\n",
      "Best accuracy pre session: 78.07, time: 03:03:31.67\n"
     ]
    }
   ],
   "source": [
    "# download all files from https://github.com/exelban/tensorflow-cifar-10\n",
    "# and put these into your working directory\n",
    "%run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying to restore last checkpoint ...\n",
      "INFO:tensorflow:Restoring parameters from ./tensorboard/cifar-10-v1.0.0/-12512\n",
      "Restored checkpoint from: ./tensorboard/cifar-10-v1.0.0/-12512\n",
      "\n",
      "Accuracy on Test-Set: 78.07% (7807 / 10000)\n"
     ]
    }
   ],
   "source": [
    "# download all files from https://github.com/exelban/tensorflow-cifar-10\n",
    "# and put these into your working directory\n",
    "%run predict.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
